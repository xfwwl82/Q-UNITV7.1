#!/usr/bin/env python3
"""
Q-UNITY-V7.1 ä¸»èœå•ç³»ç»Ÿ

ã€V7.1 æ•°æ®ç®¡ç†ä¿®å¤è¯´æ˜ã€‘
åŸ op-v3 é˜¶æ®µé¡ºåºç¼ºé™·:
  AKShareå…¨é‡(5190åªÃ—7s/2è¿›ç¨‹ = 5+å°æ—¶) â†’ TDXï¼ˆæ²¡æœ‰é€Ÿåº¦ï¼pytdx æ ¹æœ¬æœªè¢«è°ƒç”¨ï¼‰

V7.1 ä¿®å¤:
  é€‰é¡¹1: TDX å¿«é€Ÿå…¨é‡é‡‡é›†  â€” ä»… TDX åå¤æƒï¼Œ8çº¿ç¨‹ï¼Œ~30åˆ†é’Ÿï¼Œç«‹å³å¯ç”¨
  é€‰é¡¹2: AKShare æ‰©å±•å­—æ®µ  â€” å¯¹å·²é‡‡é›†æ•°æ®è¡¥å…… turnover/pct_changeï¼ˆç‹¬ç«‹æ­¥éª¤ï¼‰
  é€‰é¡¹3: å¢é‡æ›´æ–°          â€” TDX å¿«é€Ÿå¢é‡
  é€‰é¡¹4: è¡¥é‡‡å¤±è´¥è‚¡ç¥¨
"""
from __future__ import annotations
import json
import logging
import socket
import sys
import time
from pathlib import Path

logger = logging.getLogger(__name__)


def _check_data_source_heartbeat() -> None:
    print("" + "â”€" * 50)
    print("  æ•°æ®æºå¿ƒè·³æ£€æµ‹")
    print("â”€" * 50)

    print("[1] AKShare:")
    try:
        import akshare as ak
        t0 = time.time()
        df = ak.stock_zh_index_spot_em(symbol="ä¸Šè¯æŒ‡æ•°")
        elapsed = time.time() - t0
        if df is not None and not df.empty:
            print(f"  âœ“ è¿é€šæ­£å¸¸ ({elapsed:.2f}s)")
        else:
            print(f"  âœ— è¿”å›ç©ºæ•°æ® ({elapsed:.2f}s)")
    except ImportError:
        print("  âœ— akshare æœªå®‰è£…")
    except Exception as e:
        print(f"  âœ— å¼‚å¸¸: {e}")

    print("[2] TDX èŠ‚ç‚¹ï¼ˆå‰5ä¼˜é€‰ï¼‰:")
    try:
        from src.data.collector.node_scanner import get_fastest_nodes
        nodes = get_fastest_nodes(top_n=5, timeout=3.0)
        for n in nodes:
            icon = "âœ“" if n["status"] == "ok" else "âœ—"
            lat  = f"{n['latency_ms']:.0f}ms" if n["latency_ms"] >= 0 else "timeout"
            print(f"  {icon} {n['name']} {n['host']}:{n['port']}  {lat}")
    except Exception as e:
        print(f"  âœ— èŠ‚ç‚¹æ‰«æå¤±è´¥: {e}")

    print("[3] BaoStock:")
    try:
        import baostock as bs
        t0 = time.time()
        lg = bs.login()
        elapsed = time.time() - t0
        if lg.error_code == "0":
            print(f"  âœ“ ç™»å½•æˆåŠŸ ({elapsed:.2f}s)")
            bs.logout()
        else:
            print(f"  âœ— ç™»å½•å¤±è´¥: {lg.error_msg}")
    except ImportError:
        print("  âœ— baostock æœªå®‰è£…")
    except Exception as e:
        print(f"  âœ— å¼‚å¸¸: {e}")

    print("[4] Tushare (DNS):")
    try:
        t0 = time.time()
        ip = socket.gethostbyname("api.tushare.pro")
        elapsed = time.time() - t0
        print(f"  âœ“ DNS è§£ææ­£å¸¸ â†’ {ip} ({elapsed*1000:.0f}ms)")
    except socket.gaierror as e:
        print(f"  âœ— DNS è§£æå¤±è´¥: {e}")

    print("" + "â”€" * 50)
    input("æŒ‰ Enter è¿”å›...")


def _load_collector_config() -> dict:
    defaults = {
        "parquet_dir":    "./data/parquet",
        "reports_dir":    "./data/reports",
        "top_n_nodes":    5,
        "tdx_workers":    8,
        "ak_workers":     2,
        "ak_delay_min":   0.3,
        "ak_delay_max":   0.8,
        "ak_max_retries": 3,
    }
    try:
        cfg_path = Path("config.json")
        if cfg_path.exists():
            raw = json.loads(cfg_path.read_text(encoding="utf-8"))
            c = raw.get("collector", {})
            d = raw.get("data", {})
            defaults.update({
                "parquet_dir":    d.get("parquet_dir",         defaults["parquet_dir"]),
                "reports_dir":    d.get("reports_dir",         defaults["reports_dir"]),
                "top_n_nodes":    c.get("tdx_top_nodes",       defaults["top_n_nodes"]),
                "tdx_workers":    c.get("tdx_workers",         defaults["tdx_workers"]),
                "ak_workers":     c.get("akshare_workers",     defaults["ak_workers"]),
                "ak_delay_min":   c.get("akshare_delay_min",   defaults["ak_delay_min"]),
                "ak_delay_max":   c.get("akshare_delay_max",   defaults["ak_delay_max"]),
                "ak_max_retries": c.get("akshare_max_retries", defaults["ak_max_retries"]),
            })
    except Exception:
        pass
    return defaults


def _make_pipeline(force_full: bool = False, enable_akshare: bool = False):
    from src.data.collector.pipeline import StockDataPipeline
    cfg = _load_collector_config()
    return StockDataPipeline(
        parquet_dir=cfg["parquet_dir"],
        reports_dir=cfg["reports_dir"],
        top_n_nodes=cfg["top_n_nodes"],
        tdx_workers=cfg["tdx_workers"],
        ak_workers=cfg["ak_workers"],
        ak_delay_min=cfg["ak_delay_min"],
        ak_delay_max=cfg["ak_delay_max"],
        ak_max_retries=cfg["ak_max_retries"],
        force_full=force_full,
        enable_akshare=enable_akshare,
    )


def _print_stats(stats: dict) -> None:
    mode = "åŒè½¨(TDX+AKShare)" if stats.get("akshare_enabled") else "å¿«é€Ÿ(ä»…TDX)"
    print(f"{'='*54}")
    print(f"  é‡‡é›†å®Œæˆ  [{mode}]")
    print(f"{'='*54}")
    print(f"  æ€»è®¡:   {stats.get('total',   0):>6} åª")
    print(f"  æˆåŠŸ:   {stats.get('success', 0):>6} åª")
    print(f"  å¤±è´¥:   {stats.get('failed',  0):>6} åª")
    print(f"  è·³è¿‡:   {stats.get('skipped', 0):>6} åªï¼ˆå·²æœ€æ–°ï¼‰")
    print(f"  è€—æ—¶:   {stats.get('elapsed_s', 0):>6.1f} ç§’")
    print(f"  é€Ÿåº¦:   {stats.get('speed',    0):>6.1f} è‚¡/ç§’")
    print(f"  æŠ¥å‘Š:   {stats.get('reports_dir', 'N/A')}")
    print(f"{'='*54}")


def data_management_menu(config=None, storage=None) -> None:
    while True:
        print("" + "â•" * 56)
        print("  æ•°æ®ç®¡ç†  (V7.1 TDXå¿«é€Ÿ + AKShareå¯é€‰æ‰©å±•)")
        print("â•" * 56)
        print("  1. TDX å¿«é€Ÿå…¨é‡é‡‡é›†   (~30minï¼ŒHFQï¼Œæ— æ‰©å±•å­—æ®µ)")
        print("  2. AKShare æ‰©å±•å­—æ®µè¡¥å…… (turnover/pct_changeï¼Œç‹¬ç«‹æ­¥éª¤)")
        print("  3. å¢é‡æ•°æ®æ›´æ–°        (ä»…è¡¥é‡‡ç¼ºå¤±æ—¥æœŸ)")
        print("  4. è¡¥é‡‡å¤±è´¥è‚¡ç¥¨        (failed_stocks.txt)")
        print("  5. æ•°æ®å®Œæ•´æ€§æ£€æŸ¥")
        print("  6. èŠ‚ç‚¹èµ›é©¬æµ‹è¯•")
        print("  7. æ¸…ç†ç¼“å­˜")
        print("  0. è¿”å›ä¸»èœå•")
        print()
        print("  â„¹  å®Œæ•´å·¥ä½œæµ: å…ˆé€‰1(~30min) â†’ å†é€‰2(å¯é€‰,~2~4h)")
        choice = input("è¯·é€‰æ‹© [0-7]: ").strip()

        if choice == "0":
            break
        elif choice == "1":
            _cmd_tdx_fast_collect()
        elif choice == "2":
            _cmd_enrich_akshare()
        elif choice == "3":
            _cmd_incremental_update()
        elif choice == "4":
            _cmd_retry_failed()
        elif choice == "5":
            _cmd_check_integrity(storage)
        elif choice == "6":
            _cmd_node_race()
        elif choice == "7":
            _cmd_clean_cache()
        else:
            print("  âœ— æ— æ•ˆé€‰é¡¹")


def _cmd_tdx_fast_collect() -> None:
    print("âš¡ TDX å¿«é€Ÿå…¨é‡é‡‡é›†ï¼ˆä»… TDXï¼Œåå¤æƒ HFQï¼‰")
    print("  æ¨¡å¼: TDX 8çº¿ç¨‹å¹¶å‘ï¼Œä¸å¯åŠ¨ AKShare è¿›ç¨‹")
    print("  é¢„è®¡: 5000+ åª A è‚¡çº¦ 20~40 åˆ†é’Ÿ")
    print("  å­—æ®µ: open/high/low/close/vol/amountï¼ˆä¸å« turnover/pct_changeï¼‰")
    print("  åç»­: å¦‚éœ€æ‰©å±•å­—æ®µï¼Œå®Œæˆåé€‰ã€Œé€‰é¡¹2ã€å•ç‹¬è¡¥å……")
    confirm = input("  ç¡®è®¤å¼€å§‹? [y/N]: ").strip().lower()
    if confirm != "y":
        print("  å·²å–æ¶ˆã€‚")
        return
    try:
        pipeline = _make_pipeline(force_full=True, enable_akshare=False)
        stats = pipeline.download_all_a_stocks()
        _print_stats(stats)
    except ImportError as e:
        print(f"  âœ— å¯¼å…¥å¤±è´¥: {e}")
    except Exception as e:
        logger.exception("TDX å¿«é€Ÿé‡‡é›†å¼‚å¸¸")
        print(f"  âœ— å¤±è´¥: {e}")


def _cmd_enrich_akshare() -> None:
    print("ğŸ”¬ AKShare æ‰©å±•å­—æ®µè¡¥å……ï¼ˆç‹¬ç«‹æ­¥éª¤ï¼‰")
    print("  è¯´æ˜: å¯¹å·²æœ‰ Parquet æ–‡ä»¶è¡¥å…… turnoverã€pct_changeã€amplitude å­—æ®µ")
    print("  æ¨¡å¼: è¿›ç¨‹éš”ç¦»ï¼ˆ2è¿›ç¨‹ï¼‰ï¼ŒåŒ…å«é™æµæ„ŸçŸ¥é€€é¿ï¼ˆ30/60/90sï¼‰")
    print("  é¢„è®¡: 5000åªçº¦ 2~4 å°æ—¶ï¼ˆå—ä¸œæ–¹è´¢å¯Œæ¥å£é™æµå½±å“ï¼‰")
    print("  å‰æ: è¯·å…ˆå®Œæˆã€Œé€‰é¡¹1: TDX å¿«é€Ÿå…¨é‡é‡‡é›†ã€")

    cfg = _load_collector_config()
    parquet_dir = Path(cfg["parquet_dir"])
    existing = list(parquet_dir.glob("*.parquet"))
    if not existing:
        print(f"  âœ— Parquet ç›®å½•ä¸ºç©º: {parquet_dir}")
        print("  è¯·å…ˆæ‰§è¡Œã€Œé€‰é¡¹1: TDX å¿«é€Ÿå…¨é‡é‡‡é›†ã€ã€‚")
        return

    print(f"  å½“å‰æœ¬åœ° Parquet: {len(existing)} åª")
    # å¿«é€ŸæŠ½æ ·æ£€æŸ¥æ˜¯å¦å·²æœ‰æ‰©å±•å­—æ®µ
    import pandas as pd
    has_ext = no_ext = 0
    for f in existing[:30]:
        try:
            cols = pd.read_parquet(f).columns.tolist()
            if "turnover" in cols:
                has_ext += 1
            else:
                no_ext += 1
        except Exception:
            no_ext += 1
    print(f"  æŠ½æ ·ï¼ˆå‰30åªï¼‰: {has_ext} åªå·²æœ‰ turnoverï¼Œ{no_ext} åªæœªå«æ‰©å±•å­—æ®µ")

    confirm = input("  ç¡®è®¤å¼€å§‹? [y/N]: ").strip().lower()
    if confirm != "y":
        print("  å·²å–æ¶ˆã€‚")
        return
    try:
        pipeline = _make_pipeline(force_full=False, enable_akshare=True)
        stats = pipeline.enrich_akshare()
        print(f"  âœ“ å®Œæˆ: å¤„ç† {stats.get('total',0)} åªï¼Œ"
              f"æˆåŠŸ {stats.get('success',0)} åªï¼Œå¤±è´¥ {stats.get('failed',0)} åª")
    except ImportError as e:
        print(f"  âœ— å¯¼å…¥å¤±è´¥: {e}")
    except Exception as e:
        logger.exception("AKShare æ‰©å±•å­—æ®µè¡¥å……å¼‚å¸¸")
        print(f"  âœ— å¤±è´¥: {e}")


def _cmd_incremental_update() -> None:
    print("ğŸ”„ å¢é‡æ•°æ®æ›´æ–°ï¼ˆTDXï¼Œä»…è¡¥é‡‡ç¼ºå¤±æ—¥æœŸï¼‰")
    try:
        pipeline = _make_pipeline(force_full=False, enable_akshare=False)
        stock_list = pipeline._get_all_a_stock_list()
        if not stock_list:
            print("  âœ— è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥")
            return
        print(f"  å…± {len(stock_list)} åª A è‚¡ï¼Œå¼€å§‹å¢é‡æ›´æ–°...")
        stats = pipeline.run(stock_list)
        _print_stats(stats)
    except ImportError as e:
        print(f"  âœ— å¯¼å…¥å¤±è´¥: {e}")
    except Exception as e:
        logger.exception("å¢é‡æ›´æ–°å¼‚å¸¸")
        print(f"  âœ— å¤±è´¥: {e}")


def _cmd_retry_failed() -> None:
    print("ğŸ” è¡¥é‡‡å¤±è´¥è‚¡ç¥¨")
    cfg = _load_collector_config()
    failed_txt = Path(cfg["reports_dir"]) / "failed_stocks.txt"
    if not failed_txt.exists():
        print(f"  âš ï¸  æœªæ‰¾åˆ°å¤±è´¥åˆ—è¡¨: {failed_txt}")
        print("  è¯·å…ˆæ‰§è¡Œå…¨é‡é‡‡é›†æˆ–å¢é‡æ›´æ–°ã€‚")
        return
    try:
        pipeline = _make_pipeline(force_full=True, enable_akshare=False)
        stats = pipeline.retry_failed(reports_dir=cfg["reports_dir"])
        _print_stats(stats)
    except Exception as e:
        logger.exception("è¡¥é‡‡å¼‚å¸¸")
        print(f"  âœ— å¤±è´¥: {e}")


def _cmd_check_integrity(storage=None) -> None:
    print("ğŸ” æ•°æ®å®Œæ•´æ€§æ£€æŸ¥")
    cfg = _load_collector_config()
    parquet_dir = Path(cfg["parquet_dir"])
    if not parquet_dir.exists():
        print(f"  âš ï¸  Parquet ç›®å½•ä¸å­˜åœ¨: {parquet_dir}")
        return
    files = list(parquet_dir.glob("*.parquet"))
    print(f"  å·²å­˜å‚¨ {len(files)} åªè‚¡ç¥¨çš„ Parquet æ–‡ä»¶")
    if files:
        import pandas as pd
        print("  æŠ½æ ·æ£€æŸ¥ï¼ˆå‰5åªï¼‰:")
        for f in files[:5]:
            try:
                df = pd.read_parquet(f)
                ext = [c for c in ("turnover", "pct_change", "adjust") if c in df.columns]
                d_min = df["date"].min() if "date" in df.columns else "?"
                d_max = df["date"].max() if "date" in df.columns else "?"
                print(f"    âœ“ {f.stem}: {len(df)} è¡Œ | {d_min} ~ {d_max} | æ‰©å±•={ext}")
            except Exception as ex:
                print(f"    âœ— {f.stem}: {ex}")
    if storage:
        codes = storage.get_all_codes()
        print(f"  ColumnarStorage: {len(codes)} åªè‚¡ç¥¨")
    input("æŒ‰ Enter è¿”å›...")


def _cmd_node_race() -> None:
    print("ğŸ TDX èŠ‚ç‚¹èµ›é©¬æµ‹è¯•")
    try:
        from src.data.collector.node_scanner import race_nodes, TDX_NODES
        print(f"  æµ‹è¯• {len(TDX_NODES)} ä¸ªå€™é€‰èŠ‚ç‚¹...")
        results = race_nodes(timeout=3.0)
        ok_nodes = [r for r in results if r["status"] == "ok"]
        print(f"  ç»“æœï¼ˆ{len(ok_nodes)}/{len(results)} å¯è¾¾ï¼‰:")
        for i, r in enumerate(results[:10], 1):
            icon = "âœ“" if r["status"] == "ok" else "âœ—"
            lat  = f"{r['latency_ms']:>7.2f} ms" if r["latency_ms"] >= 0 else "  timeout"
            print(f"    {i:>2}. {icon} {r['name']:<10} {r['host']:>18}:{r['port']}  {lat}")
        if len(results) > 10:
            print(f"    ... ä½™ {len(results)-10} ä¸ªèŠ‚ç‚¹")
    except Exception as e:
        print(f"  âœ— èŠ‚ç‚¹æµ‹è¯•å¤±è´¥: {e}")
    input("æŒ‰ Enter è¿”å›...")


def _cmd_clean_cache() -> None:
    print("ğŸ—‘ï¸  æ¸…ç†ç¼“å­˜")
    cleaned = 0
    for p in Path("./data/cache").rglob("*.json") if Path("./data/cache").exists() else []:
        try:
            p.unlink()
            cleaned += 1
        except Exception:
            pass
    print(f"  å·²æ¸…ç† {cleaned} ä¸ªç¼“å­˜æ–‡ä»¶ï¼ˆfundamental JSON ç¼“å­˜ï¼‰")
    print("  æ³¨: Parquet è¡Œæƒ…æ–‡ä»¶å’Œè¿è¡ŒæŠ¥å‘Šä¸ä¼šè¢«æ¸…é™¤ã€‚")


def backtest_menu(config=None) -> None:
    while True:
        print("" + "â•" * 40)
        print("  å›æµ‹ç³»ç»Ÿ")
        print("â•" * 40)
        print("  1. è¿è¡Œå•ç­–ç•¥å›æµ‹")
        print("  2. å¤šç­–ç•¥å¯¹æ¯”")
        print("  3. æŸ¥çœ‹å†å²å›æµ‹ç»“æœ")
        print("  0. è¿”å›ä¸»èœå•")
        choice = input("è¯·é€‰æ‹© [0-3]: ").strip()
        if choice == "0":
            break
        elif choice == "1":
            from src.strategy.strategies import STRATEGY_REGISTRY
            print(f"å¯ç”¨ç­–ç•¥: {list(STRATEGY_REGISTRY.keys())}")
            name = input("è¾“å…¥ç­–ç•¥åç§°: ").strip()
            if name in STRATEGY_REGISTRY:
                print(f"  å·²é€‰æ‹©: {name}")
            else:
                print(f"  âœ— æœªçŸ¥ç­–ç•¥: {name}")
        elif choice == "2":
            print("  å¤šç­–ç•¥å¯¹æ¯”åŠŸèƒ½å¼€å‘ä¸­...")
        elif choice == "3":
            results_dir = Path("results")
            if results_dir.exists():
                files = list(results_dir.glob("*.json"))
                print(f"  å…± {len(files)} ä¸ªå†å²ç»“æœ")
                for f in files[:10]:
                    print(f"    {f.name}")
            else:
                print("  æš‚æ— å†å²å›æµ‹ç»“æœ")
        else:
            print("  âœ— æ— æ•ˆé€‰é¡¹")


def system_management_menu(config=None) -> None:
    while True:
        print("" + "â•" * 40)
        print("  ç³»ç»Ÿç®¡ç†")
        print("â•" * 40)
        print("  1. å¥åº·æ£€æŸ¥")
        print("  2. æŸ¥çœ‹æ—¥å¿—")
        print("  3. æ•°æ®æºå¿ƒè·³æ£€æµ‹")
        print("  0. è¿”å›ä¸»èœå•")
        choice = input("è¯·é€‰æ‹© [0-3]: ").strip()
        if choice == "0":
            break
        elif choice == "1":
            from main import run_health_check
            run_health_check()
        elif choice == "2":
            log_path = Path("logs/q-unity.log")
            if log_path.exists():
                lines = log_path.read_text(encoding="utf-8").splitlines()
                print(f"æœ€è¿‘ 20 è¡Œæ—¥å¿—:")
                for line in lines[-20:]:
                    print(f"  {line}")
            else:
                print("  æš‚æ— æ—¥å¿—æ–‡ä»¶")
        elif choice == "3":
            _check_data_source_heartbeat()
        else:
            print("  âœ— æ— æ•ˆé€‰é¡¹")


def main_menu() -> None:
    config = storage = None
    try:
        from src.config import ConfigManager
        from src.data.storage import ColumnarStorageManager
        config  = ConfigManager()
        data_dir = config.get("data", {}).get("base_dir", "./data")
        storage = ColumnarStorageManager(data_dir)
    except Exception as e:
        print(f"âš ï¸  åˆå§‹åŒ–å¤±è´¥: {e}")

    while True:
        print("" + "â•" * 56)
        print("       Q-UNITY-V7.1 é‡åŒ–äº¤æ˜“ç³»ç»Ÿ v7.1.0")
        print("       æ•°æ®å±‚: TDXå¿«é€Ÿ(~30min) + AKShareå¯é€‰æ‰©å±•")
        print("â•" * 56)
        print("  1. æ•°æ®ç®¡ç†  (å¿«é€Ÿé‡‡é›†/æ‰©å±•å­—æ®µ/å¢é‡/èŠ‚ç‚¹)")
        print("  2. å›æµ‹ç³»ç»Ÿ")
        print("  3. ç³»ç»Ÿç®¡ç†  (å¥åº·æ£€æŸ¥/æ—¥å¿—/å¿ƒè·³)")
        print("  0. é€€å‡º")
        print("â”€" * 56)
        choice = input("è¯·é€‰æ‹© [0-3]: ").strip()
        if choice == "0":
            print("å†è§! Q-UNITY-V7.1 å·²é€€å‡ºã€‚")
            sys.exit(0)
        elif choice == "1":
            data_management_menu(config, storage)
        elif choice == "2":
            backtest_menu(config)
        elif choice == "3":
            system_management_menu(config)
        else:
            print("  âœ— æ— æ•ˆé€‰é¡¹ï¼Œè¯·é‡æ–°é€‰æ‹©")


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    )
    main_menu()
