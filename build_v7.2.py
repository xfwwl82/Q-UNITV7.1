#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Q-UNITY-V7.2 一键构建脚本（最终整合版）
=========================================

Q-UNITY-V7.1/:
  - 基础: build_v7_1_fixed（原构建脚本基础）
  - 项目源码: Q-UNITY-V7.1/（完整项目代码）

V7.1 修复内容:
  P0  : 阶段顺序反转（TDX先~30min → AKShare后可选~2~4h）
  P1  : AKShare ProcessPool 进程隔离（替代 ThreadPool，解决 session 竞争）
  P2  : TDX HFQ 后复权（adjustflag=2，三源复权体系完全统一）
  P3  : enable_akshare 可选参数（默认False快速模式）
  NB-01~NB-21: 回测引擎/RSRS/熔断/持仓/止损等全量 Bug 修复

Q-UNITY-V7.1/:
  python3 build_v7.2.py

Q-UNITY-V7.'GENERATOR_EOF' Q-UNITY-V7.1/ 项目文件夹（共39个文件）。

Q-UNITY-V7.1 Q-UNITY-V7.1/:
  python3 -m py_compile build_v7.2.py
"""

from pathlib import Path

BASE = Path("Q-UNITY-V7.1")


def write_file(rel_path: str, content: bytes) -> None:
    target = BASE / rel_path
    target.parent.mkdir(parents=True, exist_ok=True)
    target.write_bytes(content)


FILE_config_json = b'{\r\n  "data": {\r\n    "base_dir": "./data",\r\n    "parquet_dir": "./data/parquet",\r\n    "cache_dir": "./data/cache",\r\n    "industry_dir": "./data/industry",\r\n    "reports_dir": "./data/reports"\r\n  },\r\n  "collector": {\r\n    "tdx_top_nodes": 5,\r\n    "tdx_timeout": 3.0,\r\n    "tdx_bars_per_req": 800,\r\n    "tdx_total_bars": 2500,\r\n    "tdx_workers": 8,\r\n    "tdx_sleep_min": 0.1,\r\n    "tdx_sleep_max": 0.2,\r\n    "akshare_workers": 2,\r\n    "akshare_delay_min": 0.3,\r\n    "akshare_delay_max": 0.8,\r\n    "akshare_max_retries": 3,\r\n    "akshare_ratelimit_wait": 30,\r\n    "baostock_delay_min": 0.5,\r\n    "baostock_delay_max": 1.0,\r\n    "baostock_max_retries": 3,\r\n    "min_bars_threshold": 10,\r\n    "adjust": "hfq"\r\n  },\r\n  "backtest": {\r\n    "initial_cash": 1000000.0,\r\n    "commission_rate": 0.0003,\r\n    "slippage_rate": 0.001,\r\n    "tax_rate": 0.001,\r\n    "position_limit": 20,\r\n    "max_position_pct": 0.2\r\n  },\r\n  "risk": {\r\n    "max_drawdown": 0.2,\r\n    "max_position_pct": 0.1,\r\n    "industry_limit": 0.3,\r\n    "stop_loss_pct": 0.1,\r\n    "take_profit_pct": 0.2,\r\n    "trailing_stop_pct": 0.05,\r\n    "circuit_breaker_cooldown_days": 5\r\n  },\r\n  "factors": {\r\n    "rsrs": {\r\n      "regression_window": 18,\r\n      "zscore_window": 600,\r\n      "enable": true\r\n    },\r\n    "alpha": {\r\n      "momentum_window": 20,\r\n      "volatility_window": 20,\r\n      "enable": true\r\n    }\r\n  },\r\n  "strategy": {\r\n    "rebalance_freq": "daily",\r\n    "top_n": 20,\r\n    "min_score": 0.0\r\n  },\r\n  "logging": {\r\n    "level": "INFO",\r\n    "file": "./logs/q-unity.log"\r\n  }\r\n}\r\n'

FILE_requirements_txt = b'# Q-UNITY-V7.1 \xe4\xbe\x9d\xe8\xb5\x96\xe5\x8c\x85\r\n\r\n# \xe6\xa0\xb8\xe5\xbf\x83\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\x84\xe7\x90\x86\r\npandas>=2.0.0\r\nnumpy>=1.24.0\r\nscipy>=1.10.0\r\nscikit-learn>=1.3.0\r\n\r\n# \xe9\xab\x98\xe6\x80\xa7\xe8\x83\xbd\xe8\xae\xa1\xe7\xae\x97\xef\xbc\x88\xe5\x8f\xaf\xe9\x80\x89\xef\xbc\x8c\xe6\x97\xa0\xe5\x88\x99\xe8\x87\xaa\xe5\x8a\xa8\xe9\x99\x8d\xe7\xba\xa7\xef\xbc\x89\r\nnumba>=0.57.0\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe5\xad\x98\xe5\x82\xa8\r\npyarrow>=12.0.0\r\n\r\n# \xe6\x95\xb0\xe6\x8d\xae\xe9\x87\x87\xe9\x9b\x86\r\npytdx>=1.72\r\nbaostock>=0.8.8\r\nakshare>=1.12.0\r\n\r\n# \xe9\x85\x8d\xe7\xbd\xae\xe7\xae\xa1\xe7\x90\x86\r\npyyaml>=6.0\r\n\r\n# \xe6\x97\xa5\xe5\xbf\x97\xe5\x92\x8c\xe5\xb7\xa5\xe5\x85\xb7\r\npython-dateutil>=2.8.2\r\ntqdm>=4.65.0\r\n\r\n# \xe5\x8f\xaf\xe9\x80\x89\xef\xbc\x9a\xe6\x95\xb0\xe6\x8d\xae\xe5\x8f\xaf\xe8\xa7\x86\xe5\x8c\x96\r\nmatplotlib>=3.7.0\r\nseaborn>=0.12.0\r\n\r\n# \xe5\x8f\xaf\xe9\x80\x89\xef\xbc\x9aWeb\xe7\x95\x8c\xe9\x9d\xa2\r\nflask>=2.3.0\r\n\r\n# \xe5\xbc\x80\xe5\x8f\x91\xe5\xb7\xa5\xe5\x85\xb7\r\npytest>=7.4.0\r\n'

FILE_README_OP_md = b'# Q-UNITY-V6-op patch_v9 \xe2\x80\x94 \xe5\x8f\x8c\xe8\xbd\xa8\xe5\xb9\xb6\xe8\xa1\x8c A \xe8\x82\xa1\xe6\x97\xa5\xe7\xba\xbf\xe9\x87\x87\xe9\x9b\x86\xe5\xbc\x95\xe6\x93\x8e\xef\xbc\x88\xe5\x85\xa8\xe7\xa8\x8b HFQ\xef\xbc\x89\r\n\r\n## \xe6\x9e\xb6\xe6\x9e\x84\xe5\x8f\x98\xe6\x9b\xb4\xe6\x91\x98\xe8\xa6\x81 (v8 \xe2\x86\x92 v9)\r\n\r\n### v7\xef\xbc\x88\xe4\xb8\xb2\xe8\xa1\x8c\xe9\x99\x8d\xe7\xba\xa7 \xe2\x80\x94 \xe5\xb7\xb2\xe5\xba\x9f\xe5\xbc\x83\xef\xbc\x89\r\n```\r\nTDX \xe2\x94\x80\xe6\x88\x90\xe5\x8a\x9f\xe2\x94\x80\xe2\x86\x92 \xe5\x86\x99\xe7\x9b\x98\xef\xbc\x88\xe7\xbc\xba turnover\xef\xbc\x89\r\n     \xe2\x94\x94\xe5\xa4\xb1\xe8\xb4\xa5\xe2\x94\x80\xe2\x86\x92 AKShare\xef\xbc\x88\xe7\xba\xbf\xe7\xa8\x8b\xe4\xb8\x8d\xe5\xae\x89\xe5\x85\xa8\xef\xbc\x81\xef\xbc\x89\xe2\x94\x80\xe6\x88\x90\xe5\x8a\x9f\xe2\x94\x80\xe2\x86\x92 \xe5\x86\x99\xe7\x9b\x98\r\n                            \xe2\x94\x94\xe5\xa4\xb1\xe8\xb4\xa5\xe2\x94\x80\xe2\x86\x92 BaoStock\r\n```\r\n\r\n### v8\xef\xbc\x88\xe5\x8f\x8c\xe8\xbd\xa8\xe5\xb9\xb6\xe8\xa1\x8c raw+hfq \xe2\x80\x94 \xe5\xb7\xb2\xe5\x8d\x87\xe7\xba\xa7\xef\xbc\x89\r\n```\r\n\xe8\xbd\xa8\xe9\x81\x93A: TDX   (8\xe7\xba\xbf\xe7\xa8\x8b)  \xe2\x94\x80\xe2\x86\x92 OHLCV (raw, \xe6\x9c\xaa\xe5\xa4\x8d\xe6\x9d\x83)\r\n\xe8\xbd\xa8\xe9\x81\x93B: AKShare (2\xe8\xbf\x9b\xe7\xa8\x8b) \xe2\x94\x80\xe2\x86\x92 \xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5 (hfq) \xe2\x86\x92 LEFT JOIN \xe2\x86\x92 adjust=partial_hfq\r\nFallback: BaoStock (hfq)\r\n```\r\n\r\n### v9\xef\xbc\x88\xe5\x8f\x8c\xe8\xbd\xa8\xe5\xb9\xb6\xe8\xa1\x8c HFQ \xe2\x80\x94 \xe5\xbd\x93\xe5\x89\x8d\xef\xbc\x89\r\n```\r\n\xe8\xbd\xa8\xe9\x81\x93A: TDX   (8\xe7\xba\xbf\xe7\xa8\x8b, ThreadPool)  \xe2\x94\x80\xe2\x86\x92 OHLCV (hfq adjustflag=2, \xe9\xab\x98\xe9\x80\x9f)\r\n                                                \xe2\x86\x93\r\n\xe8\xbd\xa8\xe9\x81\x93B: AKShare (2\xe8\xbf\x9b\xe7\xa8\x8b, ProcessPool) \xe2\x94\x80\xe2\x86\x92 \xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5: turnover/pct_change (hfq)\r\n                                                \xe2\x86\x93\r\n                                   date \xe4\xb8\xba\xe9\x94\xae LEFT JOIN \xe5\x90\x88\xe5\xb9\xb6\xef\xbc\x88\xe5\x85\xa8\xe7\xa8\x8b hfq\xef\xbc\x89\r\n                                                \xe2\x86\x93\r\nFallback: \xe4\xb8\xa4\xe8\xbd\xa8\xe5\x9d\x87\xe5\xa4\xb1\xe8\xb4\xa5 \xe2\x86\x92 BaoStock (hfq, \xe5\xae\x8c\xe6\x95\xb4\xe5\xad\x97\xe6\xae\xb5)\r\n                                                \xe2\x86\x93\r\n                             DataValidator \xe4\xb8\x89\xe5\xb1\x82\xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x88\xe8\xa1\x8c\xe6\x95\xb0/\xe5\x88\x97/OHLC\xef\xbc\x89\r\n                                                \xe2\x86\x93\r\n                             \xe6\xb5\x81\xe5\xbc\x8f\xe5\x86\x99\xe7\x9b\x98 + RunReport \xe6\x8c\x81\xe4\xb9\x85\xe5\x8c\x96\r\n```\r\n\r\n## \xe5\x85\xb3\xe9\x94\xae\xe8\xae\xbe\xe8\xae\xa1\xe5\x86\xb3\xe7\xad\x96\r\n\r\n| \xe9\x97\xae\xe9\xa2\x98 | v7 | v8 | v9 |\r\n|---|---|---|---|\r\n| AKShare \xe7\xba\xbf\xe7\xa8\x8b\xe5\xae\x89\xe5\x85\xa8 | \xe2\x9d\x8c ThreadPool \xe5\x85\xb1\xe4\xba\xab session | \xe2\x9c\x85 ProcessPool \xe8\xbf\x9b\xe7\xa8\x8b\xe9\x9a\x94\xe7\xa6\xbb | \xe2\x9c\x85 \xe5\x90\x8c v8 |\r\n| AKShare \xe9\x99\x90\xe6\xb5\x81\xe9\x87\x8d\xe8\xaf\x95 | \xe2\x9d\x8c \xe6\x97\xa0 | \xe2\x9c\x85 30/60/90s \xe9\x99\x90\xe6\xb5\x81\xe9\x80\x80\xe9\x81\xbf | \xe2\x9c\x85 \xe5\x90\x8c v8 |\r\n| turnover \xe5\xad\x97\xe6\xae\xb5 | \xe2\x9d\x8c \xe4\xbb\x85 TDX \xe6\x88\x90\xe5\x8a\x9f\xe6\x97\xb6\xe6\xb0\xb8\xe8\xbf\x9c\xe4\xb8\xa2\xe5\xa4\xb1 | \xe2\x9c\x85 AKShare \xe7\x8b\xac\xe7\xab\x8b\xe8\xbd\xa8\xe9\x81\x93\xe4\xb8\x93\xe9\x87\x87 | \xe2\x9c\x85 \xe5\x90\x8c v8 |\r\n| \xe5\xa4\x8d\xe6\x9d\x83\xe7\xbb\x9f\xe4\xb8\x80 | \xe2\x9d\x8c \xe4\xb8\x89\xe6\xba\x90\xe4\xb8\x8d\xe7\xbb\x9f\xe4\xb8\x80 | \xe2\x9a\xa0\xef\xb8\x8f AKShare/BS=hfq, TDX=raw | \xe2\x9c\x85 \xe4\xb8\x89\xe6\xba\x90\xe5\x85\xa8\xe9\x83\xa8 hfq |\r\n| TDX HFQ | \xe2\x9d\x8c \xe6\x97\xa0 | \xe2\x9d\x8c \xe6\x97\xa0\xef\xbc\x88\xe5\x8e\x9f\xe5\xa7\x8b\xe4\xbb\xb7\xef\xbc\x89 | \xe2\x9c\x85 adjustflag=2\xef\xbc\x8c\xe8\x80\x81\xe8\x8a\x82\xe7\x82\xb9\xe8\x87\xaa\xe5\x8a\xa8\xe9\x99\x8d\xe7\xba\xa7\xe5\x91\x8a\xe8\xad\xa6 |\r\n| TDX \xe8\xbf\x9e\xe6\x8e\xa5\xe6\x8e\xa2\xe6\xb4\xbb | \xe2\x9d\x8c \xe6\x97\xa0 | \xe2\x9a\xa0\xef\xb8\x8f logger.debug \xe9\x9d\x99\xe9\xbb\x98\xe9\x87\x8d\xe5\xbb\xba | \xe2\x9c\x85 logger.info + _connect_best() \xe8\x87\xaa\xe6\x84\x88 |\r\n| \xe6\x95\xb0\xe6\x8d\xae\xe9\xaa\x8c\xe8\xaf\x81 | \xe2\x9d\x8c \xe6\x97\xa0 | \xe2\x9c\x85 \xe5\x86\x99\xe7\x9b\x98\xe5\x89\x8d\xe4\xb8\x89\xe5\xb1\x82\xe9\xaa\x8c\xe8\xaf\x81 | \xe2\x9c\x85 \xe5\x90\x8c v8 |\r\n| \xe5\xa4\xb1\xe8\xb4\xa5\xe6\x8c\x81\xe4\xb9\x85\xe5\x8c\x96 | \xe2\x9d\x8c \xe5\x86\x85\xe5\xad\x98\xe8\xae\xa1\xe6\x95\xb0 | \xe2\x9c\x85 failed_stocks.txt | \xe2\x9c\x85 \xe5\x90\x8c v8 |\r\n| \xe8\xa1\xa5\xe9\x87\x87\xe6\x9c\xba\xe5\x88\xb6 | \xe2\x9d\x8c \xe6\x97\xa0 | \xe2\x9c\x85 --retry-failed | \xe2\x9c\x85 \xe5\x90\x8c v8 |\r\n| \xe6\xb5\x81\xe5\xbc\x8f\xe5\x86\x99\xe7\x9b\x98 | \xe2\x9d\x8c \xe5\x85\xa8\xe9\x87\x8f\xe5\x90\x8e\xe6\x89\xb9\xe9\x87\x8f | \xe2\x9c\x85 \xe6\xaf\x8f\xe8\x82\xa1\xe5\xae\x8c\xe6\x88\x90\xe7\xab\x8b\xe5\x8d\xb3\xe5\x86\x99 | \xe2\x9c\x85 \xe5\x90\x8c v8 |\r\n\r\n## \xe6\xa8\xa1\xe5\x9d\x97\xe7\xbb\x93\xe6\x9e\x84\r\n```\r\nsrc/data/collector/\r\n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 node_scanner.py    # 24\xe8\x8a\x82\xe7\x82\xb9\xe8\xb5\x9b\xe9\xa9\xac\xef\xbc\x88ThreadPool \xe5\xb9\xb6\xe5\x8f\x91\xe6\x8e\xa2\xe9\x92\x88\xef\xbc\x89\r\n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 tdx_pool.py        # \xe7\xba\xbf\xe7\xa8\x8b\xe5\xae\x89\xe5\x85\xa8\xe8\xbf\x9e\xe6\x8e\xa5\xe6\xb1\xa0\xef\xbc\x88threading.local\xef\xbc\x89\r\n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 akshare_client.py  # \xe8\xbf\x9b\xe7\xa8\x8b\xe9\x9a\x94\xe7\xa6\xbb\xe9\x87\x87\xe9\x9b\x86\xef\xbc\x88ProcessPool + \xe9\x99\x90\xe6\xb5\x81\xe6\x84\x9f\xe7\x9f\xa5\xe9\x80\x80\xe9\x81\xbf\xef\xbc\x89\r\n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 baostock_client.py # BaoStock \xe5\x85\x9c\xe5\xba\x95\xef\xbc\x88hfq, \xe7\x8b\xac\xe7\xab\x8b login/logout\xef\xbc\x89\r\n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 incremental.py     # \xe6\x99\xba\xe8\x83\xbd\xe5\xa2\x9e\xe9\x87\x8f\xe6\x9b\xb4\xe6\x96\xb0\xef\xbc\x88max_date + merge + dedup\xef\xbc\x89\r\n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 validator.py       # DataValidator\xef\xbc\x88\xe8\xa1\x8c\xe6\x95\xb0/\xe5\x88\x97/OHLC \xe4\xb8\x89\xe5\xb1\x82\xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x89\r\n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 run_report.py      # RunReport\xef\xbc\x88failed_stocks.txt + JSON \xe5\xae\xa1\xe8\xae\xa1\xef\xbc\x89\r\n\xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 pipeline.py        # \xe5\x8f\x8c\xe8\xbd\xa8\xe5\xb9\xb6\xe8\xa1\x8c\xe4\xb8\xbb\xe5\xbc\x95\xe6\x93\x8e\xef\xbc\x88TDX\xe7\xba\xbf\xe7\xa8\x8b + AKShare\xe8\xbf\x9b\xe7\xa8\x8b + \xe5\x90\x88\xe5\xb9\xb6\xef\xbc\x89\r\n```\r\n\r\n## \xe5\xbf\xab\xe9\x80\x9f\xe5\xbc\x80\xe5\xa7\x8b\r\n```bash\r\npip install pandas numpy pyarrow pytdx baostock akshare tqdm\r\n\r\n# \xe8\x8a\x82\xe7\x82\xb9\xe8\xb5\x9b\xe9\xa9\xac\r\npython main_op.py --nodes\r\n\r\n# \xe9\x87\x87\xe9\x9b\x86 20 \xe5\x8f\xaa\xe6\xb5\x8b\xe8\xaf\x95\r\npython main_op.py --sample 20\r\n\r\n# \xe5\x85\xa8\xe9\x87\x8f\xe9\x87\x87\xe9\x9b\x86\r\npython main_op.py --workers 8 --ak-workers 2\r\n\r\n# \xe8\xa1\xa5\xe9\x87\x87\xe5\xa4\xb1\xe8\xb4\xa5\xe8\x82\xa1\xe7\xa5\xa8\r\npython main_op.py --retry-failed\r\n\r\n# \xe5\xbc\xba\xe5\x88\xb6\xe5\x85\xa8\xe9\x87\x8f\xe9\x87\x8d\xe4\xb8\x8b\xe8\xbd\xbd\r\npython main_op.py --full\r\n\r\n# \xe5\x8d\x95\xe5\x85\x83\xe6\xb5\x8b\xe8\xaf\x95\xef\xbc\x88T1~T8\xef\xbc\x89\r\npytest tests/test_collector.py -v\r\n```\r\n\r\n## \xe8\xbe\x93\xe5\x87\xba\xe6\x96\x87\xe4\xbb\xb6\xe8\xaf\xb4\xe6\x98\x8e\r\n```\r\ndata/\r\n\xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 parquet/\r\n\xe2\x94\x82   \xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 000001.parquet    # \xe5\x90\xab turnover/pct_change \xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5\r\n\xe2\x94\x82   \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 ...\r\n\xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 reports/\r\n    \xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 failed_stocks.txt          # \xe5\xa4\xb1\xe8\xb4\xa5\xe5\x88\x97\xe8\xa1\xa8\xef\xbc\x88\xe7\x94\xa8\xe4\xba\x8e --retry-failed\xef\xbc\x89\r\n    \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 run_stats_20260223_120000.json  # \xe5\xae\x8c\xe6\x95\xb4\xe5\xae\xa1\xe8\xae\xa1\xe6\x97\xa5\xe5\xbf\x97\r\n```\r\n\r\n## \xe5\xa4\x8d\xe6\x9d\x83\xe8\xaf\xb4\xe6\x98\x8e\r\n- **TDX**\xef\xbc\x9a`adjust="hfq"`\xef\xbc\x88\xe5\x90\x8e\xe5\xa4\x8d\xe6\x9d\x83\xef\xbc\x8c\xe9\x80\x9a\xe8\xbf\x87 `adjustflag=2` \xe5\x8f\x82\xe6\x95\xb0\xe8\xaf\xb7\xe6\xb1\x82\xef\xbc\x89\xef\xbc\x9b\xe8\x80\x81\xe8\x8a\x82\xe7\x82\xb9\xe4\xb8\x8d\xe6\x94\xaf\xe6\x8c\x81\xe6\x97\xb6\xe8\x87\xaa\xe5\x8a\xa8\xe9\x99\x8d\xe7\xba\xa7\xe5\xb9\xb6\xe6\x89\x93\xe5\x8d\xb0 WARNING\r\n- **AKShare**\xef\xbc\x9a`adjust="hfq"`\xef\xbc\x88\xe5\x90\x8e\xe5\xa4\x8d\xe6\x9d\x83\xef\xbc\x89\xef\xbc\x8c\xe7\x94\xa8\xe4\xba\x8e\xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5\xef\xbc\x88turnover \xe7\xad\x89\xef\xbc\x89  \r\n- **BaoStock**\xef\xbc\x9a`adjust="hfq"`\xef\xbc\x88\xe5\x90\x8e\xe5\xa4\x8d\xe6\x9d\x83\xef\xbc\x89\xef\xbc\x8c\xe5\x85\x9c\xe5\xba\x95\xe5\xae\x8c\xe6\x95\xb4\xe6\x95\xb0\xe6\x8d\xae\r\n- **\xe5\x90\x88\xe5\xb9\xb6\xe5\x90\x8e**\xef\xbc\x9a`adjust="hfq"`\xef\xbc\x88\xe4\xb8\x89\xe6\xba\x90\xe5\xa4\x8d\xe6\x9d\x83\xe4\xbd\x93\xe7\xb3\xbb\xe5\xae\x8c\xe5\x85\xa8\xe7\xbb\x9f\xe4\xb8\x80\xef\xbc\x8cOHLCV + \xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5\xe5\x9d\x87\xe4\xb8\xba\xe5\x90\x8e\xe5\xa4\x8d\xe6\x9d\x83\xef\xbc\x89\r\n- \xe7\x9b\xb8\xe6\xaf\x94 patch_v8\xef\xbc\x8cpatch_v9 \xe6\xb6\x88\xe9\x99\xa4\xe4\xba\x86 TDX \xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\x8e AKShare/BaoStock \xe6\x95\xb0\xe6\x8d\xae\xe9\x97\xb4\xe7\x9a\x84\xe5\xa4\x8d\xe6\x9d\x83\xe4\xb8\x8d\xe4\xb8\x80\xe8\x87\xb4\xe9\x97\xae\xe9\xa2\x98\r\n'

FILE_main_py = b'#!/usr/bin/env python3\r\n"""Q-UNITY-V7.1 \xe7\xb3\xbb\xe7\xbb\x9f\xe5\x81\xa5\xe5\xba\xb7\xe6\xa3\x80\xe6\x9f\xa5"""\r\nfrom __future__ import annotations\r\nimport json\r\nimport logging\r\nimport sys\r\nfrom pathlib import Path\r\n\r\nlogging.basicConfig(\r\n    level=logging.INFO,\r\n    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",\r\n)\r\nlogger = logging.getLogger("Q-UNITY-V7.1")\r\n\r\n\r\ndef check_dependencies() -> dict:\r\n    results = {}\r\n    deps = {\r\n        "numpy":    "import numpy; results[\'numpy\']=numpy.__version__",\r\n        "pandas":   "import pandas; results[\'pandas\']=pandas.__version__",\r\n        "scipy":    "import scipy; results[\'scipy\']=scipy.__version__",\r\n        "sklearn":  "import sklearn; results[\'sklearn\']=sklearn.__version__",\r\n        "pyarrow":  "import pyarrow; results[\'pyarrow\']=pyarrow.__version__",\r\n        "akshare":  "import akshare; results[\'akshare\']=akshare.__version__",\r\n        "baostock": "import baostock; results[\'baostock\']=\'ok\'",\r\n        "pytdx":    "from pytdx.hq import TdxHq_API; results[\'pytdx\']=\'ok\'",\r\n        "numba":    "import numba; results[\'numba\']=numba.__version__",\r\n        "tqdm":     "import tqdm; results[\'tqdm\']=tqdm.__version__",\r\n    }\r\n    for pkg, code in deps.items():\r\n        try:\r\n            exec(code, {"results": results})\r\n        except ImportError:\r\n            results[pkg] = "MISSING"\r\n        except Exception as e:\r\n            results[pkg] = f"ERROR: {e}"\r\n    return results\r\n\r\n\r\ndef check_data_dirs() -> dict:\r\n    dirs = {\r\n        "data/parquet": False, "data/cache": False,\r\n        "data/cache/fundamental": False, "data/industry": False,\r\n        "data/reports": False, "logs": False,\r\n    }\r\n    for d in dirs:\r\n        p = Path(d)\r\n        p.mkdir(parents=True, exist_ok=True)\r\n        dirs[d] = p.exists()\r\n    return dirs\r\n\r\n\r\ndef check_config() -> dict:\r\n    path = Path("config.json")\r\n    if not path.exists():\r\n        return {"status": "MISSING"}\r\n    try:\r\n        cfg = json.loads(path.read_text(encoding="utf-8"))\r\n        return {"status": "OK", "keys": list(cfg.keys())}\r\n    except Exception as e:\r\n        return {"status": f"ERROR: {e}"}\r\n\r\n\r\ndef run_health_check() -> bool:\r\n    print("=" * 60)\r\n    print("  Q-UNITY-V7.1 \xe7\xb3\xbb\xe7\xbb\x9f\xe5\x81\xa5\xe5\xba\xb7\xe6\xa3\x80\xe6\x9f\xa5")\r\n    print("=" * 60)\r\n\r\n    print("[1] \xe4\xbe\x9d\xe8\xb5\x96\xe5\x8c\x85\xe7\x8a\xb6\xe6\x80\x81:")\r\n    deps = check_dependencies()\r\n    required = {"numpy", "pandas", "scipy"}\r\n    all_ok = True\r\n    for pkg, ver in sorted(deps.items()):\r\n        status = "\xe2\x9c\x93" if ver not in ("MISSING",) and not str(ver).startswith("ERROR") else "\xe2\x9c\x97"\r\n        tag = "[\xe5\xbf\x85\xe9\x9c\x80]" if pkg in required else "[\xe5\x8f\xaf\xe9\x80\x89]"\r\n        print(f"  {status} {tag} {pkg:12s}: {ver}")\r\n        if pkg in required and status == "\xe2\x9c\x97":\r\n            all_ok = False\r\n\r\n    print("[2] \xe6\x95\xb0\xe6\x8d\xae\xe7\x9b\xae\xe5\xbd\x95:")\r\n    dirs = check_data_dirs()\r\n    for d, ok in dirs.items():\r\n        print(f"  {\'\xe2\x9c\x93\' if ok else \'\xe2\x9c\x97\'} {d}")\r\n\r\n    print("[3] \xe9\x85\x8d\xe7\xbd\xae\xe6\x96\x87\xe4\xbb\xb6:")\r\n    cfg = check_config()\r\n    print(f"  \xe7\x8a\xb6\xe6\x80\x81: {cfg.get(\'status\')}")\r\n    if "keys" in cfg:\r\n        print(f"  \xe9\x85\x8d\xe7\xbd\xae\xe9\xa1\xb9: {cfg[\'keys\']}")\r\n    try:\r\n        with open("config.json", encoding="utf-8") as f:\r\n            raw_cfg = json.load(f)\r\n        if "collector" in raw_cfg:\r\n            c = raw_cfg["collector"]\r\n            print(f"  \xe9\x87\x87\xe9\x9b\x86\xe9\x85\x8d\xe7\xbd\xae: tdx_workers={c.get(\'tdx_workers\',\'?\')} "\r\n                  f"ak_workers={c.get(\'akshare_workers\',\'?\')} "\r\n                  f"adjust={c.get(\'adjust\',\'?\')} ")\r\n    except Exception:\r\n        pass\r\n\r\n    print("[4] \xe6\xa0\xb8\xe5\xbf\x83\xe6\xa8\xa1\xe5\x9d\x97:")\r\n    modules = [\r\n        ("src.types",                    "OrderSide, Signal"),\r\n        ("src.config",                   "ConfigManager"),\r\n        ("src.engine.execution",         "BacktestEngine"),\r\n        ("src.factors.alpha_engine",     "AlphaEngine"),\r\n        ("src.risk.risk_control",        "RiskController"),\r\n        ("src.strategy.strategies",      "STRATEGY_REGISTRY"),\r\n        ("src.data.fundamental",         "FundamentalDataProvider"),\r\n        ("src.data.collector.pipeline",  "StockDataPipeline"),\r\n        ("src.data.collector.validator", "DataValidator"),\r\n        ("src.data.collector.run_report","RunReport"),\r\n    ]\r\n    for mod, items in modules:\r\n        try:\r\n            exec(f"from {mod} import {items}")\r\n            print(f"  \xe2\x9c\x93 {mod}")\r\n        except Exception as e:\r\n            print(f"  \xe2\x9c\x97 {mod}: {e}")\r\n            all_ok = False\r\n\r\n    print("[5] NB-21 \xe9\x97\xad\xe7\x8e\xaf\xe8\xa1\xa5\xe4\xb8\x81:")\r\n    try:\r\n        from src.factors.alpha_engine import AlphaEngine\r\n        import pandas as pd, numpy as np\r\n        df5 = pd.DataFrame({\r\n            "open": [10.0]*5, "high": [10.5]*5,\r\n            "low": [9.5]*5, "close": [10.0]*5, "volume": [1e6]*5,\r\n        })\r\n        result = AlphaEngine.compute_from_history(df5)\r\n        rsrs_all_nan = result["rsrs_adaptive"].isna().all()\r\n        print(f"  \xe2\x9c\x93 5\xe5\xa4\xa9\xe6\x96\xb0\xe8\x82\xa1 rsrs_adaptive \xe5\x85\xa8NaN: {rsrs_all_nan}")\r\n        if not rsrs_all_nan:\r\n            print("  \xe2\x9c\x97 NB-21 \xe8\xa1\xa5\xe4\xb8\x81\xe6\x9c\xaa\xe6\xad\xa3\xe7\xa1\xae\xe5\xb1\x8f\xe8\x94\xbd\xe6\x96\xb0\xe8\x82\xa1!")\r\n            all_ok = False\r\n    except Exception as e:\r\n        print(f"  \xe2\x9c\x97 NB-21 \xe9\xaa\x8c\xe8\xaf\x81\xe5\xa4\xb1\xe8\xb4\xa5: {e}")\r\n        all_ok = False\r\n\r\n    print("" + "=" * 60)\r\n    print(f"  \xe6\x80\xbb\xe4\xbd\x93\xe7\x8a\xb6\xe6\x80\x81: {\'\xe2\x9c\x85 \xe5\x81\xa5\xe5\xba\xb7\' if all_ok else \'\xe2\x9a\xa0\xef\xb8\x8f  \xe5\xad\x98\xe5\x9c\xa8\xe9\x97\xae\xe9\xa2\x98\'}")\r\n    print("=" * 60)\r\n    return all_ok\r\n\r\n\r\nif __name__ == "__main__":\r\n    ok = run_health_check()\r\n    if not ok:\r\n        print("\xe6\x8f\x90\xe7\xa4\xba: \xe8\xbf\x90\xe8\xa1\x8c pip install -r requirements.txt \xe5\xae\x89\xe8\xa3\x85\xe7\xbc\xba\xe5\xa4\xb1\xe4\xbe\x9d\xe8\xb5\x96")\r\n    sys.exit(0 if ok else 1)\r\n'

FILE_main_op_py = b'#!/usr/bin/env python3\r\n# -*- coding: utf-8 -*-\r\n"""\r\nmain_op.py \xe2\x80\x94 Q-UNITY-V6-op \xe5\x8f\x8c\xe8\xbd\xa8\xe9\x87\x87\xe9\x9b\x86\xe5\xbc\x95\xe6\x93\x8e CLI (patch_v9)\r\n========================================================\r\n\xe4\xbd\xbf\xe7\x94\xa8\xe6\x96\xb9\xe6\xb3\x95:\r\n    python main_op.py --nodes              # \xe8\x8a\x82\xe7\x82\xb9\xe8\xb5\x9b\xe9\xa9\xac\xe6\xb5\x8b\xe8\xaf\x95\r\n    python main_op.py --sample 20          # \xe6\xb5\x8b\xe8\xaf\x95\xe5\x89\x8d 20 \xe5\x8f\xaa\r\n    python main_op.py --code 000001 0      # \xe5\x8d\x95\xe5\x8f\xaa\xe8\x82\xa1\xe7\xa5\xa8\r\n    python main_op.py                      # \xe5\x85\xa8\xe9\x87\x8f\xe9\x87\x87\xe9\x9b\x86\r\n    python main_op.py --full               # \xe5\xbc\xba\xe5\x88\xb6\xe5\x85\xa8\xe9\x87\x8f\xe9\x87\x8d\xe4\xb8\x8b\xe8\xbd\xbd\r\n    python main_op.py --retry-failed       # \xe8\xa1\xa5\xe9\x87\x87\xe5\xa4\xb1\xe8\xb4\xa5\xe8\x82\xa1\xe7\xa5\xa8\r\n    python main_op.py --workers 8          # \xe6\x8c\x87\xe5\xae\x9a TDX \xe7\xba\xbf\xe7\xa8\x8b\xe6\x95\xb0\r\n    python main_op.py --ak-workers 2       # \xe6\x8c\x87\xe5\xae\x9a AKShare \xe8\xbf\x9b\xe7\xa8\x8b\xe6\x95\xb0\r\n"""\r\n\r\nimport argparse\r\nimport logging\r\nimport sys\r\nfrom pathlib import Path\r\n\r\nlogging.basicConfig(\r\n    level=logging.INFO,\r\n    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",\r\n    datefmt="%Y-%m-%d %H:%M:%S",\r\n)\r\nlogger = logging.getLogger("main_op")\r\n\r\n\r\ndef cmd_node_race() -> None:\r\n    from src.data.collector.node_scanner import race_nodes, TDX_NODES\r\n    print(f"\\n{\'=\'*62}")\r\n    print(f"TDX \xe8\x8a\x82\xe7\x82\xb9\xe8\xb5\x9b\xe9\xa9\xac\xe6\xb5\x8b\xe8\xaf\x95 ({len(TDX_NODES)} \xe4\xb8\xaa\xe5\x80\x99\xe9\x80\x89\xe8\x8a\x82\xe7\x82\xb9)")\r\n    print(f"{\'=\'*62}")\r\n    results = race_nodes(timeout=3.0)\r\n    for i, r in enumerate(results, 1):\r\n        icon    = "\xe2\x9c\x93" if r["status"] == "ok" else "\xe2\x9c\x97"\r\n        lat_str = f"{r[\'latency_ms\']:>7.2f} ms" if r["latency_ms"] >= 0 else "  timeout"\r\n        print(f"  {i:>2}. {icon} {r[\'name\']:<10} {r[\'host\']:>18}:{r[\'port\']}  {lat_str}")\r\n    ok = [r for r in results if r["status"] == "ok"]\r\n    print(f"\\n\xe5\x8f\xaf\xe8\xbe\xbe: {len(ok)}/{len(results)} | "\r\n          f"\xe6\x9c\x80\xe4\xbc\x98: {ok[0][\'name\']} ({ok[0][\'host\']}) \xe2\x80\x94 {ok[0][\'latency_ms\']:.2f}ms" if ok else "\xe6\x97\xa0\xe5\x8f\xaf\xe8\xbe\xbe\xe8\x8a\x82\xe7\x82\xb9")\r\n    print()\r\n\r\n\r\ndef _make_pipeline(args) -> "StockDataPipeline":\r\n    from src.data.collector.pipeline import StockDataPipeline\r\n    return StockDataPipeline(\r\n        parquet_dir=args.output,\r\n        reports_dir=args.reports,\r\n        top_n_nodes=5,\r\n        tdx_workers=args.workers,\r\n        ak_workers=args.ak_workers,\r\n        force_full=args.full,\r\n    )\r\n\r\n\r\ndef cmd_collect(args) -> None:\r\n    pipeline   = _make_pipeline(args)\r\n    stock_list = pipeline._get_all_a_stock_list()\r\n    if not stock_list:\r\n        logger.error("\xe8\x8e\xb7\xe5\x8f\x96\xe8\x82\xa1\xe7\xa5\xa8\xe5\x88\x97\xe8\xa1\xa8\xe5\xa4\xb1\xe8\xb4\xa5\xef\xbc\x8c\xe9\x80\x80\xe5\x87\xba")\r\n        sys.exit(1)\r\n    logger.info("\xe5\x85\xb1 %d \xe5\x8f\xaa A \xe8\x82\xa1", len(stock_list))\r\n    if args.sample > 0:\r\n        stock_list = stock_list[:args.sample]\r\n        logger.info("Sample \xe6\xa8\xa1\xe5\xbc\x8f: \xe5\x89\x8d %d \xe5\x8f\xaa", len(stock_list))\r\n    stats = pipeline.run(stock_list)\r\n    _print_stats(stats)\r\n\r\n\r\ndef cmd_retry_failed(args) -> None:\r\n    pipeline = _make_pipeline(args)\r\n    stats    = pipeline.retry_failed(reports_dir=args.reports)\r\n    _print_stats(stats)\r\n\r\n\r\ndef cmd_single(args) -> None:\r\n    import pandas as pd\r\n    from src.data.collector.pipeline import StockDataPipeline, update_single_stock\r\n    from src.data.collector.run_report import RunReport\r\n    from pathlib import Path\r\n\r\n    pipeline   = _make_pipeline(args)\r\n    report     = RunReport(args.reports)\r\n    code, mkt  = args.code[0], int(args.code[1])\r\n\r\n    # AKShare \xe5\x8d\x95\xe8\x82\xa1\r\n    from src.data.collector.akshare_client import fetch_akshare_single\r\n    from src.data.collector.incremental import compute_missing_range, read_local_max_date\r\n    from datetime import date\r\n    parquet_path = Path(args.output) / f"{code}.parquet"\r\n    local_max    = read_local_max_date(parquet_path)\r\n    start, end   = compute_missing_range(local_max, date.today().strftime("%Y-%m-%d"))\r\n    ak_df        = fetch_akshare_single(code, start, end)\r\n    ak_results   = {code: ak_df}\r\n\r\n    _, ok, source = update_single_stock(\r\n        code=code, market=mkt,\r\n        parquet_dir=Path(args.output),\r\n        tdx_pool=pipeline.tdx_pool,\r\n        ak_results=ak_results,\r\n        report=report,\r\n        force_full=True,\r\n    )\r\n    report.save()\r\n\r\n    if ok:\r\n        df = pd.read_parquet(parquet_path)\r\n        print(f"\\n\xe2\x9c\x93 {code} \xe9\x87\x87\xe9\x9b\x86\xe6\x88\x90\xe5\x8a\x9f (\xe6\x9d\xa5\xe6\xba\x90: {source})")\r\n        print(f"  \xe8\xa1\x8c\xe6\x95\xb0: {len(df)} | \xe6\x97\xa5\xe6\x9c\x9f: {df[\'date\'].min()} ~ {df[\'date\'].max()}")\r\n        # \xe6\x98\xbe\xe7\xa4\xba\xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5\r\n        ext = [c for c in ("turnover", "pct_change") if c in df.columns]\r\n        if ext:\r\n            print(f"  \xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5: {ext}")\r\n        print(df.tail(5).to_string(index=False))\r\n    else:\r\n        print(f"\\n\xe2\x9c\x97 {code} \xe9\x87\x87\xe9\x9b\x86\xe5\xa4\xb1\xe8\xb4\xa5\xef\xbc\x88\xe8\xaf\xa6\xe8\xa7\x81 {args.reports}/run_stats_*.json\xef\xbc\x89")\r\n\r\n\r\ndef _print_stats(stats: dict) -> None:\r\n    print(f"\\n{\'=\'*60}")\r\n    print("\xe9\x87\x87\xe9\x9b\x86\xe5\xae\x8c\xe6\x88\x90\xe7\xbb\x9f\xe8\xae\xa1")\r\n    print(f"{\'=\'*60}")\r\n    print(f"  \xe6\x80\xbb\xe8\xae\xa1:    {stats.get(\'total\', 0):>6} \xe5\x8f\xaa")\r\n    print(f"  \xe6\x88\x90\xe5\x8a\x9f:    {stats.get(\'success\', 0):>6} \xe5\x8f\xaa")\r\n    print(f"  \xe5\xa4\xb1\xe8\xb4\xa5:    {stats.get(\'failed\', 0):>6} \xe5\x8f\xaa")\r\n    print(f"  \xe8\xb7\xb3\xe8\xbf\x87:    {stats.get(\'skipped\', 0):>6} \xe5\x8f\xaa\xef\xbc\x88\xe5\xb7\xb2\xe6\x9c\x80\xe6\x96\xb0\xef\xbc\x89")\r\n    print(f"  \xe8\x80\x97\xe6\x97\xb6:    {stats.get(\'elapsed_s\', 0):>6.1f} \xe7\xa7\x92")\r\n    print(f"  \xe9\x80\x9f\xe5\xba\xa6:    {stats.get(\'speed\', 0):>6.1f} \xe8\x82\xa1/\xe7\xa7\x92")\r\n    print(f"  \xe6\x8a\xa5\xe5\x91\x8a\xe7\x9b\xae\xe5\xbd\x95: {stats.get(\'reports_dir\', \'N/A\')}")\r\n    print(f"{\'=\'*60}\\n")\r\n\r\n\r\ndef main() -> None:\r\n    parser = argparse.ArgumentParser(description="Q-UNITY-V6-op \xe5\x8f\x8c\xe8\xbd\xa8\xe9\x87\x87\xe9\x9b\x86\xe5\xbc\x95\xe6\x93\x8e (patch_v9)")\r\n    parser.add_argument("--nodes",        action="store_true", help="\xe8\x8a\x82\xe7\x82\xb9\xe8\xb5\x9b\xe9\xa9\xac\xe6\xb5\x8b\xe8\xaf\x95")\r\n    parser.add_argument("--sample",       type=int, default=0,  help="\xe4\xbb\x85\xe9\x87\x87\xe9\x9b\x86\xe5\x89\x8d N \xe5\x8f\xaa\xef\xbc\x88\xe6\xb5\x8b\xe8\xaf\x95\xef\xbc\x89")\r\n    parser.add_argument("--full",         action="store_true",  help="\xe5\xbc\xba\xe5\x88\xb6\xe5\x85\xa8\xe9\x87\x8f\xe9\x87\x8d\xe4\xb8\x8b\xe8\xbd\xbd")\r\n    parser.add_argument("--retry-failed", action="store_true",  help="\xe8\xa1\xa5\xe9\x87\x87\xe5\xa4\xb1\xe8\xb4\xa5\xe8\x82\xa1\xe7\xa5\xa8")\r\n    parser.add_argument("--workers",      type=int, default=8,  help="TDX \xe7\xba\xbf\xe7\xa8\x8b\xe6\x95\xb0\xef\xbc\x88\xe9\xbb\x98\xe8\xae\xa4 8\xef\xbc\x89")\r\n    parser.add_argument("--ak-workers",   type=int, default=2,  help="AKShare \xe8\xbf\x9b\xe7\xa8\x8b\xe6\x95\xb0\xef\xbc\x88\xe9\xbb\x98\xe8\xae\xa4 2\xef\xbc\x89")\r\n    parser.add_argument("--output",       type=str, default="./data/parquet", help="Parquet \xe7\x9b\xae\xe5\xbd\x95")\r\n    parser.add_argument("--reports",      type=str, default="./data/reports", help="\xe6\x8a\xa5\xe5\x91\x8a\xe7\x9b\xae\xe5\xbd\x95")\r\n    parser.add_argument("--code",         type=str, nargs=2,    help="\xe5\x8d\x95\xe8\x82\xa1: --code 000001 0")\r\n    args = parser.parse_args()\r\n\r\n    if args.nodes:\r\n        cmd_node_race()\r\n    elif args.code:\r\n        cmd_single(args)\r\n    elif args.retry_failed:\r\n        cmd_retry_failed(args)\r\n    else:\r\n        cmd_collect(args)\r\n\r\n\r\nif __name__ == "__main__":\r\n    main()\r\n'

FILE_menu_main_py = b'#!/usr/bin/env python3\r\n"""\r\nQ-UNITY-V7.1 \xe4\xb8\xbb\xe8\x8f\x9c\xe5\x8d\x95\xe7\xb3\xbb\xe7\xbb\x9f\r\n\r\n\xe3\x80\x90V7.1 \xe6\x95\xb0\xe6\x8d\xae\xe7\xae\xa1\xe7\x90\x86\xe4\xbf\xae\xe5\xa4\x8d\xe8\xaf\xb4\xe6\x98\x8e\xe3\x80\x91\r\n\xe5\x8e\x9f op-v3 \xe9\x98\xb6\xe6\xae\xb5\xe9\xa1\xba\xe5\xba\x8f\xe7\xbc\xba\xe9\x99\xb7:\r\n  AKShare\xe5\x85\xa8\xe9\x87\x8f(5190\xe5\x8f\xaa\xc3\x977s/2\xe8\xbf\x9b\xe7\xa8\x8b = 5+\xe5\xb0\x8f\xe6\x97\xb6) \xe2\x86\x92 TDX\xef\xbc\x88\xe6\xb2\xa1\xe6\x9c\x89\xe9\x80\x9f\xe5\xba\xa6\xef\xbc\x81pytdx \xe6\xa0\xb9\xe6\x9c\xac\xe6\x9c\xaa\xe8\xa2\xab\xe8\xb0\x83\xe7\x94\xa8\xef\xbc\x89\r\n\r\nV7.1 \xe4\xbf\xae\xe5\xa4\x8d:\r\n  \xe9\x80\x89\xe9\xa1\xb91: TDX \xe5\xbf\xab\xe9\x80\x9f\xe5\x85\xa8\xe9\x87\x8f\xe9\x87\x87\xe9\x9b\x86  \xe2\x80\x94 \xe4\xbb\x85 TDX \xe5\x90\x8e\xe5\xa4\x8d\xe6\x9d\x83\xef\xbc\x8c8\xe7\xba\xbf\xe7\xa8\x8b\xef\xbc\x8c~30\xe5\x88\x86\xe9\x92\x9f\xef\xbc\x8c\xe7\xab\x8b\xe5\x8d\xb3\xe5\x8f\xaf\xe7\x94\xa8\r\n  \xe9\x80\x89\xe9\xa1\xb92: AKShare \xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5  \xe2\x80\x94 \xe5\xaf\xb9\xe5\xb7\xb2\xe9\x87\x87\xe9\x9b\x86\xe6\x95\xb0\xe6\x8d\xae\xe8\xa1\xa5\xe5\x85\x85 turnover/pct_change\xef\xbc\x88\xe7\x8b\xac\xe7\xab\x8b\xe6\xad\xa5\xe9\xaa\xa4\xef\xbc\x89\r\n  \xe9\x80\x89\xe9\xa1\xb93: \xe5\xa2\x9e\xe9\x87\x8f\xe6\x9b\xb4\xe6\x96\xb0          \xe2\x80\x94 TDX \xe5\xbf\xab\xe9\x80\x9f\xe5\xa2\x9e\xe9\x87\x8f\r\n  \xe9\x80\x89\xe9\xa1\xb94: \xe8\xa1\xa5\xe9\x87\x87\xe5\xa4\xb1\xe8\xb4\xa5\xe8\x82\xa1\xe7\xa5\xa8\r\n"""\r\nfrom __future__ import annotations\r\nimport json\r\nimport logging\r\nimport socket\r\nimport sys\r\nimport time\r\nfrom pathlib import Path\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\ndef _check_data_source_heartbeat() -> None:\r\n    print("" + "\xe2\x94\x80" * 50)\r\n    print("  \xe6\x95\xb0\xe6\x8d\xae\xe6\xba\x90\xe5\xbf\x83\xe8\xb7\xb3\xe6\xa3\x80\xe6\xb5\x8b")\r\n    print("\xe2\x94\x80" * 50)\r\n\r\n    print("[1] AKShare:")\r\n    try:\r\n        import akshare as ak\r\n        t0 = time.time()\r\n        df = ak.stock_zh_index_spot_em(symbol="\xe4\xb8\x8a\xe8\xaf\x81\xe6\x8c\x87\xe6\x95\xb0")\r\n        elapsed = time.time() - t0\r\n        if df is not None and not df.empty:\r\n            print(f"  \xe2\x9c\x93 \xe8\xbf\x9e\xe9\x80\x9a\xe6\xad\xa3\xe5\xb8\xb8 ({elapsed:.2f}s)")\r\n        else:\r\n            print(f"  \xe2\x9c\x97 \xe8\xbf\x94\xe5\x9b\x9e\xe7\xa9\xba\xe6\x95\xb0\xe6\x8d\xae ({elapsed:.2f}s)")\r\n    except ImportError:\r\n        print("  \xe2\x9c\x97 akshare \xe6\x9c\xaa\xe5\xae\x89\xe8\xa3\x85")\r\n    except Exception as e:\r\n        print(f"  \xe2\x9c\x97 \xe5\xbc\x82\xe5\xb8\xb8: {e}")\r\n\r\n    print("[2] TDX \xe8\x8a\x82\xe7\x82\xb9\xef\xbc\x88\xe5\x89\x8d5\xe4\xbc\x98\xe9\x80\x89\xef\xbc\x89:")\r\n    try:\r\n        from src.data.collector.node_scanner import get_fastest_nodes\r\n        nodes = get_fastest_nodes(top_n=5, timeout=3.0)\r\n        for n in nodes:\r\n            icon = "\xe2\x9c\x93" if n["status"] == "ok" else "\xe2\x9c\x97"\r\n            lat  = f"{n[\'latency_ms\']:.0f}ms" if n["latency_ms"] >= 0 else "timeout"\r\n            print(f"  {icon} {n[\'name\']} {n[\'host\']}:{n[\'port\']}  {lat}")\r\n    except Exception as e:\r\n        print(f"  \xe2\x9c\x97 \xe8\x8a\x82\xe7\x82\xb9\xe6\x89\xab\xe6\x8f\x8f\xe5\xa4\xb1\xe8\xb4\xa5: {e}")\r\n\r\n    print("[3] BaoStock:")\r\n    try:\r\n        import baostock as bs\r\n        t0 = time.time()\r\n        lg = bs.login()\r\n        elapsed = time.time() - t0\r\n        if lg.error_code == "0":\r\n            print(f"  \xe2\x9c\x93 \xe7\x99\xbb\xe5\xbd\x95\xe6\x88\x90\xe5\x8a\x9f ({elapsed:.2f}s)")\r\n            bs.logout()\r\n        else:\r\n            print(f"  \xe2\x9c\x97 \xe7\x99\xbb\xe5\xbd\x95\xe5\xa4\xb1\xe8\xb4\xa5: {lg.error_msg}")\r\n    except ImportError:\r\n        print("  \xe2\x9c\x97 baostock \xe6\x9c\xaa\xe5\xae\x89\xe8\xa3\x85")\r\n    except Exception as e:\r\n        print(f"  \xe2\x9c\x97 \xe5\xbc\x82\xe5\xb8\xb8: {e}")\r\n\r\n    print("[4] Tushare (DNS):")\r\n    try:\r\n        t0 = time.time()\r\n        ip = socket.gethostbyname("api.tushare.pro")\r\n        elapsed = time.time() - t0\r\n        print(f"  \xe2\x9c\x93 DNS \xe8\xa7\xa3\xe6\x9e\x90\xe6\xad\xa3\xe5\xb8\xb8 \xe2\x86\x92 {ip} ({elapsed*1000:.0f}ms)")\r\n    except socket.gaierror as e:\r\n        print(f"  \xe2\x9c\x97 DNS \xe8\xa7\xa3\xe6\x9e\x90\xe5\xa4\xb1\xe8\xb4\xa5: {e}")\r\n\r\n    print("" + "\xe2\x94\x80" * 50)\r\n    input("\xe6\x8c\x89 Enter \xe8\xbf\x94\xe5\x9b\x9e...")\r\n\r\n\r\ndef _load_collector_config() -> dict:\r\n    defaults = {\r\n        "parquet_dir":    "./data/parquet",\r\n        "reports_dir":    "./data/reports",\r\n        "top_n_nodes":    5,\r\n        "tdx_workers":    8,\r\n        "ak_workers":     2,\r\n        "ak_delay_min":   0.3,\r\n        "ak_delay_max":   0.8,\r\n        "ak_max_retries": 3,\r\n    }\r\n    try:\r\n        cfg_path = Path("config.json")\r\n        if cfg_path.exists():\r\n            raw = json.loads(cfg_path.read_text(encoding="utf-8"))\r\n            c = raw.get("collector", {})\r\n            d = raw.get("data", {})\r\n            defaults.update({\r\n                "parquet_dir":    d.get("parquet_dir",         defaults["parquet_dir"]),\r\n                "reports_dir":    d.get("reports_dir",         defaults["reports_dir"]),\r\n                "top_n_nodes":    c.get("tdx_top_nodes",       defaults["top_n_nodes"]),\r\n                "tdx_workers":    c.get("tdx_workers",         defaults["tdx_workers"]),\r\n                "ak_workers":     c.get("akshare_workers",     defaults["ak_workers"]),\r\n                "ak_delay_min":   c.get("akshare_delay_min",   defaults["ak_delay_min"]),\r\n                "ak_delay_max":   c.get("akshare_delay_max",   defaults["ak_delay_max"]),\r\n                "ak_max_retries": c.get("akshare_max_retries", defaults["ak_max_retries"]),\r\n            })\r\n    except Exception:\r\n        pass\r\n    return defaults\r\n\r\n\r\ndef _make_pipeline(force_full: bool = False, enable_akshare: bool = False):\r\n    from src.data.collector.pipeline import StockDataPipeline\r\n    cfg = _load_collector_config()\r\n    return StockDataPipeline(\r\n        parquet_dir=cfg["parquet_dir"],\r\n        reports_dir=cfg["reports_dir"],\r\n        top_n_nodes=cfg["top_n_nodes"],\r\n        tdx_workers=cfg["tdx_workers"],\r\n        ak_workers=cfg["ak_workers"],\r\n        ak_delay_min=cfg["ak_delay_min"],\r\n        ak_delay_max=cfg["ak_delay_max"],\r\n        ak_max_retries=cfg["ak_max_retries"],\r\n        force_full=force_full,\r\n        enable_akshare=enable_akshare,\r\n    )\r\n\r\n\r\ndef _print_stats(stats: dict) -> None:\r\n    mode = "\xe5\x8f\x8c\xe8\xbd\xa8(TDX+AKShare)" if stats.get("akshare_enabled") else "\xe5\xbf\xab\xe9\x80\x9f(\xe4\xbb\x85TDX)"\r\n    print(f"{\'=\'*54}")\r\n    print(f"  \xe9\x87\x87\xe9\x9b\x86\xe5\xae\x8c\xe6\x88\x90  [{mode}]")\r\n    print(f"{\'=\'*54}")\r\n    print(f"  \xe6\x80\xbb\xe8\xae\xa1:   {stats.get(\'total\',   0):>6} \xe5\x8f\xaa")\r\n    print(f"  \xe6\x88\x90\xe5\x8a\x9f:   {stats.get(\'success\', 0):>6} \xe5\x8f\xaa")\r\n    print(f"  \xe5\xa4\xb1\xe8\xb4\xa5:   {stats.get(\'failed\',  0):>6} \xe5\x8f\xaa")\r\n    print(f"  \xe8\xb7\xb3\xe8\xbf\x87:   {stats.get(\'skipped\', 0):>6} \xe5\x8f\xaa\xef\xbc\x88\xe5\xb7\xb2\xe6\x9c\x80\xe6\x96\xb0\xef\xbc\x89")\r\n    print(f"  \xe8\x80\x97\xe6\x97\xb6:   {stats.get(\'elapsed_s\', 0):>6.1f} \xe7\xa7\x92")\r\n    print(f"  \xe9\x80\x9f\xe5\xba\xa6:   {stats.get(\'speed\',    0):>6.1f} \xe8\x82\xa1/\xe7\xa7\x92")\r\n    print(f"  \xe6\x8a\xa5\xe5\x91\x8a:   {stats.get(\'reports_dir\', \'N/A\')}")\r\n    print(f"{\'=\'*54}")\r\n\r\n\r\ndef data_management_menu(config=None, storage=None) -> None:\r\n    while True:\r\n        print("" + "\xe2\x95\x90" * 56)\r\n        print("  \xe6\x95\xb0\xe6\x8d\xae\xe7\xae\xa1\xe7\x90\x86  (V7.1 TDX\xe5\xbf\xab\xe9\x80\x9f + AKShare\xe5\x8f\xaf\xe9\x80\x89\xe6\x89\xa9\xe5\xb1\x95)")\r\n        print("\xe2\x95\x90" * 56)\r\n        print("  1. TDX \xe5\xbf\xab\xe9\x80\x9f\xe5\x85\xa8\xe9\x87\x8f\xe9\x87\x87\xe9\x9b\x86   (~30min\xef\xbc\x8cHFQ\xef\xbc\x8c\xe6\x97\xa0\xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5)")\r\n        print("  2. AKShare \xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5\xe8\xa1\xa5\xe5\x85\x85 (turnover/pct_change\xef\xbc\x8c\xe7\x8b\xac\xe7\xab\x8b\xe6\xad\xa5\xe9\xaa\xa4)")\r\n        print("  3. \xe5\xa2\x9e\xe9\x87\x8f\xe6\x95\xb0\xe6\x8d\xae\xe6\x9b\xb4\xe6\x96\xb0        (\xe4\xbb\x85\xe8\xa1\xa5\xe9\x87\x87\xe7\xbc\xba\xe5\xa4\xb1\xe6\x97\xa5\xe6\x9c\x9f)")\r\n        print("  4. \xe8\xa1\xa5\xe9\x87\x87\xe5\xa4\xb1\xe8\xb4\xa5\xe8\x82\xa1\xe7\xa5\xa8        (failed_stocks.txt)")\r\n        print("  5. \xe6\x95\xb0\xe6\x8d\xae\xe5\xae\x8c\xe6\x95\xb4\xe6\x80\xa7\xe6\xa3\x80\xe6\x9f\xa5")\r\n        print("  6. \xe8\x8a\x82\xe7\x82\xb9\xe8\xb5\x9b\xe9\xa9\xac\xe6\xb5\x8b\xe8\xaf\x95")\r\n        print("  7. \xe6\xb8\x85\xe7\x90\x86\xe7\xbc\x93\xe5\xad\x98")\r\n        print("  0. \xe8\xbf\x94\xe5\x9b\x9e\xe4\xb8\xbb\xe8\x8f\x9c\xe5\x8d\x95")\r\n        print()\r\n        print("  \xe2\x84\xb9  \xe5\xae\x8c\xe6\x95\xb4\xe5\xb7\xa5\xe4\xbd\x9c\xe6\xb5\x81: \xe5\x85\x88\xe9\x80\x891(~30min) \xe2\x86\x92 \xe5\x86\x8d\xe9\x80\x892(\xe5\x8f\xaf\xe9\x80\x89,~2~4h)")\r\n        choice = input("\xe8\xaf\xb7\xe9\x80\x89\xe6\x8b\xa9 [0-7]: ").strip()\r\n\r\n        if choice == "0":\r\n            break\r\n        elif choice == "1":\r\n            _cmd_tdx_fast_collect()\r\n        elif choice == "2":\r\n            _cmd_enrich_akshare()\r\n        elif choice == "3":\r\n            _cmd_incremental_update()\r\n        elif choice == "4":\r\n            _cmd_retry_failed()\r\n        elif choice == "5":\r\n            _cmd_check_integrity(storage)\r\n        elif choice == "6":\r\n            _cmd_node_race()\r\n        elif choice == "7":\r\n            _cmd_clean_cache()\r\n        else:\r\n            print("  \xe2\x9c\x97 \xe6\x97\xa0\xe6\x95\x88\xe9\x80\x89\xe9\xa1\xb9")\r\n\r\n\r\ndef _cmd_tdx_fast_collect() -> None:\r\n    print("\xe2\x9a\xa1 TDX \xe5\xbf\xab\xe9\x80\x9f\xe5\x85\xa8\xe9\x87\x8f\xe9\x87\x87\xe9\x9b\x86\xef\xbc\x88\xe4\xbb\x85 TDX\xef\xbc\x8c\xe5\x90\x8e\xe5\xa4\x8d\xe6\x9d\x83 HFQ\xef\xbc\x89")\r\n    print("  \xe6\xa8\xa1\xe5\xbc\x8f: TDX 8\xe7\xba\xbf\xe7\xa8\x8b\xe5\xb9\xb6\xe5\x8f\x91\xef\xbc\x8c\xe4\xb8\x8d\xe5\x90\xaf\xe5\x8a\xa8 AKShare \xe8\xbf\x9b\xe7\xa8\x8b")\r\n    print("  \xe9\xa2\x84\xe8\xae\xa1: 5000+ \xe5\x8f\xaa A \xe8\x82\xa1\xe7\xba\xa6 20~40 \xe5\x88\x86\xe9\x92\x9f")\r\n    print("  \xe5\xad\x97\xe6\xae\xb5: open/high/low/close/vol/amount\xef\xbc\x88\xe4\xb8\x8d\xe5\x90\xab turnover/pct_change\xef\xbc\x89")\r\n    print("  \xe5\x90\x8e\xe7\xbb\xad: \xe5\xa6\x82\xe9\x9c\x80\xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5\xef\xbc\x8c\xe5\xae\x8c\xe6\x88\x90\xe5\x90\x8e\xe9\x80\x89\xe3\x80\x8c\xe9\x80\x89\xe9\xa1\xb92\xe3\x80\x8d\xe5\x8d\x95\xe7\x8b\xac\xe8\xa1\xa5\xe5\x85\x85")\r\n    confirm = input("  \xe7\xa1\xae\xe8\xae\xa4\xe5\xbc\x80\xe5\xa7\x8b? [y/N]: ").strip().lower()\r\n    if confirm != "y":\r\n        print("  \xe5\xb7\xb2\xe5\x8f\x96\xe6\xb6\x88\xe3\x80\x82")\r\n        return\r\n    try:\r\n        pipeline = _make_pipeline(force_full=True, enable_akshare=False)\r\n        stats = pipeline.download_all_a_stocks()\r\n        _print_stats(stats)\r\n    except ImportError as e:\r\n        print(f"  \xe2\x9c\x97 \xe5\xaf\xbc\xe5\x85\xa5\xe5\xa4\xb1\xe8\xb4\xa5: {e}")\r\n    except Exception as e:\r\n        logger.exception("TDX \xe5\xbf\xab\xe9\x80\x9f\xe9\x87\x87\xe9\x9b\x86\xe5\xbc\x82\xe5\xb8\xb8")\r\n        print(f"  \xe2\x9c\x97 \xe5\xa4\xb1\xe8\xb4\xa5: {e}")\r\n\r\n\r\ndef _cmd_enrich_akshare() -> None:\r\n    print("\xf0\x9f\x94\xac AKShare \xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5\xe8\xa1\xa5\xe5\x85\x85\xef\xbc\x88\xe7\x8b\xac\xe7\xab\x8b\xe6\xad\xa5\xe9\xaa\xa4\xef\xbc\x89")\r\n    print("  \xe8\xaf\xb4\xe6\x98\x8e: \xe5\xaf\xb9\xe5\xb7\xb2\xe6\x9c\x89 Parquet \xe6\x96\x87\xe4\xbb\xb6\xe8\xa1\xa5\xe5\x85\x85 turnover\xe3\x80\x81pct_change\xe3\x80\x81amplitude \xe5\xad\x97\xe6\xae\xb5")\r\n    print("  \xe6\xa8\xa1\xe5\xbc\x8f: \xe8\xbf\x9b\xe7\xa8\x8b\xe9\x9a\x94\xe7\xa6\xbb\xef\xbc\x882\xe8\xbf\x9b\xe7\xa8\x8b\xef\xbc\x89\xef\xbc\x8c\xe5\x8c\x85\xe5\x90\xab\xe9\x99\x90\xe6\xb5\x81\xe6\x84\x9f\xe7\x9f\xa5\xe9\x80\x80\xe9\x81\xbf\xef\xbc\x8830/60/90s\xef\xbc\x89")\r\n    print("  \xe9\xa2\x84\xe8\xae\xa1: 5000\xe5\x8f\xaa\xe7\xba\xa6 2~4 \xe5\xb0\x8f\xe6\x97\xb6\xef\xbc\x88\xe5\x8f\x97\xe4\xb8\x9c\xe6\x96\xb9\xe8\xb4\xa2\xe5\xaf\x8c\xe6\x8e\xa5\xe5\x8f\xa3\xe9\x99\x90\xe6\xb5\x81\xe5\xbd\xb1\xe5\x93\x8d\xef\xbc\x89")\r\n    print("  \xe5\x89\x8d\xe6\x8f\x90: \xe8\xaf\xb7\xe5\x85\x88\xe5\xae\x8c\xe6\x88\x90\xe3\x80\x8c\xe9\x80\x89\xe9\xa1\xb91: TDX \xe5\xbf\xab\xe9\x80\x9f\xe5\x85\xa8\xe9\x87\x8f\xe9\x87\x87\xe9\x9b\x86\xe3\x80\x8d")\r\n\r\n    cfg = _load_collector_config()\r\n    parquet_dir = Path(cfg["parquet_dir"])\r\n    existing = list(parquet_dir.glob("*.parquet"))\r\n    if not existing:\r\n        print(f"  \xe2\x9c\x97 Parquet \xe7\x9b\xae\xe5\xbd\x95\xe4\xb8\xba\xe7\xa9\xba: {parquet_dir}")\r\n        print("  \xe8\xaf\xb7\xe5\x85\x88\xe6\x89\xa7\xe8\xa1\x8c\xe3\x80\x8c\xe9\x80\x89\xe9\xa1\xb91: TDX \xe5\xbf\xab\xe9\x80\x9f\xe5\x85\xa8\xe9\x87\x8f\xe9\x87\x87\xe9\x9b\x86\xe3\x80\x8d\xe3\x80\x82")\r\n        return\r\n\r\n    print(f"  \xe5\xbd\x93\xe5\x89\x8d\xe6\x9c\xac\xe5\x9c\xb0 Parquet: {len(existing)} \xe5\x8f\xaa")\r\n    # \xe5\xbf\xab\xe9\x80\x9f\xe6\x8a\xbd\xe6\xa0\xb7\xe6\xa3\x80\xe6\x9f\xa5\xe6\x98\xaf\xe5\x90\xa6\xe5\xb7\xb2\xe6\x9c\x89\xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5\r\n    import pandas as pd\r\n    has_ext = no_ext = 0\r\n    for f in existing[:30]:\r\n        try:\r\n            cols = pd.read_parquet(f).columns.tolist()\r\n            if "turnover" in cols:\r\n                has_ext += 1\r\n            else:\r\n                no_ext += 1\r\n        except Exception:\r\n            no_ext += 1\r\n    print(f"  \xe6\x8a\xbd\xe6\xa0\xb7\xef\xbc\x88\xe5\x89\x8d30\xe5\x8f\xaa\xef\xbc\x89: {has_ext} \xe5\x8f\xaa\xe5\xb7\xb2\xe6\x9c\x89 turnover\xef\xbc\x8c{no_ext} \xe5\x8f\xaa\xe6\x9c\xaa\xe5\x90\xab\xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5")\r\n\r\n    confirm = input("  \xe7\xa1\xae\xe8\xae\xa4\xe5\xbc\x80\xe5\xa7\x8b? [y/N]: ").strip().lower()\r\n    if confirm != "y":\r\n        print("  \xe5\xb7\xb2\xe5\x8f\x96\xe6\xb6\x88\xe3\x80\x82")\r\n        return\r\n    try:\r\n        pipeline = _make_pipeline(force_full=False, enable_akshare=True)\r\n        stats = pipeline.enrich_akshare()\r\n        print(f"  \xe2\x9c\x93 \xe5\xae\x8c\xe6\x88\x90: \xe5\xa4\x84\xe7\x90\x86 {stats.get(\'total\',0)} \xe5\x8f\xaa\xef\xbc\x8c"\r\n              f"\xe6\x88\x90\xe5\x8a\x9f {stats.get(\'success\',0)} \xe5\x8f\xaa\xef\xbc\x8c\xe5\xa4\xb1\xe8\xb4\xa5 {stats.get(\'failed\',0)} \xe5\x8f\xaa")\r\n    except ImportError as e:\r\n        print(f"  \xe2\x9c\x97 \xe5\xaf\xbc\xe5\x85\xa5\xe5\xa4\xb1\xe8\xb4\xa5: {e}")\r\n    except Exception as e:\r\n        logger.exception("AKShare \xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5\xe8\xa1\xa5\xe5\x85\x85\xe5\xbc\x82\xe5\xb8\xb8")\r\n        print(f"  \xe2\x9c\x97 \xe5\xa4\xb1\xe8\xb4\xa5: {e}")\r\n\r\n\r\ndef _cmd_incremental_update() -> None:\r\n    print("\xf0\x9f\x94\x84 \xe5\xa2\x9e\xe9\x87\x8f\xe6\x95\xb0\xe6\x8d\xae\xe6\x9b\xb4\xe6\x96\xb0\xef\xbc\x88TDX\xef\xbc\x8c\xe4\xbb\x85\xe8\xa1\xa5\xe9\x87\x87\xe7\xbc\xba\xe5\xa4\xb1\xe6\x97\xa5\xe6\x9c\x9f\xef\xbc\x89")\r\n    try:\r\n        pipeline = _make_pipeline(force_full=False, enable_akshare=False)\r\n        stock_list = pipeline._get_all_a_stock_list()\r\n        if not stock_list:\r\n            print("  \xe2\x9c\x97 \xe8\x8e\xb7\xe5\x8f\x96\xe8\x82\xa1\xe7\xa5\xa8\xe5\x88\x97\xe8\xa1\xa8\xe5\xa4\xb1\xe8\xb4\xa5")\r\n            return\r\n        print(f"  \xe5\x85\xb1 {len(stock_list)} \xe5\x8f\xaa A \xe8\x82\xa1\xef\xbc\x8c\xe5\xbc\x80\xe5\xa7\x8b\xe5\xa2\x9e\xe9\x87\x8f\xe6\x9b\xb4\xe6\x96\xb0...")\r\n        stats = pipeline.run(stock_list)\r\n        _print_stats(stats)\r\n    except ImportError as e:\r\n        print(f"  \xe2\x9c\x97 \xe5\xaf\xbc\xe5\x85\xa5\xe5\xa4\xb1\xe8\xb4\xa5: {e}")\r\n    except Exception as e:\r\n        logger.exception("\xe5\xa2\x9e\xe9\x87\x8f\xe6\x9b\xb4\xe6\x96\xb0\xe5\xbc\x82\xe5\xb8\xb8")\r\n        print(f"  \xe2\x9c\x97 \xe5\xa4\xb1\xe8\xb4\xa5: {e}")\r\n\r\n\r\ndef _cmd_retry_failed() -> None:\r\n    print("\xf0\x9f\x94\x81 \xe8\xa1\xa5\xe9\x87\x87\xe5\xa4\xb1\xe8\xb4\xa5\xe8\x82\xa1\xe7\xa5\xa8")\r\n    cfg = _load_collector_config()\r\n    failed_txt = Path(cfg["reports_dir"]) / "failed_stocks.txt"\r\n    if not failed_txt.exists():\r\n        print(f"  \xe2\x9a\xa0\xef\xb8\x8f  \xe6\x9c\xaa\xe6\x89\xbe\xe5\x88\xb0\xe5\xa4\xb1\xe8\xb4\xa5\xe5\x88\x97\xe8\xa1\xa8: {failed_txt}")\r\n        print("  \xe8\xaf\xb7\xe5\x85\x88\xe6\x89\xa7\xe8\xa1\x8c\xe5\x85\xa8\xe9\x87\x8f\xe9\x87\x87\xe9\x9b\x86\xe6\x88\x96\xe5\xa2\x9e\xe9\x87\x8f\xe6\x9b\xb4\xe6\x96\xb0\xe3\x80\x82")\r\n        return\r\n    try:\r\n        pipeline = _make_pipeline(force_full=True, enable_akshare=False)\r\n        stats = pipeline.retry_failed(reports_dir=cfg["reports_dir"])\r\n        _print_stats(stats)\r\n    except Exception as e:\r\n        logger.exception("\xe8\xa1\xa5\xe9\x87\x87\xe5\xbc\x82\xe5\xb8\xb8")\r\n        print(f"  \xe2\x9c\x97 \xe5\xa4\xb1\xe8\xb4\xa5: {e}")\r\n\r\n\r\ndef _cmd_check_integrity(storage=None) -> None:\r\n    print("\xf0\x9f\x94\x8d \xe6\x95\xb0\xe6\x8d\xae\xe5\xae\x8c\xe6\x95\xb4\xe6\x80\xa7\xe6\xa3\x80\xe6\x9f\xa5")\r\n    cfg = _load_collector_config()\r\n    parquet_dir = Path(cfg["parquet_dir"])\r\n    if not parquet_dir.exists():\r\n        print(f"  \xe2\x9a\xa0\xef\xb8\x8f  Parquet \xe7\x9b\xae\xe5\xbd\x95\xe4\xb8\x8d\xe5\xad\x98\xe5\x9c\xa8: {parquet_dir}")\r\n        return\r\n    files = list(parquet_dir.glob("*.parquet"))\r\n    print(f"  \xe5\xb7\xb2\xe5\xad\x98\xe5\x82\xa8 {len(files)} \xe5\x8f\xaa\xe8\x82\xa1\xe7\xa5\xa8\xe7\x9a\x84 Parquet \xe6\x96\x87\xe4\xbb\xb6")\r\n    if files:\r\n        import pandas as pd\r\n        print("  \xe6\x8a\xbd\xe6\xa0\xb7\xe6\xa3\x80\xe6\x9f\xa5\xef\xbc\x88\xe5\x89\x8d5\xe5\x8f\xaa\xef\xbc\x89:")\r\n        for f in files[:5]:\r\n            try:\r\n                df = pd.read_parquet(f)\r\n                ext = [c for c in ("turnover", "pct_change", "adjust") if c in df.columns]\r\n                d_min = df["date"].min() if "date" in df.columns else "?"\r\n                d_max = df["date"].max() if "date" in df.columns else "?"\r\n                print(f"    \xe2\x9c\x93 {f.stem}: {len(df)} \xe8\xa1\x8c | {d_min} ~ {d_max} | \xe6\x89\xa9\xe5\xb1\x95={ext}")\r\n            except Exception as ex:\r\n                print(f"    \xe2\x9c\x97 {f.stem}: {ex}")\r\n    if storage:\r\n        codes = storage.get_all_codes()\r\n        print(f"  ColumnarStorage: {len(codes)} \xe5\x8f\xaa\xe8\x82\xa1\xe7\xa5\xa8")\r\n    input("\xe6\x8c\x89 Enter \xe8\xbf\x94\xe5\x9b\x9e...")\r\n\r\n\r\ndef _cmd_node_race() -> None:\r\n    print("\xf0\x9f\x8f\x81 TDX \xe8\x8a\x82\xe7\x82\xb9\xe8\xb5\x9b\xe9\xa9\xac\xe6\xb5\x8b\xe8\xaf\x95")\r\n    try:\r\n        from src.data.collector.node_scanner import race_nodes, TDX_NODES\r\n        print(f"  \xe6\xb5\x8b\xe8\xaf\x95 {len(TDX_NODES)} \xe4\xb8\xaa\xe5\x80\x99\xe9\x80\x89\xe8\x8a\x82\xe7\x82\xb9...")\r\n        results = race_nodes(timeout=3.0)\r\n        ok_nodes = [r for r in results if r["status"] == "ok"]\r\n        print(f"  \xe7\xbb\x93\xe6\x9e\x9c\xef\xbc\x88{len(ok_nodes)}/{len(results)} \xe5\x8f\xaf\xe8\xbe\xbe\xef\xbc\x89:")\r\n        for i, r in enumerate(results[:10], 1):\r\n            icon = "\xe2\x9c\x93" if r["status"] == "ok" else "\xe2\x9c\x97"\r\n            lat  = f"{r[\'latency_ms\']:>7.2f} ms" if r["latency_ms"] >= 0 else "  timeout"\r\n            print(f"    {i:>2}. {icon} {r[\'name\']:<10} {r[\'host\']:>18}:{r[\'port\']}  {lat}")\r\n        if len(results) > 10:\r\n            print(f"    ... \xe4\xbd\x99 {len(results)-10} \xe4\xb8\xaa\xe8\x8a\x82\xe7\x82\xb9")\r\n    except Exception as e:\r\n        print(f"  \xe2\x9c\x97 \xe8\x8a\x82\xe7\x82\xb9\xe6\xb5\x8b\xe8\xaf\x95\xe5\xa4\xb1\xe8\xb4\xa5: {e}")\r\n    input("\xe6\x8c\x89 Enter \xe8\xbf\x94\xe5\x9b\x9e...")\r\n\r\n\r\ndef _cmd_clean_cache() -> None:\r\n    print("\xf0\x9f\x97\x91\xef\xb8\x8f  \xe6\xb8\x85\xe7\x90\x86\xe7\xbc\x93\xe5\xad\x98")\r\n    cleaned = 0\r\n    for p in Path("./data/cache").rglob("*.json") if Path("./data/cache").exists() else []:\r\n        try:\r\n            p.unlink()\r\n            cleaned += 1\r\n        except Exception:\r\n            pass\r\n    print(f"  \xe5\xb7\xb2\xe6\xb8\x85\xe7\x90\x86 {cleaned} \xe4\xb8\xaa\xe7\xbc\x93\xe5\xad\x98\xe6\x96\x87\xe4\xbb\xb6\xef\xbc\x88fundamental JSON \xe7\xbc\x93\xe5\xad\x98\xef\xbc\x89")\r\n    print("  \xe6\xb3\xa8: Parquet \xe8\xa1\x8c\xe6\x83\x85\xe6\x96\x87\xe4\xbb\xb6\xe5\x92\x8c\xe8\xbf\x90\xe8\xa1\x8c\xe6\x8a\xa5\xe5\x91\x8a\xe4\xb8\x8d\xe4\xbc\x9a\xe8\xa2\xab\xe6\xb8\x85\xe9\x99\xa4\xe3\x80\x82")\r\n\r\n\r\ndef backtest_menu(config=None) -> None:\r\n    while True:\r\n        print("" + "\xe2\x95\x90" * 40)\r\n        print("  \xe5\x9b\x9e\xe6\xb5\x8b\xe7\xb3\xbb\xe7\xbb\x9f")\r\n        print("\xe2\x95\x90" * 40)\r\n        print("  1. \xe8\xbf\x90\xe8\xa1\x8c\xe5\x8d\x95\xe7\xad\x96\xe7\x95\xa5\xe5\x9b\x9e\xe6\xb5\x8b")\r\n        print("  2. \xe5\xa4\x9a\xe7\xad\x96\xe7\x95\xa5\xe5\xaf\xb9\xe6\xaf\x94")\r\n        print("  3. \xe6\x9f\xa5\xe7\x9c\x8b\xe5\x8e\x86\xe5\x8f\xb2\xe5\x9b\x9e\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c")\r\n        print("  0. \xe8\xbf\x94\xe5\x9b\x9e\xe4\xb8\xbb\xe8\x8f\x9c\xe5\x8d\x95")\r\n        choice = input("\xe8\xaf\xb7\xe9\x80\x89\xe6\x8b\xa9 [0-3]: ").strip()\r\n        if choice == "0":\r\n            break\r\n        elif choice == "1":\r\n            from src.strategy.strategies import STRATEGY_REGISTRY\r\n            print(f"\xe5\x8f\xaf\xe7\x94\xa8\xe7\xad\x96\xe7\x95\xa5: {list(STRATEGY_REGISTRY.keys())}")\r\n            name = input("\xe8\xbe\x93\xe5\x85\xa5\xe7\xad\x96\xe7\x95\xa5\xe5\x90\x8d\xe7\xa7\xb0: ").strip()\r\n            if name in STRATEGY_REGISTRY:\r\n                print(f"  \xe5\xb7\xb2\xe9\x80\x89\xe6\x8b\xa9: {name}")\r\n            else:\r\n                print(f"  \xe2\x9c\x97 \xe6\x9c\xaa\xe7\x9f\xa5\xe7\xad\x96\xe7\x95\xa5: {name}")\r\n        elif choice == "2":\r\n            print("  \xe5\xa4\x9a\xe7\xad\x96\xe7\x95\xa5\xe5\xaf\xb9\xe6\xaf\x94\xe5\x8a\x9f\xe8\x83\xbd\xe5\xbc\x80\xe5\x8f\x91\xe4\xb8\xad...")\r\n        elif choice == "3":\r\n            results_dir = Path("results")\r\n            if results_dir.exists():\r\n                files = list(results_dir.glob("*.json"))\r\n                print(f"  \xe5\x85\xb1 {len(files)} \xe4\xb8\xaa\xe5\x8e\x86\xe5\x8f\xb2\xe7\xbb\x93\xe6\x9e\x9c")\r\n                for f in files[:10]:\r\n                    print(f"    {f.name}")\r\n            else:\r\n                print("  \xe6\x9a\x82\xe6\x97\xa0\xe5\x8e\x86\xe5\x8f\xb2\xe5\x9b\x9e\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c")\r\n        else:\r\n            print("  \xe2\x9c\x97 \xe6\x97\xa0\xe6\x95\x88\xe9\x80\x89\xe9\xa1\xb9")\r\n\r\n\r\ndef system_management_menu(config=None) -> None:\r\n    while True:\r\n        print("" + "\xe2\x95\x90" * 40)\r\n        print("  \xe7\xb3\xbb\xe7\xbb\x9f\xe7\xae\xa1\xe7\x90\x86")\r\n        print("\xe2\x95\x90" * 40)\r\n        print("  1. \xe5\x81\xa5\xe5\xba\xb7\xe6\xa3\x80\xe6\x9f\xa5")\r\n        print("  2. \xe6\x9f\xa5\xe7\x9c\x8b\xe6\x97\xa5\xe5\xbf\x97")\r\n        print("  3. \xe6\x95\xb0\xe6\x8d\xae\xe6\xba\x90\xe5\xbf\x83\xe8\xb7\xb3\xe6\xa3\x80\xe6\xb5\x8b")\r\n        print("  0. \xe8\xbf\x94\xe5\x9b\x9e\xe4\xb8\xbb\xe8\x8f\x9c\xe5\x8d\x95")\r\n        choice = input("\xe8\xaf\xb7\xe9\x80\x89\xe6\x8b\xa9 [0-3]: ").strip()\r\n        if choice == "0":\r\n            break\r\n        elif choice == "1":\r\n            from main import run_health_check\r\n            run_health_check()\r\n        elif choice == "2":\r\n            log_path = Path("logs/q-unity.log")\r\n            if log_path.exists():\r\n                lines = log_path.read_text(encoding="utf-8").splitlines()\r\n                print(f"\xe6\x9c\x80\xe8\xbf\x91 20 \xe8\xa1\x8c\xe6\x97\xa5\xe5\xbf\x97:")\r\n                for line in lines[-20:]:\r\n                    print(f"  {line}")\r\n            else:\r\n                print("  \xe6\x9a\x82\xe6\x97\xa0\xe6\x97\xa5\xe5\xbf\x97\xe6\x96\x87\xe4\xbb\xb6")\r\n        elif choice == "3":\r\n            _check_data_source_heartbeat()\r\n        else:\r\n            print("  \xe2\x9c\x97 \xe6\x97\xa0\xe6\x95\x88\xe9\x80\x89\xe9\xa1\xb9")\r\n\r\n\r\ndef main_menu() -> None:\r\n    config = storage = None\r\n    try:\r\n        from src.config import ConfigManager\r\n        from src.data.storage import ColumnarStorageManager\r\n        config  = ConfigManager()\r\n        data_dir = config.get("data", {}).get("base_dir", "./data")\r\n        storage = ColumnarStorageManager(data_dir)\r\n    except Exception as e:\r\n        print(f"\xe2\x9a\xa0\xef\xb8\x8f  \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe5\xa4\xb1\xe8\xb4\xa5: {e}")\r\n\r\n    while True:\r\n        print("" + "\xe2\x95\x90" * 56)\r\n        print("       Q-UNITY-V7.1 \xe9\x87\x8f\xe5\x8c\x96\xe4\xba\xa4\xe6\x98\x93\xe7\xb3\xbb\xe7\xbb\x9f v7.1.0")\r\n        print("       \xe6\x95\xb0\xe6\x8d\xae\xe5\xb1\x82: TDX\xe5\xbf\xab\xe9\x80\x9f(~30min) + AKShare\xe5\x8f\xaf\xe9\x80\x89\xe6\x89\xa9\xe5\xb1\x95")\r\n        print("\xe2\x95\x90" * 56)\r\n        print("  1. \xe6\x95\xb0\xe6\x8d\xae\xe7\xae\xa1\xe7\x90\x86  (\xe5\xbf\xab\xe9\x80\x9f\xe9\x87\x87\xe9\x9b\x86/\xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5/\xe5\xa2\x9e\xe9\x87\x8f/\xe8\x8a\x82\xe7\x82\xb9)")\r\n        print("  2. \xe5\x9b\x9e\xe6\xb5\x8b\xe7\xb3\xbb\xe7\xbb\x9f")\r\n        print("  3. \xe7\xb3\xbb\xe7\xbb\x9f\xe7\xae\xa1\xe7\x90\x86  (\xe5\x81\xa5\xe5\xba\xb7\xe6\xa3\x80\xe6\x9f\xa5/\xe6\x97\xa5\xe5\xbf\x97/\xe5\xbf\x83\xe8\xb7\xb3)")\r\n        print("  0. \xe9\x80\x80\xe5\x87\xba")\r\n        print("\xe2\x94\x80" * 56)\r\n        choice = input("\xe8\xaf\xb7\xe9\x80\x89\xe6\x8b\xa9 [0-3]: ").strip()\r\n        if choice == "0":\r\n            print("\xe5\x86\x8d\xe8\xa7\x81! Q-UNITY-V7.1 \xe5\xb7\xb2\xe9\x80\x80\xe5\x87\xba\xe3\x80\x82")\r\n            sys.exit(0)\r\n        elif choice == "1":\r\n            data_management_menu(config, storage)\r\n        elif choice == "2":\r\n            backtest_menu(config)\r\n        elif choice == "3":\r\n            system_management_menu(config)\r\n        else:\r\n            print("  \xe2\x9c\x97 \xe6\x97\xa0\xe6\x95\x88\xe9\x80\x89\xe9\xa1\xb9\xef\xbc\x8c\xe8\xaf\xb7\xe9\x87\x8d\xe6\x96\xb0\xe9\x80\x89\xe6\x8b\xa9")\r\n\r\n\r\nif __name__ == "__main__":\r\n    logging.basicConfig(\r\n        level=logging.INFO,\r\n        format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",\r\n    )\r\n    main_menu()\r\n'

FILE_src_init_py = b'#!/usr/bin/env python3\r\n"""Q-UNITY-V7.1 \xe6\xa0\xb8\xe5\xbf\x83\xe6\xa8\xa1\xe5\x9d\x97"""\r\n__version__ = "7.1.0"\r\n__author__  = "Q-UNITY Team"\r\n'

FILE_src_types_py = b'#!/usr/bin/env python3\r\n"""\r\nQ-UNITY-V6 \xe6\xa0\xb8\xe5\xbf\x83\xe6\x95\xb0\xe6\x8d\xae\xe7\xb1\xbb\xe5\x9e\x8b\xe5\xae\x9a\xe4\xb9\x89\r\n\xe4\xbf\xae\xe5\xa4\x8d: NB-08 PositionState \xe6\x96\xb0\xe5\xa2\x9e entry_date \xe5\xad\x97\xe6\xae\xb5\r\n"""\r\n\r\nfrom __future__ import annotations\r\nfrom dataclasses import dataclass, field\r\nfrom datetime import datetime\r\nfrom enum import Enum\r\nfrom typing import Dict, List, Optional, Any\r\n\r\n\r\n# ============================================================================\r\n# \xe6\x9e\x9a\xe4\xb8\xbe\xe7\xb1\xbb\xe5\x9e\x8b\r\n# ============================================================================\r\n\r\nclass OrderSide(Enum):\r\n    BUY  = "BUY"\r\n    SELL = "SELL"\r\n\r\n\r\nclass OrderType(Enum):\r\n    MARKET = "MARKET"\r\n    LIMIT  = "LIMIT"\r\n    STOP   = "STOP"\r\n\r\n\r\nclass OrderStatus(Enum):\r\n    PENDING   = "PENDING"\r\n    FILLED    = "FILLED"\r\n    PARTIAL   = "PARTIAL"\r\n    CANCELLED = "CANCELLED"\r\n    REJECTED  = "REJECTED"\r\n\r\n\r\nclass PositionDirection(Enum):\r\n    LONG  = "LONG"\r\n    SHORT = "SHORT"\r\n\r\n\r\n# ============================================================================\r\n# \xe4\xbf\xa1\xe5\x8f\xb7\r\n# ============================================================================\r\n\r\n@dataclass\r\nclass Signal:\r\n    """\xe4\xba\xa4\xe6\x98\x93\xe4\xbf\xa1\xe5\x8f\xb7"""\r\n    timestamp: Any          # datetime \xe6\x88\x96 Timestamp \xe5\x8c\x85\xe8\xa3\x85\xe7\xb1\xbb\r\n    code: str\r\n    side: OrderSide\r\n    score: float = 0.0\r\n    reason: str = ""\r\n    price: Optional[float] = None\r\n    volume: Optional[int] = None\r\n    weight: float = 0.0           # \xe7\x9b\xae\xe6\xa0\x87\xe4\xbb\x93\xe4\xbd\x8d\xe6\x9d\x83\xe9\x87\x8d [0, 1]\r\n    strategy_name: str = ""       # \xe7\x94\x9f\xe6\x88\x90\xe6\xad\xa4\xe4\xbf\xa1\xe5\x8f\xb7\xe7\x9a\x84\xe7\xad\x96\xe7\x95\xa5\xe5\x90\x8d\xe7\xa7\xb0\r\n    metadata: Dict = field(default_factory=dict)\r\n\r\n\r\n# ============================================================================\r\n# \xe8\xae\xa2\xe5\x8d\x95\r\n# ============================================================================\r\n\r\n@dataclass\r\nclass Order:\r\n    """\xe5\xa7\x94\xe6\x89\x98\xe8\xae\xa2\xe5\x8d\x95"""\r\n    order_id: str\r\n    timestamp: datetime\r\n    code: str\r\n    side: OrderSide\r\n    order_type: OrderType\r\n    status: OrderStatus\r\n    price: float\r\n    volume: int\r\n    filled_volume: int = 0\r\n    filled_price: float = 0.0\r\n    commission: float = 0.0\r\n    reason: str = ""\r\n    metadata: Dict = field(default_factory=dict)\r\n\r\n\r\n@dataclass\r\nclass Fill:\r\n    """\xe6\x88\x90\xe4\xba\xa4\xe8\xae\xb0\xe5\xbd\x95\xef\xbc\x88\xe8\xbd\xbb\xe9\x87\x8f\xef\xbc\x89"""\r\n    order_id: str\r\n    code: str\r\n    side: OrderSide\r\n    price: float\r\n    volume: int\r\n    timestamp: datetime\r\n\r\n\r\n# ============================================================================\r\n# \xe6\x8c\x81\xe4\xbb\x93\r\n# ============================================================================\r\n\r\n@dataclass\r\nclass PositionState:\r\n    """\xe6\x8c\x81\xe4\xbb\x93\xe7\x8a\xb6\xe6\x80\x81"""\r\n    code: str\r\n    direction: PositionDirection\r\n    volume: int\r\n    available_volume: int\r\n    frozen_volume: int\r\n    avg_cost: float\r\n    current_price: float\r\n    market_value: float\r\n    profit_loss: float\r\n    profit_loss_pct: float\r\n    holding_days: int = 0\r\n    last_trade_date: Optional[datetime] = None\r\n    entry_date: Optional[datetime] = None     # NB-08 \xe4\xbf\xae\xe5\xa4\x8d\xef\xbc\x9a\xe8\xae\xb0\xe5\xbd\x95\xe5\xbb\xba\xe4\xbb\x93\xe6\x97\xa5\xe6\x9c\x9f\r\n    metadata: Dict = field(default_factory=dict)\r\n\r\n    def update_price(self, new_price: float) -> None:\r\n        self.current_price = new_price\r\n        self.market_value  = self.volume * new_price\r\n        cost_basis = self.avg_cost * self.volume\r\n        self.profit_loss     = self.market_value - cost_basis\r\n        self.profit_loss_pct = (self.profit_loss / cost_basis) if cost_basis > 1e-9 else 0.0\r\n\r\n    def add_volume(self, volume: int, price: float) -> None:\r\n        total_cost  = self.avg_cost * self.volume + price * volume\r\n        self.volume += volume\r\n        self.avg_cost = total_cost / self.volume if self.volume > 0 else price\r\n        self.available_volume = self.volume\r\n        self.update_price(self.current_price)\r\n\r\n    def reduce_volume(self, volume: int) -> None:\r\n        self.volume = max(0, self.volume - volume)\r\n        self.available_volume = max(0, self.available_volume - volume)\r\n        self.update_price(self.current_price)\r\n\r\n\r\n# ============================================================================\r\n# \xe8\xb4\xa6\xe6\x88\xb7\xe5\xbf\xab\xe7\x85\xa7\r\n# ============================================================================\r\n\r\n@dataclass\r\nclass AccountSnapshot:\r\n    """\xe8\xb4\xa6\xe6\x88\xb7\xe5\xbf\xab\xe7\x85\xa7"""\r\n    timestamp: datetime\r\n    total_value: float\r\n    cash: float\r\n    market_value: float\r\n    frozen_cash: float\r\n    available_cash: float\r\n    positions_count: int\r\n    total_trades: int\r\n    metadata: Dict = field(default_factory=dict)\r\n\r\n\r\n# ============================================================================\r\n# \xe6\x88\x90\xe4\xba\xa4\xe8\xae\xb0\xe5\xbd\x95\r\n# ============================================================================\r\n\r\n@dataclass\r\nclass TradeRecord:\r\n    """\xe6\x88\x90\xe4\xba\xa4\xe8\xae\xb0\xe5\xbd\x95"""\r\n    trade_id: str\r\n    timestamp: datetime\r\n    code: str\r\n    side: OrderSide\r\n    volume: int\r\n    price: float\r\n    amount: float\r\n    commission: float\r\n    slippage: float\r\n    tax: float\r\n    net_amount: float\r\n    order_id: str = ""\r\n    reason: str = ""\r\n    metadata: Dict = field(default_factory=dict)\r\n\r\n\r\n# ============================================================================\r\n# \xe9\xa3\x8e\xe6\x8e\xa7\xe6\x8c\x87\xe6\xa0\x87\r\n# ============================================================================\r\n\r\n@dataclass\r\nclass RiskMetrics:\r\n    """\xe9\xa3\x8e\xe9\x99\xa9\xe6\x8c\x87\xe6\xa0\x87\xe5\xbf\xab\xe7\x85\xa7"""\r\n    timestamp: datetime\r\n    total_value: float\r\n    max_drawdown: float\r\n    current_drawdown: float\r\n    volatility: float\r\n    sharpe_ratio: float\r\n    beta: float\r\n    var_95: float\r\n    cvar_95: float\r\n    concentration_ratio: float\r\n    turnover_rate: float\r\n    max_position_pct: float\r\n    industry_exposure: Dict[str, float] = field(default_factory=dict)\r\n    alerts: List[str] = field(default_factory=list)\r\n\r\n\r\n__all__ = [\r\n    "OrderSide", "OrderType", "OrderStatus", "PositionDirection",\r\n    "Signal", "Order", "Fill", "PositionState", "AccountSnapshot",\r\n    "TradeRecord", "RiskMetrics",\r\n]\r\n'

FILE_src_constants_py = b'#!/usr/bin/env python3\r\n"""\r\nQ-UNITY-V7.1 \xe5\x85\xa8\xe5\xb1\x80\xe5\xb8\xb8\xe9\x87\x8f\xe5\xae\x9a\xe4\xb9\x89\r\n\xe6\x95\xb4\xe5\x90\x88 V6 \xe5\x9f\xba\xe7\xa1\x80\xe7\x89\x88\xe5\xb8\xb8\xe9\x87\x8f + V6-op patch_v9 \xe5\xa4\x8d\xe6\x9d\x83\xe6\xa0\x87\xe5\x87\x86\r\n"""\r\n\r\nVERSION    = "7.1.0"\r\nBUILD_DATE = "2026-02-23"\r\n\r\n# \xe5\xa4\x8d\xe6\x9d\x83\xe6\xa0\x87\xe5\x87\x86\xef\xbc\x88\xe5\x85\xa8\xe5\xb1\x80\xe7\xbb\x9f\xe4\xb8\x80\xef\xbc\x8chfq=\xe5\x90\x8e\xe5\xa4\x8d\xe6\x9d\x83\xef\xbc\x89\r\nADJUST_STD = "hfq"\r\n\r\nT_PLUS_1       = True\r\nMIN_TRADE_UNIT = 100\r\n\r\nDEFAULT_COMMISSION_RATE = 0.0003\r\nSTAMP_TAX_RATE          = 0.001\r\nDEFAULT_SLIPPAGE_RATE   = 0.001\r\nMIN_COMMISSION          = 5.0\r\n\r\nMAX_DRAWDOWN      = 0.20\r\nMAX_POSITION_PCT  = 0.10\r\nMAX_INDUSTRY_PCT  = 0.30\r\nSTOP_LOSS_PCT     = 0.10\r\nTAKE_PROFIT_PCT   = 0.20\r\nTRAILING_STOP_PCT = 0.05\r\n\r\n# ==================== RSRS \xe5\x9b\xa0\xe5\xad\x90\xe9\x98\x88\xe5\x80\xbc\xe8\xaf\xb4\xe6\x98\x8e (NB-17) ====================\r\nRSRS_NORMALIZED_NOTE = "\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96beta\xef\xbc\x8c\xe9\x98\x88\xe5\x80\xbc\xe9\x9c\x80\xe9\x87\x8d\xe6\x96\xb0\xe6\xa0\xa1\xe5\x87\x86\xef\xbc\x8c\xe8\xaf\xa6\xe8\xa7\x81constants.py\xe6\xb3\xa8\xe9\x87\x8a"\r\n\r\nTRADING_DAYS_PER_YEAR = 252\r\nMIN_HISTORY_DAYS      = 100\r\n'

FILE_src_config_py = b'#!/usr/bin/env python3\r\n"""\r\nQ-UNITY-V6 \xe9\x85\x8d\xe7\xbd\xae\xe7\xae\xa1\xe7\x90\x86\xe6\xa8\xa1\xe5\x9d\x97\r\n"""\r\nfrom __future__ import annotations\r\nimport json\r\nimport logging\r\nfrom pathlib import Path\r\nfrom typing import Any, Dict, Optional\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\nclass ConfigManager:\r\n    """\xe9\x85\x8d\xe7\xbd\xae\xe7\xae\xa1\xe7\x90\x86\xe5\x99\xa8\xef\xbc\x9a\xe6\x94\xaf\xe6\x8c\x81 JSON \xe9\x85\x8d\xe7\xbd\xae\xe6\x96\x87\xe4\xbb\xb6\xe5\x92\x8c\xe9\xbb\x98\xe8\xae\xa4\xe5\x80\xbc"""\r\n\r\n    _DEFAULT = {\r\n        "data": {\r\n            "base_dir": "./data",\r\n            "parquet_dir": "./data/parquet",\r\n            "cache_dir": "./data/cache",\r\n            "industry_dir": "./data/industry",\r\n        },\r\n        "backtest": {\r\n            "initial_cash": 1_000_000.0,\r\n            "commission_rate": 0.0003,\r\n            "slippage_rate": 0.001,\r\n            "tax_rate": 0.001,\r\n            "position_limit": 20,\r\n            "max_position_pct": 0.2,\r\n        },\r\n        "risk": {\r\n            "max_drawdown": 0.2,\r\n            "max_position_pct": 0.1,\r\n            "industry_limit": 0.3,\r\n            "stop_loss_pct": 0.1,\r\n            "take_profit_pct": 0.2,\r\n            "trailing_stop_pct": 0.05,\r\n            "circuit_breaker_cooldown_days": 5,\r\n        },\r\n        "factors": {\r\n            "rsrs": {"regression_window": 18, "zscore_window": 600, "enable": True},\r\n            "alpha": {"momentum_window": 20, "volatility_window": 20, "enable": True},\r\n        },\r\n        "strategy": {"rebalance_freq": "daily", "top_n": 20, "min_score": 0.0},\r\n        "logging": {"level": "INFO", "file": "./logs/q-unity.log"},\r\n    }\r\n\r\n    def __init__(self, config_path: Optional[str] = None) -> None:\r\n        self.config: Dict[str, Any] = dict(self._DEFAULT)\r\n        if config_path:\r\n            self._load(config_path)\r\n        else:\r\n            default_path = Path("config.json")\r\n            if default_path.exists():\r\n                self._load(str(default_path))\r\n\r\n    def _load(self, path: str) -> None:\r\n        try:\r\n            with open(path, encoding="utf-8") as f:\r\n                loaded = json.load(f)\r\n            self._deep_merge(self.config, loaded)\r\n            logger.info(f"\xe9\x85\x8d\xe7\xbd\xae\xe5\xb7\xb2\xe5\x8a\xa0\xe8\xbd\xbd: {path}")\r\n        except FileNotFoundError:\r\n            logger.warning(f"\xe9\x85\x8d\xe7\xbd\xae\xe6\x96\x87\xe4\xbb\xb6\xe4\xb8\x8d\xe5\xad\x98\xe5\x9c\xa8: {path}\xef\xbc\x8c\xe4\xbd\xbf\xe7\x94\xa8\xe9\xbb\x98\xe8\xae\xa4\xe5\x80\xbc")\r\n        except json.JSONDecodeError as e:\r\n            logger.error(f"\xe9\x85\x8d\xe7\xbd\xae\xe6\x96\x87\xe4\xbb\xb6\xe8\xa7\xa3\xe6\x9e\x90\xe5\xa4\xb1\xe8\xb4\xa5: {e}\xef\xbc\x8c\xe4\xbd\xbf\xe7\x94\xa8\xe9\xbb\x98\xe8\xae\xa4\xe5\x80\xbc")\r\n\r\n    @staticmethod\r\n    def _deep_merge(base: dict, override: dict) -> None:\r\n        for k, v in override.items():\r\n            if k in base and isinstance(base[k], dict) and isinstance(v, dict):\r\n                ConfigManager._deep_merge(base[k], v)\r\n            else:\r\n                base[k] = v\r\n\r\n    def get(self, key: str, default: Any = None) -> Any:\r\n        return self.config.get(key, default)\r\n'

FILE_src_data_init_py = b'#!/usr/bin/env python3\r\n"""Q-UNITY-V7.1 \xe6\x95\xb0\xe6\x8d\xae\xe6\xa8\xa1\xe5\x9d\x97"""\r\nfrom .storage import ColumnarStorageManager\r\n__all__ = ["ColumnarStorageManager"]\r\n'

FILE_src_data_storage_py = b'#!/usr/bin/env python3\r\n"""\r\nQ-UNITY-V6 \xe5\x88\x97\xe5\xbc\x8f\xe5\xad\x98\xe5\x82\xa8\xe7\xae\xa1\xe7\x90\x86\xe5\x99\xa8\r\n\xe6\x94\xaf\xe6\x8c\x81 Parquet\xef\xbc\x88\xe4\xbc\x98\xe5\x85\x88\xef\xbc\x89\xe5\x92\x8c CSV.gz\xef\xbc\x88\xe9\x99\x8d\xe7\xba\xa7\xef\xbc\x89\xe4\xb8\xa4\xe7\xa7\x8d\xe6\xa0\xbc\xe5\xbc\x8f\r\n"""\r\nfrom __future__ import annotations\r\nimport logging\r\nimport gzip\r\nfrom pathlib import Path\r\nfrom typing import Dict, List, Optional\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\ntry:\r\n    import pyarrow  # noqa\r\n    _PARQUET = True\r\nexcept ImportError:\r\n    _PARQUET = False\r\n    logger.warning("PyArrow \xe6\x9c\xaa\xe5\xae\x89\xe8\xa3\x85\xef\xbc\x8c\xe8\x87\xaa\xe5\x8a\xa8\xe9\x99\x8d\xe7\xba\xa7\xe4\xb8\xba CSV.gz \xe6\xa0\xbc\xe5\xbc\x8f")\r\n\r\n\r\nclass ColumnarStorageManager:\r\n    """\xe5\x88\x97\xe5\xbc\x8f\xe5\xad\x98\xe5\x82\xa8\xe7\xae\xa1\xe7\x90\x86\xe5\x99\xa8\xef\xbc\x9a\xe7\xbb\x9f\xe4\xb8\x80\xe5\xad\x98\xe5\x8f\x96\xe6\x8e\xa5\xe5\x8f\xa3\xef\xbc\x8c\xe9\x80\x8f\xe6\x98\x8e\xe6\xa0\xbc\xe5\xbc\x8f\xe5\x88\x87\xe6\x8d\xa2"""\r\n\r\n    def __init__(self, base_dir: str = "./data") -> None:\r\n        self.base_dir = Path(base_dir)\r\n        self.stock_dir  = self.base_dir / "parquet"\r\n        self.factor_dir = self.base_dir / "factors"\r\n        self.industry_dir = self.base_dir / "industry"\r\n        for d in [self.stock_dir, self.factor_dir, self.industry_dir]:\r\n            d.mkdir(parents=True, exist_ok=True)\r\n        self.gateway = None\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe8\x82\xa1\xe7\xa5\xa8\xe8\xa1\x8c\xe6\x83\x85 \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    def _stock_path(self, code: str, fmt: str = None) -> Path:\r\n        if fmt is None:\r\n            fmt = "parquet" if _PARQUET else "csv.gz"\r\n        return self.stock_dir / f"{code}.{fmt}"\r\n\r\n    def save_stock_data(self, code: str, df: pd.DataFrame) -> bool:\r\n        if df is None or df.empty:\r\n            return False\r\n        try:\r\n            if _PARQUET:\r\n                df.to_parquet(self._stock_path(code, "parquet"), engine="pyarrow")\r\n            else:\r\n                with gzip.open(self._stock_path(code, "csv.gz"), "wt", encoding="utf-8") as f:\r\n                    df.to_csv(f)\r\n            return True\r\n        except Exception as e:\r\n            logger.error(f"\xe4\xbf\x9d\xe5\xad\x98 {code} \xe5\xa4\xb1\xe8\xb4\xa5: {e}")\r\n            return False\r\n\r\n    def load_stock_data(\r\n        self, code: str,\r\n        start_date: Optional[str] = None,\r\n        end_date: Optional[str] = None,\r\n    ) -> Optional[pd.DataFrame]:\r\n        try:\r\n            if _PARQUET:\r\n                path = self._stock_path(code, "parquet")\r\n                if not path.exists():\r\n                    path = self._stock_path(code, "csv.gz")\r\n                    if not path.exists():\r\n                        return None\r\n                    df = pd.read_csv(path, index_col=0, parse_dates=True)\r\n                else:\r\n                    df = pd.read_parquet(path, engine="pyarrow")\r\n            else:\r\n                path = self._stock_path(code, "csv.gz")\r\n                if not path.exists():\r\n                    return None\r\n                df = pd.read_csv(path, index_col=0, parse_dates=True)\r\n\r\n            if not isinstance(df.index, pd.DatetimeIndex):\r\n                df.index = pd.to_datetime(df.index)\r\n            df = df.sort_index()\r\n            if start_date:\r\n                df = df.loc[df.index >= pd.to_datetime(start_date)]\r\n            if end_date:\r\n                df = df.loc[df.index <= pd.to_datetime(end_date)]\r\n            return df if not df.empty else None\r\n        except Exception as e:\r\n            logger.debug(f"\xe5\x8a\xa0\xe8\xbd\xbd {code} \xe5\xa4\xb1\xe8\xb4\xa5: {e}")\r\n            return None\r\n\r\n    def get_all_codes(self) -> List[str]:\r\n        codes = set()\r\n        for ext in ("parquet", "csv.gz"):\r\n            for p in self.stock_dir.glob(f"*.{ext}"):\r\n                codes.add(p.name.split(".")[0])\r\n        return sorted(codes)\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe5\x9b\xa0\xe5\xad\x90\xe6\x95\xb0\xe6\x8d\xae \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    def save_factor_data(self, code: str, df: pd.DataFrame) -> bool:\r\n        if df is None or df.empty:\r\n            return False\r\n        try:\r\n            path = self.factor_dir / f"{code}_factors.parquet"\r\n            if _PARQUET:\r\n                df.to_parquet(path)\r\n            else:\r\n                df.to_csv(path.with_suffix(".csv.gz"), compression="gzip")\r\n            return True\r\n        except Exception as e:\r\n            logger.error(f"\xe4\xbf\x9d\xe5\xad\x98\xe5\x9b\xa0\xe5\xad\x90 {code} \xe5\xa4\xb1\xe8\xb4\xa5: {e}")\r\n            return False\r\n\r\n    def load_factor_data(self, code: str) -> Optional[pd.DataFrame]:\r\n        try:\r\n            path = self.factor_dir / f"{code}_factors.parquet"\r\n            if not path.exists():\r\n                path = self.factor_dir / f"{code}_factors.csv.gz"\r\n                if not path.exists():\r\n                    return None\r\n                return pd.read_csv(path, index_col=0, parse_dates=True)\r\n            return pd.read_parquet(path)\r\n        except Exception:\r\n            return None\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe8\xa1\x8c\xe4\xb8\x9a\xe6\x95\xb0\xe6\x8d\xae \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    def save_industry_data(self, df: pd.DataFrame) -> bool:\r\n        try:\r\n            path = self.industry_dir / "industry_map.parquet"\r\n            if _PARQUET:\r\n                df.to_parquet(path)\r\n            else:\r\n                df.to_csv(path.with_suffix(".csv"), index=False)\r\n            return True\r\n        except Exception as e:\r\n            logger.error(f"\xe4\xbf\x9d\xe5\xad\x98\xe8\xa1\x8c\xe4\xb8\x9a\xe6\x95\xb0\xe6\x8d\xae\xe5\xa4\xb1\xe8\xb4\xa5: {e}")\r\n            return False\r\n\r\n    def load_industry_data(self) -> Optional[pd.DataFrame]:\r\n        try:\r\n            for path in [\r\n                self.industry_dir / "industry_map.parquet",\r\n                self.industry_dir / "industry_map.csv",\r\n            ]:\r\n                if path.exists():\r\n                    if path.suffix == ".parquet":\r\n                        return pd.read_parquet(path)\r\n                    return pd.read_csv(path)\r\n        except Exception:\r\n            pass\r\n        return None\r\n'

FILE_src_data_fundamental_py = b'#!/usr/bin/env python3\r\n"""\r\nQ-UNITY-V6 \xe5\x9f\xba\xe6\x9c\xac\xe9\x9d\xa2\xe6\x95\xb0\xe6\x8d\xae\xe8\x8e\xb7\xe5\x8f\x96\xe6\xa8\xa1\xe5\x9d\x97 v2.1\r\n\xe7\x89\xb9\xe6\x80\xa7:\r\n  - AKShare stock_financial_analysis_indicator \xe7\x9c\x9f\xe6\xad\xa3 TTM \xe6\x95\xb0\xe6\x8d\xae\r\n  - \xe5\xad\x97\xe6\xae\xb5\xe7\xba\xa7 try/except \xe9\x9a\x94\xe7\xa6\xbb\xef\xbc\x8c\xe5\x8d\x95\xe5\xad\x97\xe6\xae\xb5\xe5\xa4\xb1\xe8\xb4\xa5\xe4\xb8\x8d\xe5\xbd\xb1\xe5\x93\x8d\xe5\x85\xb6\xe4\xbb\x96\r\n  - \xe5\xad\xa3\xe5\xba\xa6\xe2\x86\x92TTM \xe6\xbb\x9a\xe5\x8a\xa8\xe9\x99\x8d\xe7\xba\xa7\xe8\xb7\xaf\xe5\xbe\x84\r\n  - \xe7\xbc\x93\xe5\xad\x98\xe7\x89\x88\xe6\x9c\xac\xe6\xa0\xa1\xe9\xaa\x8c (CACHE_VERSION=2)\r\n  - \xe8\xbe\x93\xe5\x87\xba\xe5\xad\x97\xe6\xae\xb5: pe_ttm, pb_lf, roe_ttm, net_profit_ttm,\r\n              revenue_growth, net_profit_growth, circ_mv\r\n"""\r\nfrom __future__ import annotations\r\nimport logging\r\nimport json\r\nimport time\r\nimport hashlib\r\nfrom pathlib import Path\r\nfrom typing import Any, Dict, Optional, Tuple\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\nCACHE_VERSION = 2          # \xe5\x8d\x87\xe7\x89\x88\xe6\x9c\xac\xe5\x8f\xb7\xe5\x8f\xaf\xe5\xbc\xba\xe5\x88\xb6\xe5\x88\xb7\xe6\x96\xb0\xe6\x97\xa7\xe7\xbc\x93\xe5\xad\x98\r\nCACHE_TTL     = 24 * 3600  # 24\xe5\xb0\x8f\xe6\x97\xb6\r\n\r\n\r\nclass FundamentalDataProvider:\r\n    """\xe5\x9f\xba\xe6\x9c\xac\xe9\x9d\xa2\xe6\x95\xb0\xe6\x8d\xae\xe6\x8f\x90\xe4\xbe\x9b\xe8\x80\x85\xef\xbc\x88v2.1 TTM\xe7\xb2\xbe\xe5\x87\x86\xe5\x8c\x96\xef\xbc\x89"""\r\n\r\n    def __init__(\r\n        self,\r\n        cache_dir: str = "./data/cache/fundamental",\r\n        cache_ttl: int = CACHE_TTL,\r\n    ) -> None:\r\n        self.cache_dir = Path(cache_dir)\r\n        self.cache_dir.mkdir(parents=True, exist_ok=True)\r\n        self.cache_ttl = cache_ttl\r\n        self._mem: Dict[str, Tuple[float, Any]] = {}  # \xe5\x86\x85\xe5\xad\x98\xe4\xba\x8c\xe7\xba\xa7\xe7\xbc\x93\xe5\xad\x98\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe7\xbc\x93\xe5\xad\x98 \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    def _cache_key(self, code: str) -> str:\r\n        raw = f"v{CACHE_VERSION}:{code}"\r\n        return hashlib.md5(raw.encode()).hexdigest()\r\n\r\n    def _cache_path(self, code: str) -> Path:\r\n        return self.cache_dir / f"{self._cache_key(code)}.json"\r\n\r\n    def _load_cache(self, code: str) -> Optional[Dict]:\r\n        key = self._cache_key(code)\r\n        # \xe5\x86\x85\xe5\xad\x98\xe7\xbc\x93\xe5\xad\x98\r\n        if key in self._mem:\r\n            ts, data = self._mem[key]\r\n            if time.time() - ts < self.cache_ttl:\r\n                return data\r\n        # \xe7\xa3\x81\xe7\x9b\x98\xe7\xbc\x93\xe5\xad\x98\r\n        path = self._cache_path(code)\r\n        if not path.exists():\r\n            return None\r\n        try:\r\n            raw = json.loads(path.read_text(encoding="utf-8"))\r\n            # \xe7\x89\x88\xe6\x9c\xac\xe6\xa0\xa1\xe9\xaa\x8c\r\n            if raw.get("__version__") != CACHE_VERSION:\r\n                path.unlink(missing_ok=True)\r\n                return None\r\n            if time.time() - raw.get("__ts__", 0) > self.cache_ttl:\r\n                path.unlink(missing_ok=True)\r\n                return None\r\n            data = {k: v for k, v in raw.items() if not k.startswith("__")}\r\n            self._mem[key] = (raw["__ts__"], data)\r\n            return data\r\n        except Exception:\r\n            return None\r\n\r\n    def _save_cache(self, code: str, data: Dict) -> None:\r\n        key = self._cache_key(code)\r\n        ts  = time.time()\r\n        self._mem[key] = (ts, data)\r\n        path = self._cache_path(code)\r\n        try:\r\n            out = {"__version__": CACHE_VERSION, "__ts__": ts}\r\n            out.update(data)\r\n            path.write_text(json.dumps(out, ensure_ascii=False, default=float), encoding="utf-8")\r\n        except Exception as e:\r\n            logger.debug(f"\xe5\x86\x99\xe5\x85\xa5\xe7\xbc\x93\xe5\xad\x98\xe5\xa4\xb1\xe8\xb4\xa5 {code}: {e}")\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe4\xb8\xbb\xe6\x8e\xa5\xe5\x8f\xa3 \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    def get_fundamental(self, code: str) -> Optional[Dict]:\r\n        """\r\n        \xe8\x8e\xb7\xe5\x8f\x96\xe8\x82\xa1\xe7\xa5\xa8\xe5\x9f\xba\xe6\x9c\xac\xe9\x9d\xa2\xe6\x8c\x87\xe6\xa0\x87\xef\xbc\x88TTM\xe5\x8f\xa3\xe5\xbe\x84\xef\xbc\x89\r\n        \xe8\xbf\x94\xe5\x9b\x9e\xe5\xad\x97\xe6\xae\xb5:\r\n            pe_ttm            \xe2\x80\x94 \xe5\xb8\x82\xe7\x9b\x88\xe7\x8e\x87(TTM)\r\n            pb_lf             \xe2\x80\x94 \xe5\xb8\x82\xe5\x87\x80\xe7\x8e\x87(LF)\r\n            roe_ttm           \xe2\x80\x94 \xe5\x87\x80\xe8\xb5\x84\xe4\xba\xa7\xe6\x94\xb6\xe7\x9b\x8a\xe7\x8e\x87(TTM)\r\n            net_profit_ttm    \xe2\x80\x94 \xe5\x87\x80\xe5\x88\xa9\xe6\xb6\xa6TTM (\xe4\xb8\x87\xe5\x85\x83)\r\n            revenue_growth    \xe2\x80\x94 \xe8\x90\xa5\xe6\x94\xb6\xe5\x90\x8c\xe6\xaf\x94\xe5\xa2\x9e\xe9\x95\xbf\xe7\x8e\x87\r\n            net_profit_growth \xe2\x80\x94 \xe5\x87\x80\xe5\x88\xa9\xe6\xb6\xa6\xe5\x90\x8c\xe6\xaf\x94\xe5\xa2\x9e\xe9\x95\xbf\xe7\x8e\x87\r\n            circ_mv           \xe2\x80\x94 \xe6\xb5\x81\xe9\x80\x9a\xe5\xb8\x82\xe5\x80\xbc(\xe4\xb8\x87\xe5\x85\x83)\r\n        """\r\n        # \xe6\x9f\xa5\xe7\xbc\x93\xe5\xad\x98\r\n        cached = self._load_cache(code)\r\n        if cached:\r\n            return cached\r\n\r\n        result: Dict[str, Optional[float]] = {\r\n            "pe_ttm": None, "pb_lf": None, "roe_ttm": None,\r\n            "net_profit_ttm": None, "revenue_growth": None,\r\n            "net_profit_growth": None, "circ_mv": None,\r\n        }\r\n\r\n        # \xe2\x94\x80\xe2\x94\x80 \xe8\xb7\xaf\xe5\xbe\x84\xe4\xb8\x80: AKShare \xe7\x9c\x9f\xe6\xad\xa3TTM \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n        try:\r\n            result = self._fetch_via_akshare_ttm(code, result)\r\n        except Exception as e:\r\n            logger.debug(f"AKShare TTM \xe8\xb7\xaf\xe5\xbe\x84\xe5\xa4\xb1\xe8\xb4\xa5 {code}: {e}")\r\n\r\n        # \xe2\x94\x80\xe2\x94\x80 \xe8\xb7\xaf\xe5\xbe\x84\xe4\xba\x8c: \xe5\xad\xa3\xe5\xba\xa6\xe2\x86\x92TTM \xe6\xbb\x9a\xe5\x8a\xa8\xe9\x99\x8d\xe7\xba\xa7 \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n        missing = [k for k, v in result.items() if v is None]\r\n        if missing:\r\n            try:\r\n                result = self._fetch_via_quarterly_fallback(code, result)\r\n            except Exception as e:\r\n                logger.debug(f"\xe5\xad\xa3\xe5\xba\xa6\xe9\x99\x8d\xe7\xba\xa7\xe8\xb7\xaf\xe5\xbe\x84\xe5\xa4\xb1\xe8\xb4\xa5 {code}: {e}")\r\n\r\n        # \xe2\x94\x80\xe2\x94\x80 \xe8\xb7\xaf\xe5\xbe\x84\xe4\xb8\x89: \xe5\xae\x9e\xe6\x97\xb6\xe8\xa1\x8c\xe6\x83\x85\xe8\xa1\xa5\xe5\x85\x85\xe5\xb8\x82\xe5\x80\xbc/PE \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n        if result.get("pe_ttm") is None or result.get("circ_mv") is None:\r\n            try:\r\n                result = self._fetch_realtime_supplement(code, result)\r\n            except Exception as e:\r\n                logger.debug(f"\xe5\xae\x9e\xe6\x97\xb6\xe8\xa1\x8c\xe6\x83\x85\xe8\xa1\xa5\xe5\x85\x85\xe5\xa4\xb1\xe8\xb4\xa5 {code}: {e}")\r\n\r\n        if any(v is not None for v in result.values()):\r\n            self._save_cache(code, result)\r\n        return result\r\n\r\n    def get_batch(self, codes: list) -> Dict[str, Optional[Dict]]:\r\n        """\xe6\x89\xb9\xe9\x87\x8f\xe8\x8e\xb7\xe5\x8f\x96\xe5\x9f\xba\xe6\x9c\xac\xe9\x9d\xa2\xe6\x95\xb0\xe6\x8d\xae"""\r\n        out = {}\r\n        for code in codes:\r\n            out[code] = self.get_fundamental(code)\r\n            time.sleep(0.05)\r\n        return out\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe5\x86\x85\xe9\x83\xa8\xe9\x87\x87\xe9\x9b\x86\xe6\x96\xb9\xe6\xb3\x95 \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    def _fetch_via_akshare_ttm(self, code: str, result: Dict) -> Dict:\r\n        """\r\n        \xe4\xbb\x8e AKShare stock_financial_analysis_indicator \xe8\x8e\xb7\xe5\x8f\x96\xe7\x9c\x9f\xe6\xad\xa3TTM\xe6\x8c\x87\xe6\xa0\x87\r\n        \xe6\xad\xa4\xe6\x8e\xa5\xe5\x8f\xa3\xe7\x9b\xb4\xe6\x8e\xa5\xe8\xbf\x94\xe5\x9b\x9e TTM/LF \xe5\x8f\xa3\xe5\xbe\x84\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe6\x97\xa0\xe9\x9c\x80\xe8\x87\xaa\xe8\xa1\x8c\xe6\xbb\x9a\xe5\x8a\xa8\xe8\xae\xa1\xe7\xae\x97\r\n        """\r\n        import akshare as ak\r\n        df = ak.stock_financial_analysis_indicator(symbol=code, start_year="2020")\r\n        if df is None or df.empty:\r\n            return result\r\n        # \xe5\x8f\x96\xe6\x9c\x80\xe6\x96\xb0\xe4\xb8\x80\xe8\xa1\x8c\r\n        row = df.iloc[-1]\r\n\r\n        # pe_ttm \xe2\x80\x94 \xe5\xad\x97\xe6\xae\xb5\xe5\x90\x8d\xe5\x8f\xaf\xe8\x83\xbd\xe5\x9b\xa0\xe7\x89\x88\xe6\x9c\xac\xe5\x8f\x98\xe5\x8c\x96\r\n        for col_pe in ["\xe5\xb8\x82\xe7\x9b\x88\xe7\x8e\x87(TTM)", "PE(TTM)", "pe_ttm", "\xe5\xb8\x82\xe7\x9b\x88\xe7\x8e\x87TTM"]:\r\n            if col_pe in row.index:\r\n                try:\r\n                    result["pe_ttm"] = float(row[col_pe])\r\n                    break\r\n                except Exception:\r\n                    pass\r\n\r\n        # pb_lf\r\n        for col_pb in ["\xe5\xb8\x82\xe5\x87\x80\xe7\x8e\x87", "PB", "pb", "pb_lf"]:\r\n            if col_pb in row.index:\r\n                try:\r\n                    result["pb_lf"] = float(row[col_pb])\r\n                    break\r\n                except Exception:\r\n                    pass\r\n\r\n        # roe_ttm\r\n        for col_roe in ["\xe5\x87\x80\xe8\xb5\x84\xe4\xba\xa7\xe6\x94\xb6\xe7\x9b\x8a\xe7\x8e\x87(TTM)", "ROE(TTM)", "roe_ttm", "\xe5\x8a\xa0\xe6\x9d\x83\xe5\x87\x80\xe8\xb5\x84\xe4\xba\xa7\xe6\x94\xb6\xe7\x9b\x8a\xe7\x8e\x87"]:\r\n            if col_roe in row.index:\r\n                try:\r\n                    v = float(row[col_roe])\r\n                    result["roe_ttm"] = v / 100.0 if v > 1.0 else v\r\n                    break\r\n                except Exception:\r\n                    pass\r\n\r\n        # net_profit_ttm (\xe4\xb8\x87\xe5\x85\x83)\r\n        for col_np in ["\xe5\x87\x80\xe5\x88\xa9\xe6\xb6\xa6(TTM)", "\xe5\xbd\x92\xe6\xaf\x8d\xe5\x87\x80\xe5\x88\xa9\xe6\xb6\xa6(TTM)", "\xe5\x87\x80\xe5\x88\xa9\xe6\xb6\xa6TTM"]:\r\n            if col_np in row.index:\r\n                try:\r\n                    result["net_profit_ttm"] = float(row[col_np])\r\n                    break\r\n                except Exception:\r\n                    pass\r\n\r\n        # revenue / profit growth\r\n        for col_rg in ["\xe8\x90\xa5\xe6\x94\xb6\xe5\x90\x8c\xe6\xaf\x94", "\xe8\x90\xa5\xe4\xb8\x9a\xe6\x94\xb6\xe5\x85\xa5\xe5\x90\x8c\xe6\xaf\x94\xe5\xa2\x9e\xe9\x95\xbf\xe7\x8e\x87", "revenue_growth"]:\r\n            if col_rg in row.index:\r\n                try:\r\n                    v = float(row[col_rg])\r\n                    result["revenue_growth"] = v / 100.0 if abs(v) > 1.5 else v\r\n                    break\r\n                except Exception:\r\n                    pass\r\n\r\n        for col_pg in ["\xe5\x87\x80\xe5\x88\xa9\xe6\xb6\xa6\xe5\x90\x8c\xe6\xaf\x94", "\xe5\xbd\x92\xe6\xaf\x8d\xe5\x87\x80\xe5\x88\xa9\xe6\xb6\xa6\xe5\x90\x8c\xe6\xaf\x94\xe5\xa2\x9e\xe9\x95\xbf\xe7\x8e\x87", "net_profit_growth"]:\r\n            if col_pg in row.index:\r\n                try:\r\n                    v = float(row[col_pg])\r\n                    result["net_profit_growth"] = v / 100.0 if abs(v) > 1.5 else v\r\n                    break\r\n                except Exception:\r\n                    pass\r\n\r\n        return result\r\n\r\n    def _fetch_via_quarterly_fallback(self, code: str, result: Dict) -> Dict:\r\n        """\xe5\xad\xa3\xe5\xba\xa6\xe6\x8a\xa5\xe8\xa1\xa8\xe2\x86\x92\xe6\x89\x8b\xe5\xb7\xa5\xe6\xbb\x9a\xe5\x8a\xa8TTM\xef\xbc\x88\xe9\x99\x8d\xe7\xba\xa7\xe8\xb7\xaf\xe5\xbe\x84\xef\xbc\x89"""\r\n        try:\r\n            import akshare as ak\r\n            # \xe5\x88\xa9\xe6\xb6\xa6\xe8\xa1\xa8\xe5\xad\xa3\xe5\xba\xa6\xe6\x95\xb0\xe6\x8d\xae\r\n            df = ak.stock_profit_statement_by_report_em(symbol=code)\r\n            if df is None or df.empty:\r\n                return result\r\n            # \xe6\x8c\x89\xe6\x8a\xa5\xe5\x91\x8a\xe6\x9c\x9f\xe6\x8e\x92\xe5\xba\x8f\r\n            date_col = [c for c in df.columns if "\xe6\x8a\xa5\xe5\x91\x8a\xe6\x9c\x9f" in c or "date" in c.lower()]\r\n            if date_col:\r\n                df[date_col[0]] = pd.to_datetime(df[date_col[0]], errors="coerce")\r\n                df = df.sort_values(date_col[0])\r\n            # \xe5\x8f\x96\xe6\x9c\x80\xe8\xbf\x914\xe6\x9c\x9f\xe6\xbb\x9a\xe5\x8a\xa8\xe6\xb1\x82\xe5\x92\x8c = TTM\xe5\x87\x80\xe5\x88\xa9\xe6\xb6\xa6\r\n            np_col = [c for c in df.columns if "\xe5\x87\x80\xe5\x88\xa9\xe6\xb6\xa6" in c and "\xe5\xbd\x92\xe6\xaf\x8d" in c]\r\n            if np_col and result.get("net_profit_ttm") is None:\r\n                vals = pd.to_numeric(df[np_col[0]].tail(4), errors="coerce").dropna()\r\n                if len(vals) >= 4:\r\n                    result["net_profit_ttm"] = float(vals.sum()) / 1e4  # \xe8\xbd\xac\xe4\xb8\x87\xe5\x85\x83\r\n        except Exception as e:\r\n            logger.debug(f"\xe5\xad\xa3\xe5\xba\xa6\xe9\x99\x8d\xe7\xba\xa7-\xe5\x87\x80\xe5\x88\xa9\xe6\xb6\xa6 {code}: {e}")\r\n\r\n        # \xe5\x90\x8c\xe6\xaf\x94\xe5\xa2\x9e\xe9\x95\xbf\xef\xbc\x88\xe4\xb8\xa4\xe5\xb9\xb4\xe5\xaf\xb9\xe6\xaf\x94\xef\xbc\x89\r\n        try:\r\n            import akshare as ak\r\n            df = ak.stock_financial_benefit_ths(symbol=code, indicator="\xe6\x8c\x89\xe5\xb9\xb4\xe5\xba\xa6")\r\n            if df is not None and not df.empty and len(df) >= 2:\r\n                rev_col = [c for c in df.columns if "\xe8\x90\xa5\xe4\xb8\x9a\xe6\x80\xbb\xe6\x94\xb6\xe5\x85\xa5" in c or "\xe8\x90\xa5\xe6\x94\xb6" in c]\r\n                npf_col = [c for c in df.columns if "\xe5\xbd\x92\xe6\xaf\x8d\xe5\x87\x80\xe5\x88\xa9\xe6\xb6\xa6" in c or "\xe5\x87\x80\xe5\x88\xa9\xe6\xb6\xa6" in c]\r\n                if rev_col and result.get("revenue_growth") is None:\r\n                    vals = pd.to_numeric(df[rev_col[0]].head(2), errors="coerce")\r\n                    if not vals.isna().any() and vals.iloc[1] > 0:\r\n                        result["revenue_growth"] = float(vals.iloc[0] / vals.iloc[1] - 1)\r\n                if npf_col and result.get("net_profit_growth") is None:\r\n                    vals = pd.to_numeric(df[npf_col[0]].head(2), errors="coerce")\r\n                    if not vals.isna().any() and vals.iloc[1] > 0:\r\n                        result["net_profit_growth"] = float(vals.iloc[0] / vals.iloc[1] - 1)\r\n        except Exception as e:\r\n            logger.debug(f"\xe5\xad\xa3\xe5\xba\xa6\xe9\x99\x8d\xe7\xba\xa7-\xe5\xa2\x9e\xe9\x80\x9f {code}: {e}")\r\n\r\n        return result\r\n\r\n    def _fetch_realtime_supplement(self, code: str, result: Dict) -> Dict:\r\n        """\xe5\xae\x9e\xe6\x97\xb6\xe8\xa1\x8c\xe6\x83\x85\xe8\xa1\xa5\xe5\x85\x85 PE / \xe6\xb5\x81\xe9\x80\x9a\xe5\xb8\x82\xe5\x80\xbc"""\r\n        try:\r\n            import akshare as ak\r\n            df = ak.stock_individual_info_em(symbol=code)\r\n            if df is None or df.empty:\r\n                return result\r\n            # \xe5\xb1\x95\xe5\xbc\x80 key-value \xe7\xbb\x93\xe6\x9e\x84\r\n            info = {}\r\n            if "item" in df.columns and "value" in df.columns:\r\n                info = dict(zip(df["item"].astype(str), df["value"].astype(str)))\r\n            elif len(df.columns) == 2:\r\n                info = dict(zip(df.iloc[:, 0].astype(str), df.iloc[:, 1].astype(str)))\r\n\r\n            def safe_float(s: str) -> Optional[float]:\r\n                try:\r\n                    s = s.replace(",", "").replace("\xe4\xba\xbf", "").strip()\r\n                    return float(s)\r\n                except Exception:\r\n                    return None\r\n\r\n            for k in ["\xe5\xb8\x82\xe7\x9b\x88\xe7\x8e\x87(\xe5\x8a\xa8)", "PE(TTM)", "\xe5\xb8\x82\xe7\x9b\x88\xe7\x8e\x87TTM"]:\r\n                if k in info and result.get("pe_ttm") is None:\r\n                    v = safe_float(info[k])\r\n                    if v is not None:\r\n                        result["pe_ttm"] = v\r\n\r\n            for k in ["\xe6\xb5\x81\xe9\x80\x9a\xe5\xb8\x82\xe5\x80\xbc", "\xe5\xb8\x82\xe5\x80\xbc"]:\r\n                if k in info and result.get("circ_mv") is None:\r\n                    v = safe_float(info[k])\r\n                    if v is not None:\r\n                        result["circ_mv"] = v * 1e4  # \xe4\xba\xbf\xe2\x86\x92\xe4\xb8\x87\xe5\x85\x83\r\n        except Exception as e:\r\n            logger.debug(f"\xe5\xae\x9e\xe6\x97\xb6\xe8\xa1\x8c\xe6\x83\x85\xe8\xa1\xa5\xe5\x85\x85\xe5\xa4\xb1\xe8\xb4\xa5 {code}: {e}")\r\n        return result\r\n'

FILE_src_data_industry_provider_py = b'#!/usr/bin/env python3\r\n"""\r\nQ-UNITY-V6 \xe8\xa1\x8c\xe4\xb8\x9a\xe6\x95\xb0\xe6\x8d\xae\xe6\x8f\x90\xe4\xbe\x9b\xe8\x80\x85\r\n"""\r\nfrom __future__ import annotations\r\nimport logging\r\nfrom typing import Optional\r\nimport pandas as pd\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\ndef fetch_and_save_industry_data(storage) -> bool:\r\n    """\xe4\xbb\x8e AKShare \xe8\x8e\xb7\xe5\x8f\x96\xe7\x94\xb3\xe4\xb8\x87\xe8\xa1\x8c\xe4\xb8\x9a\xe5\x88\x86\xe7\xb1\xbb\xe5\xb9\xb6\xe4\xbf\x9d\xe5\xad\x98"""\r\n    try:\r\n        import akshare as ak\r\n        df = ak.stock_board_industry_name_em()\r\n        if df is None or df.empty:\r\n            logger.error("\xe8\xa1\x8c\xe4\xb8\x9a\xe6\x95\xb0\xe6\x8d\xae\xe4\xb8\xba\xe7\xa9\xba")\r\n            return False\r\n        storage.save_industry_data(df)\r\n        logger.info(f"\xe8\xa1\x8c\xe4\xb8\x9a\xe6\x95\xb0\xe6\x8d\xae\xe5\xb7\xb2\xe4\xbf\x9d\xe5\xad\x98: {len(df)} \xe6\x9d\xa1")\r\n        return True\r\n    except ImportError:\r\n        logger.error("akshare \xe6\x9c\xaa\xe5\xae\x89\xe8\xa3\x85")\r\n        return False\r\n    except Exception as e:\r\n        logger.error(f"\xe8\xa1\x8c\xe4\xb8\x9a\xe6\x95\xb0\xe6\x8d\xae\xe8\x8e\xb7\xe5\x8f\x96\xe5\xa4\xb1\xe8\xb4\xa5: {e}")\r\n        return False\r\n\r\n\r\ndef load_industry_map(storage) -> Optional[pd.DataFrame]:\r\n    """\xe5\x8a\xa0\xe8\xbd\xbd\xe8\xa1\x8c\xe4\xb8\x9a\xe6\x98\xa0\xe5\xb0\x84\xe8\xa1\xa8"""\r\n    return storage.load_industry_data()\r\n'

FILE_src_data_collector_init_py = b'#!/usr/bin/env python3\r\n# -*- coding: utf-8 -*-\r\n"""\r\nsrc/data/collector \xe2\x80\x94 \xe5\x8f\x8c\xe8\xbd\xa8\xe5\xb9\xb6\xe8\xa1\x8c\xe9\x87\x87\xe9\x9b\x86\xe5\x8c\x85 (patch_v9)\r\n================================================\r\n\xe4\xb8\xbb\xe8\xa6\x81\xe6\x8e\xa5\xe5\x8f\xa3:\r\n  StockDataPipeline   \xe2\x80\x94 \xe4\xb8\xbb\xe9\x87\x87\xe9\x9b\x86\xe5\xbc\x95\xe6\x93\x8e\xef\xbc\x88\xe5\x8f\x8c\xe8\xbd\xa8\xe5\xb9\xb6\xe8\xa1\x8c\xef\xbc\x89\r\n  TDXConnectionPool   \xe2\x80\x94 \xe7\xba\xbf\xe7\xa8\x8b\xe5\xae\x89\xe5\x85\xa8 TDX \xe8\xbf\x9e\xe6\x8e\xa5\xe6\xb1\xa0\r\n  get_fastest_nodes   \xe2\x80\x94 24\xe8\x8a\x82\xe7\x82\xb9\xe8\xb5\x9b\xe9\xa9\xac\r\n  run_akshare_batch   \xe2\x80\x94 AKShare \xe8\xbf\x9b\xe7\xa8\x8b\xe6\xb1\xa0\xe6\x89\xb9\xe9\x87\x8f\xe9\x87\x87\xe9\x9b\x86\r\n  fetch_baostock      \xe2\x80\x94 BaoStock \xe5\x8d\x95\xe8\x82\xa1\xe9\x87\x87\xe9\x9b\x86\r\n  DataValidator       \xe2\x80\x94 \xe6\x95\xb0\xe6\x8d\xae\xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x88\xe4\xb8\x89\xe5\xb1\x82\xef\xbc\x89\r\n  RunReport           \xe2\x80\x94 \xe8\xbf\x90\xe8\xa1\x8c\xe6\x8a\xa5\xe5\x91\x8a\xe6\x8c\x81\xe4\xb9\x85\xe5\x8c\x96\r\n"""\r\n\r\nfrom .node_scanner import TDX_NODES, get_fastest_nodes, race_nodes\r\nfrom .tdx_pool import TDXConnectionPool, get_global_pool, reset_global_pool\r\nfrom .akshare_client import (\r\n    run_akshare_batch,\r\n    fetch_akshare_single,\r\n    _akshare_process_worker,\r\n    AK_EXTENDED_FIELDS,\r\n)\r\nfrom .baostock_client import fetch_baostock\r\nfrom .incremental import (\r\n    read_local_max_date, compute_missing_range,\r\n    is_up_to_date, merge_incremental, load_local_df, save_df,\r\n)\r\nfrom .validator import DataValidator, REQUIRED_COLS, MIN_ROWS\r\nfrom .run_report import RunReport\r\nfrom .pipeline import StockDataPipeline, update_single_stock\r\n\r\n__all__ = [\r\n    "TDX_NODES", "get_fastest_nodes", "race_nodes",\r\n    "TDXConnectionPool", "get_global_pool", "reset_global_pool",\r\n    "run_akshare_batch", "fetch_akshare_single", "AK_EXTENDED_FIELDS",\r\n    "fetch_baostock",\r\n    "read_local_max_date", "compute_missing_range",\r\n    "is_up_to_date", "merge_incremental", "load_local_df", "save_df",\r\n    "DataValidator", "REQUIRED_COLS", "MIN_ROWS",\r\n    "RunReport",\r\n    "StockDataPipeline", "update_single_stock",\r\n]\r\n'

FILE_src_data_collector_node_scanner_py = b'#!/usr/bin/env python3\r\n# -*- coding: utf-8 -*-\r\n"""\r\nnode_scanner.py \xe2\x80\x94 TDX 24 \xe8\x8a\x82\xe7\x82\xb9\xe8\xb5\x9b\xe9\xa9\xac\xe7\xad\x9b\xe9\x80\x89\xe6\xa8\xa1\xe5\x9d\x97\r\n==========================================\r\n\xe5\xb9\xb6\xe5\x8f\x91 TCP \xe6\x8e\xa2\xe9\x92\x88\xef\xbc\x8c\xe6\x8c\x89\xe5\xbb\xb6\xe8\xbf\x9f\xe5\x8d\x87\xe5\xba\x8f\xe6\x8e\x92\xe5\xba\x8f\xe3\x80\x82\r\n"""\r\n\r\nimport socket\r\nimport time\r\nimport logging\r\nfrom typing import List, Dict, Optional\r\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n# ============================================================================\r\n# 24 \xe4\xb8\xaa\xe5\xae\x9e\xe6\xb5\x8b\xe4\xbc\x98\xe9\x80\x89\xe8\x8a\x82\xe7\x82\xb9 (Port \xe5\x9d\x87\xe4\xb8\xba 7709)\r\n# ============================================================================\r\nTDX_NODES: List[Dict] = [\r\n    {"name": "node-01", "host": "116.205.183.150", "port": 7709},\r\n    {"name": "node-02", "host": "116.205.163.254", "port": 7709},\r\n    {"name": "node-03", "host": "110.41.2.72",     "port": 7709},\r\n    {"name": "node-04", "host": "110.41.147.114",  "port": 7709},\r\n    {"name": "node-05", "host": "111.230.186.52",  "port": 7709},\r\n    {"name": "node-06", "host": "124.71.9.153",    "port": 7709},\r\n    {"name": "node-07", "host": "116.205.171.132", "port": 7709},\r\n    {"name": "node-08", "host": "124.71.187.122",  "port": 7709},\r\n    {"name": "node-09", "host": "123.60.84.66",    "port": 7709},\r\n    {"name": "node-10", "host": "123.60.70.228",   "port": 7709},\r\n    {"name": "node-11", "host": "122.51.232.182",  "port": 7709},\r\n    {"name": "node-12", "host": "115.238.56.198",  "port": 7709},\r\n    {"name": "node-13", "host": "122.51.120.217",  "port": 7709},\r\n    {"name": "node-14", "host": "124.70.133.119",  "port": 7709},\r\n    {"name": "node-15", "host": "123.60.73.44",    "port": 7709},\r\n    {"name": "node-16", "host": "115.238.90.165",  "port": 7709},\r\n    {"name": "node-17", "host": "218.75.126.9",    "port": 7709},\r\n    {"name": "node-18", "host": "121.36.225.169",  "port": 7709},\r\n    {"name": "node-19", "host": "118.25.98.114",   "port": 7709},\r\n    {"name": "node-20", "host": "119.97.185.59",   "port": 7709},\r\n    {"name": "node-21", "host": "124.71.187.72",   "port": 7709},\r\n    {"name": "node-22", "host": "124.70.199.56",   "port": 7709},\r\n    {"name": "node-23", "host": "111.229.247.189", "port": 7709},\r\n    {"name": "node-24", "host": "180.153.18.170",  "port": 7709},\r\n]\r\n\r\n\r\ndef _probe_sync(node: Dict, timeout: float) -> Dict:\r\n    """TCP \xe6\x8f\xa1\xe6\x89\x8b\xe6\x8e\xa2\xe9\x92\x88\xef\xbc\x8c\xe6\xb5\x8b\xe9\x87\x8f\xe5\xae\x9e\xe9\x99\x85\xe8\xbf\x9e\xe6\x8e\xa5\xe5\xbb\xb6\xe8\xbf\x9f\xe3\x80\x82"""\r\n    start = time.perf_counter()\r\n    try:\r\n        with socket.create_connection((node["host"], node["port"]), timeout=timeout):\r\n            latency_ms = (time.perf_counter() - start) * 1000\r\n            return {**node, "latency_ms": round(latency_ms, 2), "status": "ok"}\r\n    except (socket.timeout, OSError) as exc:\r\n        return {**node, "latency_ms": -1.0, "status": f"fail:{type(exc).__name__}"}\r\n\r\n\r\ndef _sort_results(results: List[Dict]) -> List[Dict]:\r\n    return sorted(results, key=lambda x: (x["latency_ms"] < 0, x["latency_ms"]))\r\n\r\n\r\ndef race_nodes(\r\n    nodes: Optional[List[Dict]] = None,\r\n    timeout: float = 3.0,\r\n    workers: int = 32,\r\n) -> List[Dict]:\r\n    """\xe5\xb9\xb6\xe5\x8f\x91\xe8\xb5\x9b\xe9\xa9\xac\xef\xbc\x9a\xe5\x90\x8c\xe6\x97\xb6\xe5\x90\x91\xe6\x89\x80\xe6\x9c\x89\xe8\x8a\x82\xe7\x82\xb9\xe5\x8f\x91\xe5\x87\xba TCP \xe6\x8e\xa2\xe9\x92\x88\xe3\x80\x82"""\r\n    nodes = nodes or TDX_NODES\r\n    results: List[Dict] = []\r\n    with ThreadPoolExecutor(max_workers=min(workers, len(nodes))) as pool:\r\n        future_map = {pool.submit(_probe_sync, node, timeout): node for node in nodes}\r\n        for future in as_completed(future_map):\r\n            try:\r\n                results.append(future.result())\r\n            except Exception as exc:\r\n                node = future_map[future]\r\n                results.append({**node, "latency_ms": -1.0, "status": f"fail:{exc}"})\r\n    sorted_results = _sort_results(results)\r\n    ok_count = sum(1 for r in sorted_results if r["status"] == "ok")\r\n    logger.info("\xe8\x8a\x82\xe7\x82\xb9\xe8\xb5\x9b\xe9\xa9\xac: %d/%d \xe5\x8f\xaf\xe8\xbe\xbe\xef\xbc\x8c\xe6\x9c\x80\xe4\xbc\x98 %s (%.1f ms)",\r\n                ok_count, len(nodes),\r\n                sorted_results[0]["name"] if ok_count else "None",\r\n                sorted_results[0]["latency_ms"] if ok_count else -1)\r\n    return sorted_results\r\n\r\n\r\ndef get_fastest_nodes(top_n: int = 5, timeout: float = 3.0) -> List[Dict]:\r\n    """\xe8\xbf\x94\xe5\x9b\x9e\xe5\xbb\xb6\xe8\xbf\x9f\xe6\x9c\x80\xe4\xbd\x8e\xe7\x9a\x84 top_n \xe4\xb8\xaa\xe5\x8f\xaf\xe7\x94\xa8\xe8\x8a\x82\xe7\x82\xb9\xe3\x80\x82"""\r\n    all_results = race_nodes(timeout=timeout)\r\n    ok_nodes = [r for r in all_results if r["status"] == "ok"]\r\n    selected = ok_nodes[:top_n]\r\n    if not selected:\r\n        logger.warning("\xe6\x89\x80\xe6\x9c\x89\xe8\x8a\x82\xe7\x82\xb9\xe4\xb8\x8d\xe5\x8f\xaf\xe8\xbe\xbe\xef\xbc\x81\xe8\xbf\x94\xe5\x9b\x9e\xe9\xbb\x98\xe8\xae\xa4\xe8\x8a\x82\xe7\x82\xb9\xef\xbc\x88\xe6\x9c\xaa\xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x89")\r\n        return [dict(n, latency_ms=-1.0, status="unknown") for n in TDX_NODES[:top_n]]\r\n    return selected\r\n'

FILE_src_data_collector_tdx_pool_py = b'#!/usr/bin/env python3\r\n# -*- coding: utf-8 -*-\r\n"""\r\ntdx_pool.py \xe2\x80\x94 TDX \xe7\xba\xbf\xe7\xa8\x8b\xe5\xae\x89\xe5\x85\xa8\xe8\xbf\x9e\xe6\x8e\xa5\xe6\xb1\xa0 (threading.local)\r\n====================================================\r\npytdx \xe7\x9a\x84 TdxHq_API \xe4\xb8\x8d\xe6\x98\xaf\xe7\xba\xbf\xe7\xa8\x8b\xe5\xae\x89\xe5\x85\xa8\xe7\x9a\x84\xe3\x80\x82\r\n\xe6\x9c\xac\xe6\xa8\xa1\xe5\x9d\x97\xe9\x80\x9a\xe8\xbf\x87 threading.local() \xe4\xbf\x9d\xe8\xaf\x81\xe6\xaf\x8f\xe7\xba\xbf\xe7\xa8\x8b\xe7\x8b\xac\xe7\xab\x8b socket \xe8\xbf\x9e\xe6\x8e\xa5\xe3\x80\x82\r\n"""\r\n\r\nimport random\r\nimport threading\r\nimport logging\r\nfrom typing import List, Dict, Optional\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\ntry:\r\n    from pytdx.hq import TdxHq_API\r\n    from pytdx.params import TDXParams\r\n    _PYTDX_AVAILABLE = True\r\nexcept ImportError:\r\n    TdxHq_API = None   # type: ignore[assignment,misc]\r\n    TDXParams  = None  # type: ignore[assignment]\r\n    _PYTDX_AVAILABLE = False\r\n\r\n\r\nclass TDXConnectionPool:\r\n    """\r\n    \xe7\xba\xbf\xe7\xa8\x8b\xe5\xae\x89\xe5\x85\xa8 TDX \xe8\xbf\x9e\xe6\x8e\xa5\xe6\xb1\xa0\xe3\x80\x82\r\n    \xe6\xaf\x8f\xe7\xba\xbf\xe7\xa8\x8b\xe9\x80\x9a\xe8\xbf\x87 get_connection() \xe8\x8e\xb7\xe5\x8f\x96\xe4\xb8\x93\xe5\xb1\x9e TdxHq_API\xef\xbc\x8c\xe9\x95\xbf\xe8\xbf\x9e\xe6\x8e\xa5\xe5\xa4\x8d\xe7\x94\xa8\xe3\x80\x82\r\n    """\r\n\r\n    def __init__(self, top_nodes: List[Dict], timeout: float = 10.0, max_retry: int = 3) -> None:\r\n        if not _PYTDX_AVAILABLE:\r\n            raise ImportError("pytdx \xe6\x9c\xaa\xe5\xae\x89\xe8\xa3\x85\xef\xbc\x8c\xe8\xaf\xb7: pip install pytdx")\r\n        if not top_nodes:\r\n            raise ValueError("top_nodes \xe4\xb8\x8d\xe8\x83\xbd\xe4\xb8\xba\xe7\xa9\xba")\r\n        self.top_nodes = top_nodes\r\n        self.timeout   = timeout\r\n        self.max_retry = max_retry\r\n        self._local    = threading.local()\r\n        logger.info("TDXConnectionPool: %d \xe8\x8a\x82\xe7\x82\xb9\xef\xbc\x8c\xe8\xb6\x85\xe6\x97\xb6=%.1fs", len(top_nodes), timeout)\r\n\r\n    def _create_connection(self) -> Optional["TdxHq_API"]:\r\n        top_pool = self.top_nodes[:3].copy()\r\n        random.shuffle(top_pool)\r\n        candidate_order = top_pool + self.top_nodes[3:]\r\n        attempts = min(self.max_retry, len(candidate_order))\r\n        for i in range(attempts):\r\n            node = candidate_order[i]\r\n            api  = TdxHq_API(heartbeat=True, auto_retry=True)\r\n            try:\r\n                api.connect(node["host"], node["port"], time_out=self.timeout)\r\n                logger.debug("[TID-%s] \xe8\xbf\x9e\xe6\x8e\xa5 \xe2\x86\x92 %s", threading.get_ident(), node["name"])\r\n                return api\r\n            except Exception as exc:\r\n                logger.warning("[TID-%s] \xe8\xbf\x9e\xe6\x8e\xa5\xe5\xa4\xb1\xe8\xb4\xa5 %s: %s", threading.get_ident(), node["name"], exc)\r\n                try:\r\n                    api.disconnect()\r\n                except Exception:\r\n                    pass\r\n        logger.error("[TID-%s] \xe6\x89\x80\xe6\x9c\x89\xe8\x8a\x82\xe7\x82\xb9\xe8\xbf\x9e\xe6\x8e\xa5\xe5\xa4\xb1\xe8\xb4\xa5", threading.get_ident())\r\n        return None\r\n\r\n    def _connect_best(self) -> Optional["TdxHq_API"]:\r\n        """\xe5\xaf\xb9\xe5\xa4\x96\xe7\xbb\x9f\xe4\xb8\x80\xe5\x85\xa5\xe5\x8f\xa3\xef\xbc\x9a\xe4\xbb\x8e\xe6\x9c\x80\xe4\xbc\x98\xe8\x8a\x82\xe7\x82\xb9\xe6\xb1\xa0\xe9\x87\x8d\xe6\x96\xb0\xe5\xbb\xba\xe7\xab\x8b\xe8\xbf\x9e\xe6\x8e\xa5\xe5\xb9\xb6\xe6\x9b\xb4\xe6\x96\xb0\xe7\xba\xbf\xe7\xa8\x8b\xe6\x9c\xac\xe5\x9c\xb0\xe5\xad\x98\xe5\x82\xa8\xe3\x80\x82"""\r\n        api = self._create_connection()\r\n        self._local.api = api\r\n        return api\r\n\r\n    def get_connection(self) -> Optional["TdxHq_API"]:\r\n        """\xe8\x8e\xb7\xe5\x8f\x96/\xe5\xa4\x8d\xe7\x94\xa8\xe5\xbd\x93\xe5\x89\x8d\xe7\xba\xbf\xe7\xa8\x8b\xe7\x9a\x84 TdxHq_API \xe8\xbf\x9e\xe6\x8e\xa5\xef\xbc\x88\xe5\x90\xab\xe6\x8e\xa2\xe6\xb4\xbb\xe8\x87\xaa\xe6\x84\x88\xe5\xbf\x83\xe8\xb7\xb3\xef\xbc\x89\xe3\x80\x82"""\r\n        if hasattr(self._local, "api") and self._local.api is not None:\r\n            # \xe6\x8e\xa2\xe6\xb4\xbb\xef\xbc\x9a\xe6\x89\xa7\xe8\xa1\x8c\xe6\x9c\x80\xe8\xbd\xbb\xe9\x87\x8f\xe8\xaf\xb7\xe6\xb1\x82\xe9\xaa\x8c\xe8\xaf\x81\xe8\xbf\x9e\xe6\x8e\xa5\xe5\xad\x98\xe6\xb4\xbb\r\n            try:\r\n                self._local.api.get_security_count(0)\r\n                return self._local.api\r\n            except Exception:\r\n                # \xe9\x95\xbf\xe8\xbf\x9e\xe6\x8e\xa5\xe5\x9b\xa0\xe7\xbd\x91\xe7\xbb\x9c\xe6\xb3\xa2\xe5\x8a\xa8\xe5\x81\x87\xe6\xad\xbb\xef\xbc\x8c\xe8\xa7\xa6\xe5\x8f\x91\xe8\x87\xaa\xe6\x84\x88\xe9\x87\x8d\xe8\xbf\x9e\r\n                logger.info("[TID-%s] \xe8\xbf\x9e\xe6\x8e\xa5\xe5\xa4\xb1\xe6\x95\x88\xef\xbc\x8c\xe6\xad\xa3\xe5\x9c\xa8\xe9\x87\x8d\xe8\xbf\x9e", threading.get_ident())\r\n                self._safe_disconnect(self._local.api)\r\n                self._local.api = None\r\n                return self._connect_best()\r\n        # \xe7\xba\xbf\xe7\xa8\x8b\xe9\xa6\x96\xe6\xac\xa1\xe8\x8e\xb7\xe5\x8f\x96\xe8\xbf\x9e\xe6\x8e\xa5\r\n        return self._connect_best()\r\n\r\n    def release(self) -> None:\r\n        api = getattr(self._local, "api", None)\r\n        if api is not None:\r\n            self._safe_disconnect(api)\r\n            self._local.api = None\r\n\r\n    def close_all(self) -> None:\r\n        self.release()\r\n\r\n    @staticmethod\r\n    def _safe_disconnect(api: "TdxHq_API") -> None:\r\n        try:\r\n            api.disconnect()\r\n        except Exception:\r\n            pass\r\n\r\n    def __enter__(self) -> Optional["TdxHq_API"]:\r\n        return self.get_connection()\r\n\r\n    def __exit__(self, *_) -> None:\r\n        pass\r\n\r\n\r\n_global_pool: Optional[TDXConnectionPool] = None\r\n_pool_lock = threading.Lock()\r\n\r\n\r\ndef get_global_pool(top_nodes: Optional[List[Dict]] = None, timeout: float = 10.0) -> TDXConnectionPool:\r\n    global _global_pool\r\n    if _global_pool is None:\r\n        with _pool_lock:\r\n            if _global_pool is None:\r\n                if top_nodes is None:\r\n                    raise ValueError("\xe9\xa6\x96\xe6\xac\xa1\xe8\xb0\x83\xe7\x94\xa8\xe5\xbf\x85\xe9\xa1\xbb\xe6\x8f\x90\xe4\xbe\x9b top_nodes")\r\n                _global_pool = TDXConnectionPool(top_nodes, timeout=timeout)\r\n    return _global_pool\r\n\r\n\r\ndef reset_global_pool() -> None:\r\n    global _global_pool\r\n    with _pool_lock:\r\n        if _global_pool is not None:\r\n            _global_pool.close_all()\r\n        _global_pool = None\r\n'

FILE_src_data_collector_akshare_client_py = b'#!/usr/bin/env python3\r\n# -*- coding: utf-8 -*-\r\n"""\r\nakshare_client.py \xe2\x80\x94 AKShare \xe8\xbf\x9b\xe7\xa8\x8b\xe9\x9a\x94\xe7\xa6\xbb\xe9\x87\x87\xe9\x9b\x86\xe5\xae\xa2\xe6\x88\xb7\xe7\xab\xaf (patch_v9)\r\n==========================================================\r\n\r\n\xe3\x80\x90\xe8\xae\xbe\xe8\xae\xa1\xe5\x86\xb3\xe7\xad\x96\xe8\xaf\xb4\xe6\x98\x8e\xe3\x80\x91\r\nAKShare \xe5\xba\x95\xe5\xb1\x82\xe4\xbd\xbf\xe7\x94\xa8 requests.Session \xe5\xb9\xb6\xe5\x9c\xa8\xe6\xa8\xa1\xe5\x9d\x97\xe7\xba\xa7\xe7\xbb\xb4\xe6\x8a\xa4\xe5\x85\xa8\xe5\xb1\x80 HTTP \xe4\xbc\x9a\xe8\xaf\x9d\xe7\x8a\xb6\xe6\x80\x81\xe3\x80\x82\r\n\xe5\xa4\x9a\xe7\xba\xbf\xe7\xa8\x8b\xe5\xb9\xb6\xe5\x8f\x91\xe8\xb0\x83\xe7\x94\xa8\xe6\x97\xb6\xef\xbc\x8c\xe5\xa4\x9a\xe4\xb8\xaa\xe7\xba\xbf\xe7\xa8\x8b\xe5\x85\xb1\xe4\xba\xab\xe5\x90\x8c\xe4\xb8\x80\xe8\xbf\x9b\xe7\xa8\x8b\xe7\x9a\x84\xe5\x85\xa8\xe5\xb1\x80 session\xef\xbc\x8c\xe5\xaf\xbc\xe8\x87\xb4\xef\xbc\x9a\r\n  - Cookie/Header \xe7\x8a\xb6\xe6\x80\x81\xe7\xab\x9e\xe4\xba\x89 \xe2\x86\x92 \xe6\x9c\x8d\xe5\x8a\xa1\xe7\xab\xaf\xe9\xa3\x8e\xe6\x8e\xa7\xe8\xaf\xaf\xe5\x88\xa4\r\n  - \xe5\x90\x8c\xe4\xb8\x80 session \xe5\xb9\xb6\xe5\x8f\x91\xe8\xaf\xb7\xe6\xb1\x82\xe8\xa2\xab\xe8\xaf\x86\xe5\x88\xab\xe4\xb8\xba\xe5\x90\x8c\xe4\xb8\x80\xe6\x9d\xa5\xe6\xba\x90 \xe2\x86\x92 \xe9\x99\x90\xe6\xb5\x81\xe6\xa6\x82\xe7\x8e\x87\xe6\x8c\x87\xe6\x95\xb0\xe7\xba\xa7\xe4\xb8\x8a\xe5\x8d\x87\r\n  - \xe5\x81\xb6\xe5\x8f\x91\xe6\x80\xa7\xe5\x93\x8d\xe5\xba\x94\xe9\x94\x99\xe4\xbd\x8d\xef\xbc\x88\xe7\xba\xbf\xe7\xa8\x8b A \xe7\x9a\x84\xe5\x93\x8d\xe5\xba\x94\xe8\xa2\xab\xe7\xba\xbf\xe7\xa8\x8b B \xe8\xaf\xbb\xe5\x8f\x96\xef\xbc\x89\r\n\r\n\xe5\x9b\xa0\xe6\xad\xa4\xef\xbc\x8cAKShare \xe5\xbf\x85\xe9\xa1\xbb\xe5\x9c\xa8\xe7\x8b\xac\xe7\xab\x8b\xe5\xad\x90\xe8\xbf\x9b\xe7\xa8\x8b\xe4\xb8\xad\xe8\xb0\x83\xe7\x94\xa8\xef\xbc\x8c\xe6\xaf\x8f\xe4\xb8\xaa\xe5\xad\x90\xe8\xbf\x9b\xe7\xa8\x8b\xe6\x8b\xa5\xe6\x9c\x89\xe5\xae\x8c\xe5\x85\xa8\xe7\x8b\xac\xe7\xab\x8b\xe7\x9a\x84 session\xe3\x80\x82\r\n\xe6\x9c\xac\xe6\xa8\xa1\xe5\x9d\x97\xe6\x8f\x90\xe4\xbe\x9b\xef\xbc\x9a\r\n  1. _akshare_process_worker()  \xe2\x80\x94 \xe9\xa1\xb6\xe5\xb1\x82\xe5\x8f\xaf\xe5\xba\x8f\xe5\x88\x97\xe5\x8c\x96\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe5\x9c\xa8\xe5\xad\x90\xe8\xbf\x9b\xe7\xa8\x8b\xe4\xb8\xad\xe8\xbf\x90\xe8\xa1\x8c\r\n  2. run_akshare_batch()        \xe2\x80\x94 ProcessPoolExecutor \xe6\x89\xb9\xe9\x87\x8f\xe8\xb0\x83\xe5\xba\xa6\xe6\x8e\xa5\xe5\x8f\xa3\r\n  3. fetch_akshare_single()     \xe2\x80\x94 \xe5\x8d\x95\xe8\x82\xa1\xe5\x90\x8c\xe6\xad\xa5\xe6\x8e\xa5\xe5\x8f\xa3\xef\xbc\x88\xe4\xb8\xbb\xe8\xbf\x9b\xe7\xa8\x8b\xe8\xb0\x83\xe7\x94\xa8\xef\xbc\x8c\xe4\xbe\x9b\xe6\xb5\x8b\xe8\xaf\x95\xe7\x94\xa8\xef\xbc\x89\r\n\r\n\xe3\x80\x90\xe5\xa4\x8d\xe6\x9d\x83\xe6\x96\xb9\xe5\xbc\x8f\xe3\x80\x91\xe7\xbb\x9f\xe4\xb8\x80 hfq\xef\xbc\x88\xe5\x90\x8e\xe5\xa4\x8d\xe6\x9d\x83\xef\xbc\x89\r\n\xe9\x87\x8f\xe5\x8c\x96\xe5\x9b\x9e\xe6\xb5\x8b\xe5\xbf\x85\xe9\xa1\xbb\xe4\xbd\xbf\xe7\x94\xa8\xe5\x90\x8e\xe5\xa4\x8d\xe6\x9d\x83\xef\xbc\x9a\xe5\x8e\x86\xe5\x8f\xb2\xe4\xbb\xb7\xe6\xa0\xbc\xe8\xbf\x9e\xe7\xbb\xad\xef\xbc\x8c\xe5\x8a\xa8\xe9\x87\x8f/\xe5\x8f\x8d\xe8\xbd\xac\xe5\x9b\xa0\xe5\xad\x90\xe5\x87\x86\xe7\xa1\xae\xef\xbc\x8c\xe5\x9b\x9e\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\xe5\x8f\xaf\xe9\x87\x8d\xe7\x8e\xb0\xe3\x80\x82\r\n\xe5\x89\x8d\xe5\xa4\x8d\xe6\x9d\x83\xef\xbc\x88qfq\xef\xbc\x89\xe4\xbc\x9a\xe9\x9a\x8f\xe6\xaf\x8f\xe6\xac\xa1\xe9\x99\xa4\xe6\x9d\x83\xe4\xba\x8b\xe4\xbb\xb6\xe9\x87\x8d\xe5\x86\x99\xe5\x8e\x86\xe5\x8f\xb2\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8c\xe5\xaf\xbc\xe8\x87\xb4\xe5\x9b\x9e\xe6\xb5\x8b\xe4\xb8\x8d\xe4\xb8\x80\xe8\x87\xb4\xe3\x80\x82\r\n\r\n\xe3\x80\x90\xe9\x99\x90\xe6\xb5\x81\xe6\x84\x9f\xe7\x9f\xa5\xe9\x80\x80\xe9\x81\xbf\xe7\xad\x96\xe7\x95\xa5\xe3\x80\x91\r\n\xe4\xb8\x9c\xe6\x96\xb9\xe8\xb4\xa2\xe5\xaf\x8c\xe6\x8e\xa5\xe5\x8f\xa3\xe9\x99\x90\xe6\xb5\x81\xe7\x89\xb9\xe5\xbe\x81\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xef\xbc\x9a429 / \xe9\x99\x90\xe6\xb5\x81 / \xe9\xa2\x91\xe7\xb9\x81 / too many\r\n\xe8\xa7\xa6\xe5\x8f\x91\xe9\x99\x90\xe6\xb5\x81\xe6\x97\xb6\xe7\xad\x89\xe5\xbe\x85 30s/60s/90s\xef\xbc\x88\xe8\xbf\x9c\xe9\x95\xbf\xe4\xba\x8e\xe6\x99\xae\xe9\x80\x9a\xe9\x94\x99\xe8\xaf\xaf\xe7\x9a\x84 1s/2s/4s\xef\xbc\x89\xe3\x80\x82\r\n"""\r\n\r\nimport time\r\nimport random\r\nimport logging\r\nfrom typing import Optional, Tuple, List, Dict, Any\r\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n# \xe4\xb8\x9c\xe6\x96\xb9\xe8\xb4\xa2\xe5\xaf\x8c\xe9\x99\x90\xe6\xb5\x81\xe7\x89\xb9\xe5\xbe\x81\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xef\xbc\x88AKShare \xe5\xba\x95\xe5\xb1\x82\xe7\x88\xac\xe5\x8f\x96\xe4\xb8\x9c\xe6\x96\xb9\xe8\xb4\xa2\xe5\xaf\x8c API\xef\xbc\x89\r\n_RATELIMIT_KEYWORDS = ("429", "\xe9\x99\x90\xe6\xb5\x81", "\xe9\xa2\x91\xe7\xb9\x81", "too many", "Too Many", "rate limit")\r\n\r\n# AKShare \xe2\x86\x92 \xe6\xa0\x87\xe5\x87\x86\xe5\x88\x97\xe5\x90\x8d\xe6\x98\xa0\xe5\xb0\x84\r\n_AK_COL_MAP = {\r\n    "\xe6\x97\xa5\xe6\x9c\x9f":  "date",\r\n    "\xe5\xbc\x80\xe7\x9b\x98":  "open",\r\n    "\xe6\x94\xb6\xe7\x9b\x98":  "close",\r\n    "\xe6\x9c\x80\xe9\xab\x98":  "high",\r\n    "\xe6\x9c\x80\xe4\xbd\x8e":  "low",\r\n    "\xe6\x88\x90\xe4\xba\xa4\xe9\x87\x8f": "vol",\r\n    "\xe6\x88\x90\xe4\xba\xa4\xe9\xa2\x9d": "amount",\r\n    "\xe6\x8c\xaf\xe5\xb9\x85":  "amplitude",\r\n    "\xe6\xb6\xa8\xe8\xb7\x8c\xe5\xb9\x85": "pct_change",\r\n    "\xe6\xb6\xa8\xe8\xb7\x8c\xe9\xa2\x9d": "change",\r\n    "\xe6\x8d\xa2\xe6\x89\x8b\xe7\x8e\x87": "turnover",\r\n}\r\n\r\n# \xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5\xef\xbc\x88TDX \xe4\xb8\x8d\xe6\x8f\x90\xe4\xbe\x9b\xef\xbc\x8cAKShare \xe4\xb8\x93\xe5\xb1\x9e\xef\xbc\x89\r\nAK_EXTENDED_FIELDS = {"amplitude", "pct_change", "change", "turnover"}\r\n\r\n\r\n# ============================================================================\r\n# \xe5\xad\x90\xe8\xbf\x9b\xe7\xa8\x8b\xe5\xb7\xa5\xe4\xbd\x9c\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x88\xe5\xbf\x85\xe9\xa1\xbb\xe6\x98\xaf\xe9\xa1\xb6\xe5\xb1\x82\xe5\x87\xbd\xe6\x95\xb0\xef\xbc\x8c\xe6\x89\x8d\xe8\x83\xbd\xe8\xa2\xab pickle \xe5\xba\x8f\xe5\x88\x97\xe5\x8c\x96\xe4\xbc\xa0\xe5\x85\xa5\xe5\xad\x90\xe8\xbf\x9b\xe7\xa8\x8b\xef\xbc\x89\r\n# ============================================================================\r\n\r\ndef _akshare_process_worker(\r\n    task: Tuple[str, str, str, int, float, float]\r\n) -> Tuple[str, Optional[Any], Optional[str]]:\r\n    """\r\n    \xe5\x9c\xa8\xe7\x8b\xac\xe7\xab\x8b\xe5\xad\x90\xe8\xbf\x9b\xe7\xa8\x8b\xe4\xb8\xad\xe9\x87\x87\xe9\x9b\x86\xe5\x8d\x95\xe5\x8f\xaa\xe8\x82\xa1\xe7\xa5\xa8\xe7\x9a\x84 AKShare \xe6\x95\xb0\xe6\x8d\xae\xe3\x80\x82\r\n\r\n    Args:\r\n        task: (code, start_date, end_date, max_retries, delay_min, delay_max)\r\n\r\n    Returns:\r\n        (code, df_dict_or_None, error_msg_or_None)\r\n        \xe6\xb3\xa8\xe6\x84\x8f\xef\xbc\x9aDataFrame \xe4\xb8\x8d\xe8\x83\xbd\xe7\x9b\xb4\xe6\x8e\xa5 pickle\xef\xbc\x8c\xe9\x80\x9a\xe8\xbf\x87 to_dict("records") \xe4\xbc\xa0\xe5\x9b\x9e\xe4\xb8\xbb\xe8\xbf\x9b\xe7\xa8\x8b\xe3\x80\x82\r\n    """\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe5\xad\x90\xe8\xbf\x9b\xe7\xa8\x8b\xe7\xba\xa7\xe7\x8b\xac\xe7\xab\x8b import\xef\xbc\x8c\xe8\x8e\xb7\xe5\xbe\x97\xe5\xae\x8c\xe5\x85\xa8\xe7\x8b\xac\xe7\xab\x8b\xe7\x9a\x84 session \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n    try:\r\n        import akshare as ak\r\n    except ImportError:\r\n        return (task[0], None, "akshare_not_installed")\r\n\r\n    import pandas as pd\r\n\r\n    code, start_date, end_date, max_retries, delay_min, delay_max = task\r\n\r\n    # \xe7\xbb\x9f\xe4\xb8\x80\xe6\x97\xa5\xe6\x9c\x9f\xe6\xa0\xbc\xe5\xbc\x8f\xe4\xb8\xba YYYYMMDD\xef\xbc\x88AKShare \xe8\xa6\x81\xe6\xb1\x82\xef\xbc\x89\r\n    start_fmt = start_date.replace("-", "")\r\n    end_fmt   = end_date.replace("-", "")\r\n\r\n    for attempt in range(max_retries):\r\n        try:\r\n            # \xe9\x9a\x8f\xe6\x9c\xba\xe5\xbb\xb6\xe8\xbf\x9f\xef\xbc\x88\xe9\x98\xb2\xe5\xb0\x81\xef\xbc\x89\r\n            time.sleep(random.uniform(delay_min, delay_max))\r\n\r\n            df = ak.stock_zh_a_hist(\r\n                symbol=code,\r\n                period="daily",\r\n                start_date=start_fmt,\r\n                end_date=end_fmt,\r\n                adjust="hfq",   # \xe5\x90\x8e\xe5\xa4\x8d\xe6\x9d\x83\xef\xbc\x8c\xe9\x87\x8f\xe5\x8c\x96\xe5\x9b\x9e\xe6\xb5\x8b\xe6\xa0\x87\xe5\x87\x86\r\n            )\r\n\r\n            if df is None or df.empty:\r\n                raise ValueError(f"\xe8\xbf\x94\xe5\x9b\x9e\xe7\xa9\xba\xe6\x95\xb0\xe6\x8d\xae")\r\n\r\n            # \xe5\x88\x97\xe5\x90\x8d\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\r\n            df = df.rename(columns=_AK_COL_MAP)\r\n            df["code"]   = code\r\n            df["source"] = "akshare"\r\n            df["adjust"] = "hfq"\r\n\r\n            # date \xe6\xa0\xbc\xe5\xbc\x8f\xe7\xbb\x9f\xe4\xb8\x80\r\n            df["date"] = pd.to_datetime(df["date"]).dt.strftime("%Y-%m-%d")\r\n\r\n            # \xe6\x95\xb0\xe5\x80\xbc\xe7\xb1\xbb\xe5\x9e\x8b\r\n            for col in ("open", "high", "low", "close"):\r\n                if col in df.columns:\r\n                    df[col] = pd.to_numeric(df[col], errors="coerce").astype("float32")\r\n            for col in ("vol", "amount"):\r\n                if col in df.columns:\r\n                    df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0).astype("int64")\r\n            for col in ("pct_change", "turnover", "amplitude", "change"):\r\n                if col in df.columns:\r\n                    df[col] = pd.to_numeric(df[col], errors="coerce").astype("float32")\r\n\r\n            # \xe9\x80\x9a\xe8\xbf\x87 dict \xe4\xbc\xa0\xe5\x9b\x9e\xef\xbc\x88DataFrame \xe6\x97\xa0\xe6\xb3\x95\xe8\xb7\xa8\xe8\xbf\x9b\xe7\xa8\x8b pickle\xef\xbc\x89\r\n            return (code, df.to_dict("records"), None)\r\n\r\n        except Exception as exc:\r\n            err_str = str(exc)\r\n            # \xe9\x99\x90\xe6\xb5\x81\xe6\xa3\x80\xe6\xb5\x8b\r\n            is_ratelimit = any(kw in err_str for kw in _RATELIMIT_KEYWORDS)\r\n            if is_ratelimit:\r\n                wait = 30.0 * (attempt + 1)   # 30s / 60s / 90s\r\n            else:\r\n                wait = (2 ** attempt) * (1 + random.random() * 0.3)  # 1s / 2s / 4s + \xe6\x8a\x96\xe5\x8a\xa8\r\n\r\n            if attempt < max_retries - 1:\r\n                time.sleep(wait)\r\n            else:\r\n                return (code, None, f"all_retries_failed:{err_str[:120]}")\r\n\r\n    return (code, None, "unknown_error")\r\n\r\n\r\n# ============================================================================\r\n# \xe6\x89\xb9\xe9\x87\x8f\xe8\xb0\x83\xe5\xba\xa6\xe6\x8e\xa5\xe5\x8f\xa3\xef\xbc\x88\xe4\xb8\xbb\xe8\xbf\x9b\xe7\xa8\x8b\xe8\xb0\x83\xe7\x94\xa8\xef\xbc\x89\r\n# ============================================================================\r\n\r\ndef run_akshare_batch(\r\n    stock_list: List[Tuple[str, str, str]],\r\n    max_workers: int = 2,\r\n    max_retries: int = 3,\r\n    delay_min: float = 0.3,\r\n    delay_max: float = 0.8,\r\n    progress_callback=None,\r\n) -> Dict[str, Optional[Any]]:\r\n    """\r\n    \xe4\xbd\xbf\xe7\x94\xa8 ProcessPoolExecutor \xe6\x89\xb9\xe9\x87\x8f\xe9\x87\x87\xe9\x9b\x86 AKShare \xe6\x95\xb0\xe6\x8d\xae\xe3\x80\x82\r\n\r\n    Args:\r\n        stock_list:        [(code, start_date, end_date), ...]\r\n        max_workers:       \xe8\xbf\x9b\xe7\xa8\x8b\xe6\x95\xb0\xef\xbc\x88\xe5\xbb\xba\xe8\xae\xae 2\xef\xbc\x8c\xe4\xb8\x9c\xe6\x96\xb9\xe8\xb4\xa2\xe5\xaf\x8c\xe6\x8e\xa5\xe5\x8f\xa3\xe5\xb9\xb6\xe5\x8f\x91\xe9\x99\x90\xe5\x88\xb6\xe4\xb8\xa5\xe6\xa0\xbc\xef\xbc\x89\r\n        max_retries:       \xe5\x8d\x95\xe8\x82\xa1\xe6\x9c\x80\xe5\xa4\xa7\xe9\x87\x8d\xe8\xaf\x95\xe6\xac\xa1\xe6\x95\xb0\r\n        delay_min/max:     \xe5\xad\x90\xe8\xbf\x9b\xe7\xa8\x8b\xe5\x86\x85\xe9\x9a\x8f\xe6\x9c\xba sleep \xe5\x8c\xba\xe9\x97\xb4\xef\xbc\x88\xe7\xa7\x92\xef\xbc\x89\r\n        progress_callback: fn(code, success, error) \xe8\xbf\x9b\xe5\xba\xa6\xe5\x9b\x9e\xe8\xb0\x83\r\n\r\n    Returns:\r\n        {code: df_or_None}  DataFrame \xe6\xa0\xbc\xe5\xbc\x8f\r\n    """\r\n    import pandas as pd\r\n\r\n    if not stock_list:\r\n        return {}\r\n\r\n    # \xe6\x9e\x84\xe5\xbb\xba\xe4\xbb\xbb\xe5\x8a\xa1 tuple\r\n    tasks = [\r\n        (code, start, end, max_retries, delay_min, delay_max)\r\n        for code, start, end in stock_list\r\n    ]\r\n\r\n    results: Dict[str, Optional[Any]] = {}\r\n\r\n    with ProcessPoolExecutor(max_workers=max_workers) as pool:\r\n        future_map = {\r\n            pool.submit(_akshare_process_worker, task): task[0]\r\n            for task in tasks\r\n        }\r\n        for future in as_completed(future_map):\r\n            code = future_map[future]\r\n            try:\r\n                result_code, data, error = future.result()\r\n                if data is not None:\r\n                    # \xe5\xb0\x86 dict \xe9\x87\x8d\xe5\xbb\xba\xe4\xb8\xba DataFrame\r\n                    df = pd.DataFrame(data)\r\n                    if "date" in df.columns:\r\n                        df = df.sort_values("date").reset_index(drop=True)\r\n                    results[code] = df\r\n                    if progress_callback:\r\n                        progress_callback(code, True, None)\r\n                else:\r\n                    results[code] = None\r\n                    logger.warning("AKShare \xe9\x87\x87\xe9\x9b\x86\xe5\xa4\xb1\xe8\xb4\xa5 %s: %s", code, error)\r\n                    if progress_callback:\r\n                        progress_callback(code, False, error)\r\n            except Exception as exc:\r\n                results[code] = None\r\n                logger.error("AKShare worker \xe5\xbc\x82\xe5\xb8\xb8 %s: %s", code, exc)\r\n                if progress_callback:\r\n                    progress_callback(code, False, str(exc))\r\n\r\n    return results\r\n\r\n\r\n# ============================================================================\r\n# \xe5\x8d\x95\xe8\x82\xa1\xe5\x90\x8c\xe6\xad\xa5\xe6\x8e\xa5\xe5\x8f\xa3\xef\xbc\x88\xe4\xb8\xbb\xe8\xbf\x9b\xe7\xa8\x8b\xe7\x9b\xb4\xe6\x8e\xa5\xe8\xb0\x83\xe7\x94\xa8\xef\xbc\x8c\xe4\xbe\x9b\xe9\x99\x8d\xe7\xba\xa7 fallback \xe5\x92\x8c\xe6\xb5\x8b\xe8\xaf\x95\xe7\x94\xa8\xef\xbc\x89\r\n# ============================================================================\r\n\r\ndef fetch_akshare_single(\r\n    code: str,\r\n    start_date: str,\r\n    end_date: str,\r\n    max_retries: int = 3,\r\n    delay_min: float = 0.3,\r\n    delay_max: float = 0.8,\r\n) -> Optional[Any]:\r\n    """\r\n    \xe5\x90\x8c\xe6\xad\xa5\xe9\x87\x87\xe9\x9b\x86\xe5\x8d\x95\xe5\x8f\xaa\xe8\x82\xa1\xe7\xa5\xa8\xef\xbc\x88\xe7\x9b\xb4\xe6\x8e\xa5\xe5\x9c\xa8\xe8\xb0\x83\xe7\x94\xa8\xe8\xbf\x9b\xe7\xa8\x8b\xe4\xb8\xad\xe8\xbf\x90\xe8\xa1\x8c\xef\xbc\x89\xe3\x80\x82\r\n    \xe6\xb3\xa8\xe6\x84\x8f\xef\xbc\x9a\xe6\xad\xa4\xe6\x8e\xa5\xe5\x8f\xa3\xe4\xbb\x85\xe4\xbe\x9b\xe5\x8d\x95\xe7\xba\xbf\xe7\xa8\x8b\xe5\x9c\xba\xe6\x99\xaf\xe4\xbd\xbf\xe7\x94\xa8\xef\xbc\x8c\xe5\xa4\x9a\xe7\xba\xbf\xe7\xa8\x8b\xe5\xb9\xb6\xe5\x8f\x91\xe8\xb0\x83\xe7\x94\xa8\xe6\x9c\x89 session \xe7\xab\x9e\xe4\xba\x89\xe9\xa3\x8e\xe9\x99\xa9\xe3\x80\x82\r\n\r\n    Returns:\r\n        pd.DataFrame \xe6\x88\x96 None\r\n    """\r\n    import pandas as pd\r\n\r\n    task = (code, start_date, end_date, max_retries, delay_min, delay_max)\r\n    result_code, data, error = _akshare_process_worker(task)\r\n    if data is None:\r\n        return None\r\n    df = pd.DataFrame(data)\r\n    if "date" in df.columns:\r\n        df = df.sort_values("date").reset_index(drop=True)\r\n    return df\r\n'

FILE_src_data_collector_baostock_client_py = b'#!/usr/bin/env python3\r\n# -*- coding: utf-8 -*-\r\n"""\r\nbaostock_client.py \xe2\x80\x94 BaoStock \xe6\x95\xb0\xe6\x8d\xae\xe9\x87\x87\xe9\x9b\x86\xe5\xae\xa2\xe6\x88\xb7\xe7\xab\xaf\xef\xbc\x88\xe4\xb8\x89\xe7\xba\xa7\xe5\x85\x9c\xe5\xba\x95\xef\xbc\x89(patch_v9)\r\n================================================================\r\n\xe5\xa4\x8d\xe6\x9d\x83\xe6\x96\xb9\xe5\xbc\x8f\xe7\xbb\x9f\xe4\xb8\x80\xe4\xb8\xba hfq\xef\xbc\x88\xe5\x90\x8e\xe5\xa4\x8d\xe6\x9d\x83\xef\xbc\x89\xef\xbc\x8cadjustflag="1"\xe3\x80\x82\r\n\xe6\xaf\x8f\xe6\xac\xa1 fetch \xe7\x8b\xac\xe7\xab\x8b login/logout\xef\xbc\x8c\xe7\xa1\xae\xe4\xbf\x9d\xe4\xbc\x9a\xe8\xaf\x9d\xe9\x9a\x94\xe7\xa6\xbb\xe3\x80\x82\r\n"""\r\n\r\nimport time\r\nimport random\r\nimport logging\r\nfrom typing import Optional, Tuple\r\n\r\nimport pandas as pd\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\ntry:\r\n    import baostock as bs\r\n    _BAOSTOCK_AVAILABLE = True\r\nexcept ImportError:\r\n    bs = None  # type: ignore[assignment]\r\n    _BAOSTOCK_AVAILABLE = False\r\n\r\n_BS_FIELDS  = "date,open,high,low,close,volume,amount,adjustflag,turn,tradestatus,pctChg"\r\n_MARKET_PFX = {0: "sz", 1: "sh"}\r\n_BS_COL_MAP = {\r\n    "volume":      "vol",\r\n    "amount":      "amount",\r\n    "turn":        "turnover",\r\n    "pctChg":      "pct_change",\r\n    "tradestatus": "trade_status",\r\n    "adjustflag":  "adjust_flag",\r\n}\r\n_REQUIRED_COLS = {"date", "open", "high", "low", "close", "vol"}\r\n\r\n\r\ndef _bs_code(code: str, market: int) -> str:\r\n    return f"{_MARKET_PFX.get(market, \'sz\')}.{code}"\r\n\r\n\r\ndef _to_date_str(d: str) -> str:\r\n    """YYYYMMDD \xe6\x88\x96 YYYY-MM-DD \xe7\xbb\x9f\xe4\xb8\x80\xe8\xbd\xac YYYY-MM-DD"""\r\n    d = d.replace("/", "-")\r\n    if len(d) == 8 and "-" not in d:\r\n        return f"{d[:4]}-{d[4:6]}-{d[6:]}"\r\n    return d\r\n\r\n\r\ndef _standardize(df: pd.DataFrame, code: str) -> pd.DataFrame:\r\n    df = df.rename(columns=_BS_COL_MAP)\r\n    df["code"]   = code\r\n    df["source"] = "baostock"\r\n    df["adjust"] = "hfq"\r\n\r\n    df["date"] = pd.to_datetime(df["date"]).dt.strftime("%Y-%m-%d")\r\n    for col in ("open", "high", "low", "close"):\r\n        if col in df.columns:\r\n            df[col] = pd.to_numeric(df[col], errors="coerce").astype("float32")\r\n    for col in ("vol", "amount"):\r\n        if col in df.columns:\r\n            df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0).astype("int64")\r\n    for col in ("turnover", "pct_change"):\r\n        if col in df.columns:\r\n            df[col] = pd.to_numeric(df[col], errors="coerce").astype("float32")\r\n\r\n    # \xe8\xbf\x87\xe6\xbb\xa4\xe5\x81\x9c\xe7\x89\x8c\xe6\x97\xa5\r\n    if "trade_status" in df.columns:\r\n        df = df[df["trade_status"].astype(str) != "0"].copy()\r\n\r\n    keep = [c for c in (\r\n        "code", "date", "open", "high", "low", "close",\r\n        "vol", "amount", "pct_change", "turnover", "source", "adjust"\r\n    ) if c in df.columns]\r\n    return df[keep].sort_values("date").reset_index(drop=True)\r\n\r\n\r\ndef fetch_baostock(\r\n    code: str,\r\n    market: int,\r\n    start_date: str,\r\n    end_date: str,\r\n    max_retries: int = 3,\r\n    delay_min: float = 0.5,\r\n    delay_max: float = 1.0,\r\n) -> Optional[pd.DataFrame]:\r\n    """\r\n    \xe9\x80\x9a\xe8\xbf\x87 BaoStock \xe8\x8e\xb7\xe5\x8f\x96 A \xe8\x82\xa1\xe6\x97\xa5\xe7\xba\xbf\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x88\xe5\x90\x8e\xe5\xa4\x8d\xe6\x9d\x83 adjustflag=1\xef\xbc\x89\xe3\x80\x82\r\n\r\n    Args:\r\n        code:        \xe8\x82\xa1\xe7\xa5\xa8\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x8c\xe5\xa6\x82 "600000"\r\n        market:      \xe5\xb8\x82\xe5\x9c\xba 0=\xe6\xb7\xb1\xe5\x9c\xb3, 1=\xe4\xb8\x8a\xe6\xb5\xb7\r\n        start_date:  \xe8\xb5\xb7\xe5\xa7\x8b\xe6\x97\xa5\xe6\x9c\x9f "YYYY-MM-DD" \xe6\x88\x96 "YYYYMMDD"\r\n        end_date:    \xe6\x88\xaa\xe6\xad\xa2\xe6\x97\xa5\xe6\x9c\x9f\r\n        max_retries: \xe6\x9c\x80\xe5\xa4\xa7\xe9\x87\x8d\xe8\xaf\x95\xe6\xac\xa1\xe6\x95\xb0\r\n        delay_min/max: \xe9\x9a\x8f\xe6\x9c\xba sleep \xe5\x8c\xba\xe9\x97\xb4\r\n\r\n    Returns:\r\n        \xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96 DataFrame\xef\xbc\x88\xe5\x90\xab turnover/pct_change\xef\xbc\x89\xe6\x88\x96 None\r\n    """\r\n    if not _BAOSTOCK_AVAILABLE:\r\n        logger.warning("baostock \xe6\x9c\xaa\xe5\xae\x89\xe8\xa3\x85\xef\xbc\x8c\xe8\xb7\xb3\xe8\xbf\x87")\r\n        return None\r\n\r\n    bs_symbol = _bs_code(code, market)\r\n    s_date    = _to_date_str(start_date)\r\n    e_date    = _to_date_str(end_date)\r\n\r\n    for attempt in range(max_retries):\r\n        lg = None\r\n        try:\r\n            time.sleep(random.uniform(delay_min, delay_max))\r\n            lg = bs.login()\r\n            if lg.error_code != "0":\r\n                raise RuntimeError(f"login \xe5\xa4\xb1\xe8\xb4\xa5: {lg.error_msg}")\r\n\r\n            rs = bs.query_history_k_data_plus(\r\n                code=bs_symbol,\r\n                fields=_BS_FIELDS,\r\n                start_date=s_date,\r\n                end_date=e_date,\r\n                frequency="d",\r\n                adjustflag="1",  # \xe5\x90\x8e\xe5\xa4\x8d\xe6\x9d\x83\xef\xbc\x88hfq\xef\xbc\x89\xef\xbc\x8c\xe4\xb8\x8e AKShare \xe7\xbb\x9f\xe4\xb8\x80\r\n            )\r\n            if rs.error_code != "0":\r\n                raise RuntimeError(f"\xe6\x9f\xa5\xe8\xaf\xa2\xe5\xa4\xb1\xe8\xb4\xa5: {rs.error_msg}")\r\n\r\n            rows = []\r\n            while rs.error_code == "0" and rs.next():\r\n                rows.append(rs.get_row_data())\r\n            if not rows:\r\n                raise ValueError(f"\xe7\xa9\xba\xe6\x95\xb0\xe6\x8d\xae: {bs_symbol}")\r\n\r\n            df = pd.DataFrame(rows, columns=rs.fields)\r\n            df = _standardize(df, code)\r\n            missing = _REQUIRED_COLS - set(df.columns)\r\n            if missing:\r\n                raise ValueError(f"\xe7\xbc\xba\xe5\xb0\x91\xe5\xbf\x85\xe9\xa1\xbb\xe5\x88\x97: {missing}")\r\n\r\n            logger.debug("BaoStock \xe6\x88\x90\xe5\x8a\x9f: %s, %d \xe8\xa1\x8c", code, len(df))\r\n            return df\r\n\r\n        except Exception as exc:\r\n            wait = (2 ** attempt) * (1 + random.random() * 0.3)\r\n            if attempt < max_retries - 1:\r\n                logger.warning("BaoStock \xe7\xac\xac%d/%d\xe6\xac\xa1\xe5\xa4\xb1\xe8\xb4\xa5 (%s): %s\xef\xbc\x8c\xe7\xad\x89\xe5\xbe\x85%.1fs",\r\n                               attempt + 1, max_retries, code, exc, wait)\r\n                time.sleep(wait)\r\n            else:\r\n                logger.error("BaoStock \xe5\x85\xa8\xe9\x83\xa8\xe5\xa4\xb1\xe8\xb4\xa5 (%s): %s", code, exc)\r\n        finally:\r\n            if lg is not None:\r\n                try:\r\n                    bs.logout()\r\n                except Exception:\r\n                    pass\r\n    return None\r\n'

FILE_src_data_collector_incremental_py = b'#!/usr/bin/env python3\r\n# -*- coding: utf-8 -*-\r\n"""\r\nincremental.py \xe2\x80\x94 \xe6\x99\xba\xe8\x83\xbd\xe5\xa2\x9e\xe9\x87\x8f\xe6\x9b\xb4\xe6\x96\xb0\xe9\x80\xbb\xe8\xbe\x91 (patch_v9)\r\n==============================================\r\n1. read_local_max_date()  \xe2\x80\x94 \xe8\xaf\xbb\xe5\x8f\x96\xe6\x9c\xac\xe5\x9c\xb0 Parquet \xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe6\x97\xa5\xe6\x9c\x9f\r\n2. compute_missing_range() \xe2\x80\x94 \xe8\xae\xa1\xe7\xae\x97\xe7\xbc\xba\xe5\xa4\xb1\xe5\x8c\xba\xe9\x97\xb4\r\n3. merge_incremental()     \xe2\x80\x94 pd.concat + drop_duplicates(keep=\'last\')\r\n"""\r\n\r\nimport logging\r\nfrom datetime import date, datetime, timedelta\r\nfrom pathlib import Path\r\nfrom typing import Optional, Tuple\r\n\r\nimport pandas as pd\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\nHISTORY_START_DATE = "2005-01-01"\r\nEARLIEST_DATE      = "1990-12-19"\r\n\r\n\r\ndef read_local_max_date(parquet_path: Path) -> Optional[str]:\r\n    """\xe8\xaf\xbb\xe5\x8f\x96\xe6\x9c\xac\xe5\x9c\xb0 Parquet \xe6\x96\x87\xe4\xbb\xb6\xe4\xb8\xad date \xe5\x88\x97\xe7\x9a\x84\xe6\x9c\x80\xe5\xa4\xa7\xe5\x80\xbc\xef\xbc\x88\xe4\xbb\x85\xe5\x8a\xa0\xe8\xbd\xbd date \xe5\x88\x97\xef\xbc\x8c\xe8\x8a\x82\xe7\x9c\x81\xe5\x86\x85\xe5\xad\x98\xef\xbc\x89\xe3\x80\x82"""\r\n    if not parquet_path.exists():\r\n        return None\r\n    try:\r\n        df = pd.read_parquet(parquet_path, columns=["date"])\r\n        if df.empty:\r\n            return None\r\n        return str(df["date"].max())\r\n    except Exception as exc:\r\n        logger.warning("\xe8\xaf\xbb\xe5\x8f\x96\xe6\x9c\xac\xe5\x9c\xb0\xe6\x96\x87\xe4\xbb\xb6\xe5\xa4\xb1\xe8\xb4\xa5 (%s): %s\xef\xbc\x8c\xe8\xa7\x86\xe4\xb8\xba\xe6\x97\xa0\xe6\x9c\xac\xe5\x9c\xb0\xe6\x95\xb0\xe6\x8d\xae", parquet_path, exc)\r\n        return None\r\n\r\n\r\ndef compute_missing_range(\r\n    local_max_date: Optional[str],\r\n    as_of_date: Optional[str] = None,\r\n    history_start: str = HISTORY_START_DATE,\r\n) -> Tuple[str, str]:\r\n    """\r\n    \xe8\xae\xa1\xe7\xae\x97\xe9\x9c\x80\xe8\xa6\x81\xe8\xaf\xb7\xe6\xb1\x82\xe7\x9a\x84 [start_date, end_date] \xe5\x8c\xba\xe9\x97\xb4\xe3\x80\x82\r\n    \xe6\x97\xa0\xe6\x9c\xac\xe5\x9c\xb0\xe6\x95\xb0\xe6\x8d\xae \xe2\x86\x92 \xe5\x85\xa8\xe9\x87\x8f\xef\xbc\x9b\xe6\x9c\x89 \xe2\x86\x92 \xe4\xbb\x8e local_max + 1 \xe5\xa4\xa9\xe5\xbc\x80\xe5\xa7\x8b\xe3\x80\x82\r\n    """\r\n    today = as_of_date or date.today().strftime("%Y-%m-%d")\r\n    if local_max_date is None:\r\n        return history_start, today\r\n    try:\r\n        max_dt   = datetime.strptime(local_max_date, "%Y-%m-%d").date()\r\n        next_day = (max_dt + timedelta(days=1)).strftime("%Y-%m-%d")\r\n        if next_day > today:\r\n            return today, today   # \xe8\xb0\x83\xe7\x94\xa8\xe6\x96\xb9\xe6\xa3\x80\xe6\x9f\xa5 start == end\r\n        return next_day, today\r\n    except ValueError:\r\n        logger.warning("\xe6\x97\xa5\xe6\x9c\x9f\xe6\xa0\xbc\xe5\xbc\x8f\xe9\x94\x99\xe8\xaf\xaf: %s\xef\xbc\x8c\xe5\xb0\x86\xe5\x85\xa8\xe9\x87\x8f\xe4\xb8\x8b\xe8\xbd\xbd", local_max_date)\r\n        return history_start, today\r\n\r\n\r\ndef is_up_to_date(local_max_date: Optional[str], as_of_date: Optional[str] = None) -> bool:\r\n    """\xe6\x9c\xac\xe5\x9c\xb0\xe6\x95\xb0\xe6\x8d\xae\xe6\x98\xaf\xe5\x90\xa6\xe5\xb7\xb2\xe6\x98\xaf\xe6\x9c\x80\xe6\x96\xb0\xef\xbc\x88\xe5\x85\x81\xe8\xae\xb8 1 \xe5\xa4\xa9\xe5\xae\xbd\xe5\xae\xb9\xef\xbc\x89\xe3\x80\x82"""\r\n    if local_max_date is None:\r\n        return False\r\n    today = as_of_date or date.today().strftime("%Y-%m-%d")\r\n    try:\r\n        max_dt   = datetime.strptime(local_max_date, "%Y-%m-%d").date()\r\n        today_dt = datetime.strptime(today, "%Y-%m-%d").date()\r\n        return (today_dt - max_dt).days <= 1\r\n    except ValueError:\r\n        return False\r\n\r\n\r\ndef merge_incremental(\r\n    local_df: Optional[pd.DataFrame],\r\n    new_df: pd.DataFrame,\r\n) -> pd.DataFrame:\r\n    """\r\n    \xe5\x90\x88\xe5\xb9\xb6\xe6\x9c\xac\xe5\x9c\xb0\xe5\x8e\x86\xe5\x8f\xb2\xe4\xb8\x8e\xe6\x96\xb0\xe5\xa2\x9e\xe6\x95\xb0\xe6\x8d\xae\xe3\x80\x82\r\n    drop_duplicates(keep=\'last\'): \xe6\x96\xb0\xe6\x95\xb0\xe6\x8d\xae\xe4\xbc\x98\xe5\x85\x88\xef\xbc\x88\xe5\xa4\x8d\xe6\x9d\x83\xe5\x9b\xa0\xe5\xad\x90\xe5\x8f\xaf\xe8\x83\xbd\xe5\x88\xb7\xe6\x96\xb0\xe5\x8e\x86\xe5\x8f\xb2\xef\xbc\x89\xe3\x80\x82\r\n    """\r\n    if local_df is None or local_df.empty:\r\n        result = new_df.copy()\r\n    elif new_df.empty:\r\n        result = local_df.copy()\r\n    else:\r\n        result = pd.concat([local_df, new_df], ignore_index=True)\r\n\r\n    dedup_cols = ["date"] if "code" not in result.columns else ["code", "date"]\r\n    result = result.drop_duplicates(subset=dedup_cols, keep="last")\r\n    return result.sort_values("date").reset_index(drop=True)\r\n\r\n\r\ndef load_local_df(parquet_path: Path) -> Optional[pd.DataFrame]:\r\n    if not parquet_path.exists():\r\n        return None\r\n    try:\r\n        df = pd.read_parquet(parquet_path)\r\n        return None if df.empty else df\r\n    except Exception as exc:\r\n        logger.warning("\xe5\x8a\xa0\xe8\xbd\xbd\xe5\xa4\xb1\xe8\xb4\xa5 (%s): %s", parquet_path, exc)\r\n        return None\r\n\r\n\r\ndef save_df(df: pd.DataFrame, parquet_path: Path, compression: str = "zstd") -> bool:\r\n    try:\r\n        parquet_path.parent.mkdir(parents=True, exist_ok=True)\r\n        df.to_parquet(parquet_path, index=False, compression=compression)\r\n        logger.debug("\xe4\xbf\x9d\xe5\xad\x98: %s (%d \xe8\xa1\x8c)", parquet_path.name, len(df))\r\n        return True\r\n    except Exception as exc:\r\n        logger.error("\xe4\xbf\x9d\xe5\xad\x98\xe5\xa4\xb1\xe8\xb4\xa5 (%s): %s", parquet_path, exc)\r\n        return False\r\n'

FILE_src_data_collector_validator_py = b'#!/usr/bin/env python3\r\n# -*- coding: utf-8 -*-\r\n"""\r\nvalidator.py \xe2\x80\x94 \xe6\x95\xb0\xe6\x8d\xae\xe9\xaa\x8c\xe8\xaf\x81\xe5\xb1\x82 (patch_v9)\r\n======================================\r\n\xe9\x87\x87\xe9\x9b\x86\xe5\x90\x8e\xe3\x80\x81\xe5\x86\x99\xe7\x9b\x98\xe5\x89\x8d\xe6\x89\xa7\xe8\xa1\x8c\xe4\xb8\x89\xe5\xb1\x82\xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x9a\r\n  Layer 1: \xe8\xa1\x8c\xe6\x95\xb0\xe6\xa3\x80\xe6\x9f\xa5   \xe2\x80\x94 \xe9\x98\xb2\xe6\xad\xa2\xe7\xa9\xba\xe6\x95\xb0\xe6\x8d\xae\xe5\x86\x99\xe5\x85\xa5 Parquet\r\n  Layer 2: \xe5\xbf\x85\xe9\x9c\x80\xe5\x88\x97\xe6\xa3\x80\xe6\x9f\xa5 \xe2\x80\x94 \xe4\xbf\x9d\xe8\xaf\x81 schema \xe5\xae\x8c\xe6\x95\xb4\r\n  Layer 3: OHLC \xe9\x80\xbb\xe8\xbe\x91  \xe2\x80\x94 \xe9\x98\xb2\xe6\xad\xa2\xe8\x84\x8f\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x88high < low / close <= 0\xef\xbc\x89\r\n\r\n\xe9\x80\x9a\xe8\xbf\x87\xe9\xaa\x8c\xe8\xaf\x81\xe8\xbf\x94\xe5\x9b\x9e (True, "ok")\xef\xbc\x9b\r\n\xe5\xa4\xb1\xe8\xb4\xa5\xe8\xbf\x94\xe5\x9b\x9e (False, "reason_string")\xef\xbc\x8c\xe8\xb0\x83\xe7\x94\xa8\xe6\x96\xb9\xe8\xae\xb0\xe5\xbd\x95\xe5\x88\xb0 RunReport\xe3\x80\x82\r\n"""\r\n\r\nimport logging\r\nfrom typing import Optional, Tuple\r\n\r\nimport pandas as pd\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n# \xe5\xbf\x85\xe9\x9c\x80\xe5\x88\x97\xe9\x9b\x86\xe5\x90\x88\r\nREQUIRED_COLS = {"date", "open", "high", "low", "close", "vol"}\r\n\r\n# \xe6\x9c\x80\xe5\xb0\x8f\xe6\x9c\x89\xe6\x95\x88\xe8\xa1\x8c\xe6\x95\xb0\r\nMIN_ROWS = 10\r\n\r\n\r\nclass DataValidator:\r\n    """\r\n    \xe4\xb8\x89\xe5\xb1\x82\xe6\x95\xb0\xe6\x8d\xae\xe9\xaa\x8c\xe8\xaf\x81\xe5\x99\xa8\xe3\x80\x82\r\n\r\n    \xe4\xbd\xbf\xe7\x94\xa8\xe7\xa4\xba\xe4\xbe\x8b:\r\n        ok, reason = DataValidator.validate(df, code="000001")\r\n        if not ok:\r\n            report.add_validation_failure(code, reason)\r\n    """\r\n\r\n    @staticmethod\r\n    def validate(\r\n        df: Optional[pd.DataFrame],\r\n        code: str = "",\r\n        min_rows: int = MIN_ROWS,\r\n    ) -> Tuple[bool, str]:\r\n        """\r\n        \xe5\xaf\xb9\xe9\x87\x87\xe9\x9b\x86\xe7\xbb\x93\xe6\x9e\x9c\xe6\x89\xa7\xe8\xa1\x8c\xe4\xb8\x89\xe5\xb1\x82\xe9\xaa\x8c\xe8\xaf\x81\xe3\x80\x82\r\n\r\n        Args:\r\n            df:       \xe5\xbe\x85\xe9\xaa\x8c\xe8\xaf\x81\xe7\x9a\x84 DataFrame\xef\xbc\x88\xe5\x8f\xaf\xe4\xb8\xba None\xef\xbc\x89\r\n            code:     \xe8\x82\xa1\xe7\xa5\xa8\xe4\xbb\xa3\xe7\xa0\x81\xef\xbc\x88\xe7\x94\xa8\xe4\xba\x8e\xe6\x97\xa5\xe5\xbf\x97\xef\xbc\x89\r\n            min_rows: \xe6\x9c\x80\xe5\xb0\x8f\xe8\xa1\x8c\xe6\x95\xb0\xe9\x98\x88\xe5\x80\xbc\r\n\r\n        Returns:\r\n            (True, "ok") \xe9\x80\x9a\xe8\xbf\x87\r\n            (False, reason_str) \xe5\xa4\xb1\xe8\xb4\xa5\xef\xbc\x8creason \xe4\xbe\x9b RunReport \xe8\xae\xb0\xe5\xbd\x95\r\n        """\r\n        # Layer 1: \xe7\xa9\xba\xe5\x80\xbc/\xe8\xa1\x8c\xe6\x95\xb0\r\n        if df is None:\r\n            return False, "df_is_none"\r\n        if df.empty:\r\n            return False, "df_empty"\r\n        if len(df) < min_rows:\r\n            return False, f"too_few_rows:{len(df)}"\r\n\r\n        # Layer 2: \xe5\xbf\x85\xe9\x9c\x80\xe5\x88\x97\xe5\xae\x8c\xe6\x95\xb4\xe6\x80\xa7\r\n        missing_cols = REQUIRED_COLS - set(df.columns)\r\n        if missing_cols:\r\n            return False, f"missing_cols:{sorted(missing_cols)}"\r\n\r\n        # Layer 3: OHLC \xe9\x80\xbb\xe8\xbe\x91\xe5\x90\x88\xe7\x90\x86\xe6\x80\xa7\r\n        try:\r\n            numeric_df = df[["open", "high", "low", "close"]].apply(\r\n                pd.to_numeric, errors="coerce"\r\n            )\r\n\r\n            # high >= low\r\n            invalid_hl = (numeric_df["high"] < numeric_df["low"]).sum()\r\n            if invalid_hl > 0:\r\n                return False, f"high_lt_low:{invalid_hl}_rows"\r\n\r\n            # close > 0\xef\xbc\x88\xe5\x85\x81\xe8\xae\xb8\xe5\x81\x9c\xe7\x89\x8c\xe6\x97\xa5\xe4\xb8\xba 0\xef\xbc\x8c\xe4\xbd\x86\xe4\xb8\x8d\xe5\x85\x81\xe8\xae\xb8\xe8\xb4\x9f\xe4\xbb\xb7\xef\xbc\x89\r\n            negative_close = (numeric_df["close"] < 0).sum()\r\n            if negative_close > 0:\r\n                return False, f"negative_close:{negative_close}_rows"\r\n\r\n            # open/high/low/close \xe4\xb8\x8d\xe8\x83\xbd\xe5\x85\xa8\xe9\x83\xa8\xe4\xb8\xba NaN\r\n            all_nan_pct = numeric_df.isna().all(axis=1).mean()\r\n            if all_nan_pct > 0.5:  # \xe8\xb6\x85\xe8\xbf\x87 50% \xe8\xa1\x8c\xe5\x85\xa8 NaN\r\n                return False, f"too_many_nan_rows:{all_nan_pct:.0%}"\r\n\r\n        except Exception as exc:\r\n            return False, f"ohlc_check_error:{exc}"\r\n\r\n        return True, "ok"\r\n\r\n    @staticmethod\r\n    def validate_merge_result(\r\n        merged_df: Optional[pd.DataFrame],\r\n        code: str = "",\r\n    ) -> Tuple[bool, str]:\r\n        """\r\n        \xe5\xaf\xb9\xe5\xa2\x9e\xe9\x87\x8f\xe5\x90\x88\xe5\xb9\xb6\xe5\x90\x8e\xe7\x9a\x84\xe6\x9c\x80\xe7\xbb\x88 DataFrame \xe5\x81\x9a\xe4\xba\x8c\xe6\xac\xa1\xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x88\xe6\x9b\xb4\xe5\xae\xbd\xe6\x9d\xbe\xef\xbc\x89\xe3\x80\x82\r\n        \xe4\xb8\xbb\xe8\xa6\x81\xe7\xa1\xae\xe4\xbf\x9d\xe5\x90\x88\xe5\xb9\xb6\xe6\xb2\xa1\xe6\x9c\x89\xe5\xbc\x95\xe5\x85\xa5\xe4\xb8\xa5\xe9\x87\x8d\xe9\x97\xae\xe9\xa2\x98\xe3\x80\x82\r\n        """\r\n        if merged_df is None or merged_df.empty:\r\n            return False, "merged_empty"\r\n\r\n        # \xe6\xa3\x80\xe6\x9f\xa5\xe6\x97\xa5\xe6\x9c\x9f\xe6\x98\xaf\xe5\x90\xa6\xe6\x9c\x89\xe5\xba\x8f\r\n        if "date" in merged_df.columns:\r\n            dates = merged_df["date"].tolist()\r\n            if dates != sorted(dates):\r\n                return False, "date_not_sorted"\r\n\r\n            # \xe6\xa3\x80\xe6\x9f\xa5\xe9\x87\x8d\xe5\xa4\x8d\xe6\x97\xa5\xe6\x9c\x9f\r\n            dup_count = merged_df.duplicated(subset=["date"]).sum()\r\n            if dup_count > 0:\r\n                return False, f"duplicate_dates:{dup_count}"\r\n\r\n        return True, "ok"\r\n'

FILE_src_data_collector_run_report_py = b'#!/usr/bin/env python3\r\n# -*- coding: utf-8 -*-\r\n"""\r\nrun_report.py \xe2\x80\x94 \xe8\xbf\x90\xe8\xa1\x8c\xe6\x8a\xa5\xe5\x91\x8a\xe6\x8c\x81\xe4\xb9\x85\xe5\x8c\x96 (patch_v9)\r\n==========================================\r\n\xe6\xaf\x8f\xe6\xac\xa1\xe9\x87\x87\xe9\x9b\x86\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9d\x9f\xe5\x90\x8e\xe7\x94\x9f\xe6\x88\x90\xef\xbc\x9a\r\n  - failed_stocks.txt      \xe2\x80\x94 \xe5\xa4\xb1\xe8\xb4\xa5\xe8\x82\xa1\xe7\xa5\xa8\xe5\x88\x97\xe8\xa1\xa8\xef\xbc\x88\xe5\x8f\xaf\xe7\x94\xa8\xe4\xba\x8e --retry-failed \xe8\xa1\xa5\xe9\x87\x87\xef\xbc\x89\r\n  - run_stats_{ts}.json    \xe2\x80\x94 \xe5\xae\x8c\xe6\x95\xb4\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x9f\xe8\xae\xa1\xef\xbc\x88\xe4\xbe\x9b\xe5\x90\x8e\xe7\xbb\xad\xe5\xae\xa1\xe8\xae\xa1\xef\xbc\x89\r\n\r\n\xe8\xae\xbe\xe8\xae\xa1\xe5\x8e\x9f\xe5\x88\x99:\r\n  - \xe7\xba\xbf\xe7\xa8\x8b\xe5\xae\x89\xe5\x85\xa8\xef\xbc\x88\xe5\x86\x85\xe9\x83\xa8\xe4\xbd\xbf\xe7\x94\xa8 threading.Lock\xef\xbc\x89\r\n  - \xe5\xb9\x82\xe7\xad\x89\xe5\xae\x89\xe5\x85\xa8\xef\xbc\x88\xe5\x90\x8c\xe4\xb8\x80 code \xe8\xa2\xab\xe8\xae\xb0\xe5\xbd\x95\xe5\xa4\x9a\xe6\xac\xa1\xe4\xbb\xa5\xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe6\xac\xa1\xe4\xb8\xba\xe5\x87\x86\xef\xbc\x89\r\n  - \xe5\xa4\xb1\xe8\xb4\xa5\xe5\x88\x86\xe7\xb1\xbb\xef\xbc\x9atdx_fail / akshare_fail / baostock_fail / validate_fail / complete_fail\r\n"""\r\n\r\nimport json\r\nimport threading\r\nimport logging\r\nfrom datetime import datetime\r\nfrom pathlib import Path\r\nfrom typing import Dict, List, Optional, Tuple\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\nclass RunReport:\r\n    """\r\n    \xe7\xba\xbf\xe7\xa8\x8b\xe5\xae\x89\xe5\x85\xa8\xe7\x9a\x84\xe8\xbf\x90\xe8\xa1\x8c\xe6\x8a\xa5\xe5\x91\x8a\xe6\x94\xb6\xe9\x9b\x86\xe5\x99\xa8\xe3\x80\x82\r\n\r\n    \xe4\xbd\xbf\xe7\x94\xa8\xe7\xa4\xba\xe4\xbe\x8b:\r\n        report = RunReport(reports_dir="./data/reports")\r\n        report.record_success(code, market, source="tdx")\r\n        report.record_failed(code, market, reason="complete_fail")\r\n        report.record_skipped(code, market)\r\n        report.save()   # \xe5\x86\x99\xe5\x87\xba txt + json\r\n    """\r\n\r\n    def __init__(self, reports_dir: str = "./data/reports") -> None:\r\n        self.reports_dir = Path(reports_dir)\r\n        self.reports_dir.mkdir(parents=True, exist_ok=True)\r\n\r\n        self._lock      = threading.Lock()\r\n        self._ts        = datetime.now().strftime("%Y%m%d_%H%M%S")\r\n\r\n        # \xe6\xa0\xb8\xe5\xbf\x83\xe7\xbb\x9f\xe8\xae\xa1\r\n        self._success: Dict[str, dict] = {}   # code \xe2\x86\x92 {market, source, rows}\r\n        self._failed:  Dict[str, dict] = {}   # code \xe2\x86\x92 {market, reason}\r\n        self._skipped: Dict[str, dict] = {}   # code \xe2\x86\x92 {market, reason}\r\n\r\n        # \xe9\xaa\x8c\xe8\xaf\x81\xe5\xa4\xb1\xe8\xb4\xa5\xef\xbc\x88\xe5\x8d\x95\xe7\x8b\xac\xe5\x88\x86\xe7\xb1\xbb\xef\xbc\x8c\xe5\x8f\xaf\xe8\x83\xbd\xe9\x83\xa8\xe5\x88\x86\xe5\xad\x97\xe6\xae\xb5\xe5\xa4\xb1\xe8\xb4\xa5\xe4\xbd\x86\xe4\xbb\x8d\xe6\x9c\x89\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x89\r\n        self._validation_failures: Dict[str, str] = {}  # code \xe2\x86\x92 reason\r\n\r\n        # \xe6\x9d\xa5\xe6\xba\x90\xe7\xbb\x9f\xe8\xae\xa1\r\n        self._source_counts = {"tdx": 0, "akshare": 0, "baostock": 0, "merged": 0}\r\n\r\n        # \xe8\xbf\x90\xe8\xa1\x8c\xe6\x97\xb6\xe5\x85\x83\xe4\xbf\xa1\xe6\x81\xaf\r\n        self._start_time = datetime.now()\r\n        self._end_time: Optional[datetime] = None\r\n\r\n    # ------------------------------------------------------------------\r\n    # \xe8\xae\xb0\xe5\xbd\x95\xe6\x8e\xa5\xe5\x8f\xa3\xef\xbc\x88\xe7\xba\xbf\xe7\xa8\x8b\xe5\xae\x89\xe5\x85\xa8\xef\xbc\x89\r\n    # ------------------------------------------------------------------\r\n\r\n    def record_success(\r\n        self,\r\n        code: str,\r\n        market: int,\r\n        source: str,\r\n        rows: int = 0,\r\n    ) -> None:\r\n        """\xe8\xae\xb0\xe5\xbd\x95\xe9\x87\x87\xe9\x9b\x86\xe6\x88\x90\xe5\x8a\x9f\xef\xbc\x88\xe5\x90\xab\xe5\x8f\x8c\xe8\xbd\xa8\xe5\x90\x88\xe5\xb9\xb6\xe5\x9c\xba\xe6\x99\xaf\xef\xbc\x89\xe3\x80\x82"""\r\n        with self._lock:\r\n            self._success[code] = {"market": market, "source": source, "rows": rows}\r\n            if source in self._source_counts:\r\n                self._source_counts[source] += 1\r\n            else:\r\n                self._source_counts["merged"] += 1\r\n\r\n    def record_failed(\r\n        self,\r\n        code: str,\r\n        market: int,\r\n        reason: str,\r\n    ) -> None:\r\n        """\xe8\xae\xb0\xe5\xbd\x95\xe9\x87\x87\xe9\x9b\x86\xe5\xbd\xbb\xe5\xba\x95\xe5\xa4\xb1\xe8\xb4\xa5\xef\xbc\x88\xe4\xb8\x89\xe7\xba\xa7\xe5\x85\xa8\xe5\xa4\xb1\xe8\xb4\xa5\xef\xbc\x89\xe3\x80\x82"""\r\n        with self._lock:\r\n            self._failed[code] = {"market": market, "reason": reason}\r\n\r\n    def record_skipped(\r\n        self,\r\n        code: str,\r\n        market: int,\r\n        reason: str = "already_up_to_date",\r\n    ) -> None:\r\n        """\xe8\xae\xb0\xe5\xbd\x95\xe8\xb7\xb3\xe8\xbf\x87\xef\xbc\x88\xe6\x9c\xac\xe5\x9c\xb0\xe6\x95\xb0\xe6\x8d\xae\xe5\xb7\xb2\xe6\x9c\x80\xe6\x96\xb0\xef\xbc\x89\xe3\x80\x82"""\r\n        with self._lock:\r\n            self._skipped[code] = {"market": market, "reason": reason}\r\n\r\n    def record_validation_failure(self, code: str, reason: str) -> None:\r\n        """\xe8\xae\xb0\xe5\xbd\x95\xe6\x95\xb0\xe6\x8d\xae\xe9\xaa\x8c\xe8\xaf\x81\xe5\xa4\xb1\xe8\xb4\xa5\xef\xbc\x88\xe6\x95\xb0\xe6\x8d\xae\xe9\x87\x87\xe9\x9b\x86\xe5\x88\xb0\xe4\xba\x86\xef\xbc\x8c\xe4\xbd\x86\xe6\xa0\xa1\xe9\xaa\x8c\xe4\xb8\x8d\xe9\x80\x9a\xe8\xbf\x87\xef\xbc\x89\xe3\x80\x82"""\r\n        with self._lock:\r\n            self._validation_failures[code] = reason\r\n\r\n    # ------------------------------------------------------------------\r\n    # \xe6\x9f\xa5\xe8\xaf\xa2\xe6\x8e\xa5\xe5\x8f\xa3\r\n    # ------------------------------------------------------------------\r\n\r\n    @property\r\n    def total_success(self) -> int:\r\n        return len(self._success)\r\n\r\n    @property\r\n    def total_failed(self) -> int:\r\n        return len(self._failed)\r\n\r\n    @property\r\n    def total_skipped(self) -> int:\r\n        return len(self._skipped)\r\n\r\n    def get_failed_list(self) -> List[Tuple[str, int, str]]:\r\n        """\xe8\xbf\x94\xe5\x9b\x9e [(code, market, reason), ...] \xe5\xa4\xb1\xe8\xb4\xa5\xe5\x88\x97\xe8\xa1\xa8\xe3\x80\x82"""\r\n        with self._lock:\r\n            return [\r\n                (code, info["market"], info["reason"])\r\n                for code, info in self._failed.items()\r\n            ]\r\n\r\n    def summary_str(self) -> str:\r\n        """\xe5\x8d\x95\xe8\xa1\x8c\xe6\x91\x98\xe8\xa6\x81\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xef\xbc\x88\xe4\xbe\x9b tqdm postfix \xe6\x98\xbe\xe7\xa4\xba\xef\xbc\x89\xe3\x80\x82"""\r\n        with self._lock:\r\n            return (\r\n                f"\xe2\x9c\x93{self.total_success}"\r\n                f" \xe2\x86\x91tdx={self._source_counts[\'tdx\']}"\r\n                f" \xe2\x86\x91ak={self._source_counts[\'akshare\']}"\r\n                f" \xe2\x86\x91bs={self._source_counts[\'baostock\']}"\r\n                f" \xe2\x9c\x97{self.total_failed}"\r\n                f" \xe2\x8f\xad{self.total_skipped}"\r\n            )\r\n\r\n    # ------------------------------------------------------------------\r\n    # \xe6\x8c\x81\xe4\xb9\x85\xe5\x8c\x96\r\n    # ------------------------------------------------------------------\r\n\r\n    def save(self) -> None:\r\n        """\r\n        \xe5\x86\x99\xe5\x87\xba\xe4\xb8\xa4\xe4\xb8\xaa\xe6\x96\x87\xe4\xbb\xb6\xef\xbc\x9a\r\n          failed_stocks.txt  \xe2\x80\x94 \xe5\x8f\xaf\xe7\x9b\xb4\xe6\x8e\xa5\xe7\x94\xa8\xe4\xba\x8e --retry-failed\r\n          run_stats_{ts}.json \xe2\x80\x94 \xe5\xae\x8c\xe6\x95\xb4\xe5\xae\xa1\xe8\xae\xa1\xe6\x97\xa5\xe5\xbf\x97\r\n        """\r\n        self._end_time = datetime.now()\r\n        elapsed = (self._end_time - self._start_time).total_seconds()\r\n\r\n        with self._lock:\r\n            # \xe2\x94\x80\xe2\x94\x80 failed_stocks.txt \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n            failed_path = self.reports_dir / "failed_stocks.txt"\r\n            NL, TAB = chr(10), chr(9)   # avoid \\n/\\t escape issues\r\n            out_lines = []\r\n            out_lines.append("# \xe9\x87\x87\xe9\x9b\x86\xe5\xa4\xb1\xe8\xb4\xa5\xe5\x88\x97\xe8\xa1\xa8 \xe2\x80\x94 \xe7\x94\x9f\xe6\x88\x90\xe6\x97\xb6\xe9\x97\xb4: " + self._ts)\r\n            out_lines.append("# \xe6\xa0\xbc\xe5\xbc\x8f: code<TAB>market<TAB>reason")\r\n            for code, info in self._failed.items():\r\n                out_lines.append(code + TAB + str(info["market"]) + TAB + str(info["reason"]))\r\n            failed_path.write_text(NL.join(out_lines) + NL, encoding="utf-8")\r\n            logger.info("\xe5\xa4\xb1\xe8\xb4\xa5\xe5\x88\x97\xe8\xa1\xa8\xe5\xb7\xb2\xe5\x86\x99\xe5\x87\xba: %s (%d \xe5\x8f\xaa)", failed_path, len(self._failed))\r\n\r\n            # \xe2\x94\x80\xe2\x94\x80 run_stats_{ts}.json \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n            stats_path = self.reports_dir / f"run_stats_{self._ts}.json"\r\n            stats = {\r\n                "run_id":        self._ts,\r\n                "start_time":    self._start_time.isoformat(),\r\n                "end_time":      self._end_time.isoformat(),\r\n                "elapsed_s":     round(elapsed, 2),\r\n                "total":         len(self._success) + len(self._failed) + len(self._skipped),\r\n                "success":       len(self._success),\r\n                "failed":        len(self._failed),\r\n                "skipped":       len(self._skipped),\r\n                "validation_failures": len(self._validation_failures),\r\n                "source_counts": dict(self._source_counts),\r\n                "failed_detail": {\r\n                    code: info for code, info in list(self._failed.items())[:200]\r\n                },\r\n                "validation_failure_detail": dict(\r\n                    list(self._validation_failures.items())[:100]\r\n                ),\r\n            }\r\n            with open(stats_path, "w", encoding="utf-8") as f:\r\n                json.dump(stats, f, indent=2, ensure_ascii=False)\r\n            logger.info("\xe8\xbf\x90\xe8\xa1\x8c\xe7\xbb\x9f\xe8\xae\xa1\xe5\xb7\xb2\xe5\x86\x99\xe5\x87\xba: %s", stats_path)\r\n\r\n    # ------------------------------------------------------------------\r\n    # \xe9\x9d\x99\xe6\x80\x81\xe5\xb7\xa5\xe5\x85\xb7\xef\xbc\x9a\xe4\xbb\x8e txt \xe5\x8a\xa0\xe8\xbd\xbd\xe5\xa4\xb1\xe8\xb4\xa5\xe5\x88\x97\xe8\xa1\xa8\r\n    # ------------------------------------------------------------------\r\n\r\n    @staticmethod\r\n    def load_failed_list(\r\n        reports_dir: str = "./data/reports",\r\n    ) -> List[Tuple[str, int]]:\r\n        """\r\n        \xe4\xbb\x8e failed_stocks.txt \xe5\x8a\xa0\xe8\xbd\xbd\xe5\xa4\xb1\xe8\xb4\xa5\xe8\x82\xa1\xe7\xa5\xa8\xe5\x88\x97\xe8\xa1\xa8\xef\xbc\x8c\xe4\xbe\x9b --retry-failed \xe4\xbd\xbf\xe7\x94\xa8\xe3\x80\x82\r\n\r\n        Returns:\r\n            [(code, market), ...]\r\n        """\r\n        failed_path = Path(reports_dir) / "failed_stocks.txt"\r\n        if not failed_path.exists():\r\n            logger.warning("\xe6\x9c\xaa\xe6\x89\xbe\xe5\x88\xb0\xe5\xa4\xb1\xe8\xb4\xa5\xe5\x88\x97\xe8\xa1\xa8: %s", failed_path)\r\n            return []\r\n\r\n        result: List[Tuple[str, int]] = []\r\n        with open(failed_path, "r", encoding="utf-8") as f:\r\n            for line in f:\r\n                line = line.strip()\r\n                if not line or line.startswith("#"):\r\n                    continue\r\n                parts = line.split("\t")\r\n                if len(parts) >= 2:\r\n                    try:\r\n                        result.append((parts[0], int(parts[1])))\r\n                    except ValueError:\r\n                        logger.debug("\xe8\xb7\xb3\xe8\xbf\x87\xe6\x97\xa0\xe6\x95\x88\xe8\xa1\x8c: %s", line)\r\n        logger.info("\xe5\x8a\xa0\xe8\xbd\xbd\xe5\xa4\xb1\xe8\xb4\xa5\xe5\x88\x97\xe8\xa1\xa8: %d \xe5\x8f\xaa\xe8\x82\xa1\xe7\xa5\xa8", len(result))\r\n        return result\r\n'

FILE_src_data_collector_cache_manager_py = b'#!/usr/bin/env python3\r\n"""\r\nQ-UNITY-V6 \xe9\x87\x87\xe9\x9b\x86\xe5\x99\xa8\xe7\xbc\x93\xe5\xad\x98\xe7\xae\xa1\xe7\x90\x86\xe5\x99\xa8\r\n"""\r\nfrom __future__ import annotations\r\nimport json\r\nimport time\r\nfrom pathlib import Path\r\nfrom typing import Any, Optional\r\n\r\n\r\nclass CacheManager:\r\n    """\xe7\xae\x80\xe5\x8d\x95\xe7\x9a\x84\xe6\x9c\xac\xe5\x9c\xb0\xe6\x96\x87\xe4\xbb\xb6\xe7\xbc\x93\xe5\xad\x98\xe7\xae\xa1\xe7\x90\x86\xe5\x99\xa8\xef\xbc\x88JSON\xe6\xa0\xbc\xe5\xbc\x8f\xef\xbc\x8c\xe5\x90\xabTTL\xef\xbc\x89"""\r\n\r\n    def __init__(self, cache_dir: str = "./data/cache", ttl: int = 3600) -> None:\r\n        self.cache_dir = Path(cache_dir)\r\n        self.cache_dir.mkdir(parents=True, exist_ok=True)\r\n        self.ttl = ttl\r\n\r\n    def _path(self, key: str) -> Path:\r\n        safe_key = key.replace("/", "_").replace(":", "_")\r\n        return self.cache_dir / f"{safe_key}.json"\r\n\r\n    def get(self, key: str) -> Optional[Any]:\r\n        path = self._path(key)\r\n        if not path.exists():\r\n            return None\r\n        try:\r\n            data = json.loads(path.read_text(encoding="utf-8"))\r\n            if time.time() - data.get("ts", 0) > self.ttl:\r\n                path.unlink(missing_ok=True)\r\n                return None\r\n            return data.get("value")\r\n        except Exception:\r\n            return None\r\n\r\n    def set(self, key: str, value: Any) -> None:\r\n        path = self._path(key)\r\n        try:\r\n            path.write_text(\r\n                json.dumps({"ts": time.time(), "value": value}, ensure_ascii=False),\r\n                encoding="utf-8",\r\n            )\r\n        except Exception:\r\n            pass\r\n\r\n    def delete(self, key: str) -> None:\r\n        self._path(key).unlink(missing_ok=True)\r\n\r\n    def clear(self) -> int:\r\n        count = 0\r\n        for p in self.cache_dir.glob("*.json"):\r\n            p.unlink(missing_ok=True)\r\n            count += 1\r\n        return count\r\n'

FILE_src_data_collector_pipeline_py = b'#!/usr/bin/env python3\r\n# -*- coding: utf-8 -*-\r\n"""\r\npipeline.py \xe2\x80\x94 \xe5\x8f\x8c\xe8\xbd\xa8\xe9\x87\x87\xe9\x9b\x86\xe5\xbc\x95\xe6\x93\x8e V7.1 \xe4\xbf\xae\xe5\xa4\x8d\xe7\x89\x88\r\n========================================\r\n\r\n\xe3\x80\x90V7.1 \xe4\xbf\xae\xe5\xa4\x8d\xef\xbc\x9a\xe9\x98\xb6\xe6\xae\xb5\xe9\xa1\xba\xe5\xba\x8f\xe5\xbd\xbb\xe5\xba\x95\xe5\x8f\x8d\xe8\xbd\xac\xe3\x80\x91\r\n\r\n\xe5\x8e\x9f op-v3 \xe7\x9a\x84\xe6\x80\xa7\xe8\x83\xbd\xe9\x99\xb7\xe9\x98\xb1:\r\n  Phase 1: AKShare \xe5\x85\xa8\xe9\x87\x8f\xe4\xb8\xb2\xe8\xa1\x8c  5190\xe5\x8f\xaa \xc3\x97 7s / 2\xe8\xbf\x9b\xe7\xa8\x8b = 5+ \xe5\xb0\x8f\xe6\x97\xb6  \xe2\x86\x90 \xe5\x85\xa8\xe7\xa8\x8b\xe5\x8d\xa1\xe5\x9c\xa8\xe8\xbf\x99\xe9\x87\x8c\r\n  Phase 2: TDX \xe5\xa4\x9a\xe7\xba\xbf\xe7\xa8\x8b\xef\xbc\x88\xe7\xad\x89 Phase 1 \xe5\x85\xa8\xe9\x83\xa8\xe5\xae\x8c\xe6\x88\x90\xe6\x89\x8d\xe5\x90\xaf\xe5\x8a\xa8\xef\xbc\x8cpytdx \xe6\xa0\xb9\xe6\x9c\xac\xe6\xb2\xa1\xe6\x9c\x89\xe8\xa2\xab\xe8\xb0\x83\xe7\x94\xa8\xef\xbc\x81\xef\xbc\x89\r\n\r\nV7.1 \xe4\xbf\xae\xe5\xa4\x8d\xe6\x96\xb9\xe6\xa1\x88:\r\n  Phase 1: TDX \xe5\xa4\x9a\xe7\xba\xbf\xe7\xa8\x8b\xe5\xb9\xb6\xe5\x8f\x91\xef\xbc\x888\xe7\xba\xbf\xe7\xa8\x8b\xef\xbc\x8c~30\xe5\x88\x86\xe9\x92\x9f\xef\xbc\x89\xe2\x86\x92 \xe7\xab\x8b\xe5\x8d\xb3\xe6\xb5\x81\xe5\xbc\x8f\xe5\x86\x99\xe7\x9b\x98\r\n  Phase 2: AKShare \xe5\x8f\xaf\xe9\x80\x89\xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5\xe8\xa1\xa5\xe5\x85\x85\xef\xbc\x88enable_akshare=True \xe6\x97\xb6\xe5\x90\xaf\xe7\x94\xa8\xef\xbc\x89\r\n\r\n\xe3\x80\x90enable_akshare \xe5\x8f\x82\xe6\x95\xb0\xe3\x80\x91\r\n  False\xef\xbc\x88\xe9\xbb\x98\xe8\xae\xa4\xef\xbc\x89: \xe4\xbb\x85 TDX\xef\xbc\x8c~30min\xef\xbc\x8c\xe6\x97\xa0 turnover/pct_change \xe5\xad\x97\xe6\xae\xb5\r\n  True:          TDX \xe5\xae\x8c\xe6\x88\x90\xe5\x90\x8e\xe5\x86\x8d\xe8\xa1\xa5 AKShare \xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5\xef\xbc\x8c~2~4h \xe9\xa2\x9d\xe5\xa4\x96\r\n\r\n\xe3\x80\x90\xe6\x8e\xa8\xe8\x8d\x90\xe5\xb7\xa5\xe4\xbd\x9c\xe6\xb5\x81\xe3\x80\x91\r\n  1. \xe5\x85\xa8\xe9\x87\x8f\xe5\xbb\xba\xe5\xba\x93: StockDataPipeline(enable_akshare=False).download_all_a_stocks()\r\n  2. \xe6\x8c\x89\xe9\x9c\x80\xe8\xa1\xa5\xe5\x85\x85: StockDataPipeline(enable_akshare=True).enrich_akshare()\r\n  3. \xe6\xaf\x8f\xe6\x97\xa5\xe5\xa2\x9e\xe9\x87\x8f: StockDataPipeline(enable_akshare=False).run(stock_list)\r\n\r\n\xe3\x80\x90\xe5\xa4\x8d\xe6\x9d\x83\xe3\x80\x91\xe5\x85\xa8\xe7\xa8\x8b hfq\xef\xbc\x88\xe5\x90\x8e\xe5\xa4\x8d\xe6\x9d\x83\xef\xbc\x89\r\n  TDX: adjustflag=2\xef\xbc\x8c\xe8\x80\x81\xe8\x8a\x82\xe7\x82\xb9\xe4\xb8\x8d\xe6\x94\xaf\xe6\x8c\x81\xe6\x97\xb6\xe9\x99\x8d\xe7\xba\xa7\xe5\x8e\x9f\xe5\xa7\x8b\xe4\xbb\xb7\xe5\xb9\xb6\xe6\x89\x93\xe5\x8d\xb0 WARNING\r\n  AKShare: adjust="hfq"\r\n  BaoStock: adjustflag="1"\xef\xbc\x88\xe4\xb8\xa4\xe8\xbd\xa8\xe5\x9d\x87\xe5\xa4\xb1\xe8\xb4\xa5\xe6\x97\xb6\xe5\x85\x9c\xe5\xba\x95\xef\xbc\x89\r\n"""\r\n\r\nimport time\r\nimport random\r\nimport logging\r\nfrom datetime import date, datetime\r\nfrom pathlib import Path\r\nfrom typing import Dict, List, Optional, Tuple\r\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\r\n\r\nimport pandas as pd\r\n\r\ntry:\r\n    from tqdm import tqdm\r\n    _TQDM_AVAILABLE = True\r\nexcept ImportError:\r\n    tqdm = None  # type: ignore[assignment,misc]\r\n    _TQDM_AVAILABLE = False\r\n\r\nfrom .node_scanner import get_fastest_nodes, TDX_NODES\r\nfrom .tdx_pool import TDXConnectionPool\r\nfrom .akshare_client import run_akshare_batch, AK_EXTENDED_FIELDS, fetch_akshare_single\r\nfrom .baostock_client import fetch_baostock\r\nfrom .incremental import (\r\n    read_local_max_date, compute_missing_range,\r\n    is_up_to_date, load_local_df, merge_incremental, save_df,\r\n)\r\nfrom .validator import DataValidator\r\nfrom .run_report import RunReport\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\nBARS_PER_REQ: int   = 800\r\nTOTAL_BARS:   int   = 2500\r\nSLEEP_MIN:    float = 0.1\r\nSLEEP_MAX:    float = 0.2\r\n\r\ntry:\r\n    from pytdx.params import TDXParams\r\n    _KLINE_DAILY = TDXParams.KLINE_TYPE_DAILY\r\nexcept ImportError:\r\n    _KLINE_DAILY = 9\r\n\r\n\r\n# ============================================================================\r\n# TDX \xe5\x88\x86\xe7\x89\x87\xe4\xb8\x8b\xe8\xbd\xbd\xef\xbc\x88\xe7\xaa\x81\xe7\xa0\xb4 800-bar \xe9\x99\x90\xe5\x88\xb6\xef\xbc\x89\r\n# ============================================================================\r\n\r\ndef _tdx_fetch_chunked(\r\n    pool: TDXConnectionPool,\r\n    code: str,\r\n    market: int,\r\n    missing_bars: int,\r\n) -> Optional[pd.DataFrame]:\r\n    """\r\n    \xe9\x80\x9a\xe8\xbf\x87\xe8\xbf\x9e\xe6\x8e\xa5\xe6\xb1\xa0\xe5\x88\x86\xe7\x89\x87\xe6\x8b\x89\xe5\x8f\x96 TDX \xe6\x97\xa5\xe7\xba\xbf\xe6\x95\xb0\xe6\x8d\xae\xe3\x80\x82\r\n    \xe5\xa4\x8d\xe6\x9d\x83\xe6\x96\xb9\xe5\xbc\x8f\xef\xbc\x9a\xe4\xbc\x98\xe5\x85\x88 adjustflag=2\xef\xbc\x88\xe5\x90\x8e\xe5\xa4\x8d\xe6\x9d\x83 hfq\xef\xbc\x89\xef\xbc\x8c\xe8\x80\x81\xe8\x8a\x82\xe7\x82\xb9\xe4\xb8\x8d\xe6\x94\xaf\xe6\x8c\x81\xe6\x97\xb6\xe9\x99\x8d\xe7\xba\xa7\xe5\xb9\xb6\xe6\x89\x93\xe5\x8d\xb0 WARNING\xe3\x80\x82\r\n    """\r\n    api = pool.get_connection()\r\n    if api is None:\r\n        return None\r\n\r\n    all_bars: List[dict] = []\r\n    offset        = 0\r\n    bars_to_fetch = min(missing_bars, TOTAL_BARS)\r\n\r\n    try:\r\n        while offset < bars_to_fetch:\r\n            count = min(BARS_PER_REQ, bars_to_fetch - offset)\r\n            try:\r\n                bars = api.get_security_bars(\r\n                    category=_KLINE_DAILY,\r\n                    market=market,\r\n                    code=code,\r\n                    start=offset,\r\n                    count=count,\r\n                    adjustflag=2,\r\n                )\r\n            except Exception:\r\n                logger.warning(\r\n                    "%s \xe5\xbd\x93\xe5\x89\x8d TDX \xe8\x8a\x82\xe7\x82\xb9\xe4\xb8\x8d\xe6\x94\xaf\xe6\x8c\x81\xe5\xa4\x8d\xe6\x9d\x83\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x8c\xe5\x9b\x9e\xe9\x80\x80\xe8\x87\xb3\xe5\x8e\x9f\xe5\xa7\x8b\xe4\xbb\xb7\xef\xbc\x8c\xe6\xb3\xa8\xe6\x84\x8f\xe5\xa4\x8d\xe6\x9d\x83\xe4\xb8\x80\xe8\x87\xb4\xe6\x80\xa7\xe9\xa3\x8e\xe9\x99\xa9\xef\xbc\x81", code\r\n                )\r\n                bars = api.get_security_bars(\r\n                    category=_KLINE_DAILY,\r\n                    market=market,\r\n                    code=code,\r\n                    start=offset,\r\n                    count=count,\r\n                )\r\n\r\n            time.sleep(random.uniform(SLEEP_MIN, SLEEP_MAX))\r\n\r\n            if not bars:\r\n                break\r\n            all_bars.extend(bars)\r\n            if len(bars) < count:\r\n                break\r\n            offset += BARS_PER_REQ\r\n\r\n    except Exception as exc:\r\n        logger.warning("TDX \xe5\x88\x86\xe7\x89\x87\xe8\xaf\xb7\xe6\xb1\x82\xe5\xbc\x82\xe5\xb8\xb8 (%s): %s", code, exc)\r\n        pool.release()\r\n        return None\r\n\r\n    if not all_bars:\r\n        return None\r\n\r\n    return _clean_tdx_bars(all_bars, code, market)\r\n\r\n\r\ndef _clean_tdx_bars(raw: List[dict], code: str, market: int) -> pd.DataFrame:\r\n    """\xe5\x90\x91\xe9\x87\x8f\xe5\x8c\x96\xe6\xb8\x85\xe6\xb4\x97 TDX \xe5\x8e\x9f\xe5\xa7\x8b bar \xe6\x95\xb0\xe6\x8d\xae\xe3\x80\x82"""\r\n    df = pd.DataFrame(raw)\r\n    col_map = {"datetime": "date", "vol": "vol", "amount": "amount"}\r\n    df = df.rename(columns=col_map)\r\n    std_cols = ["date", "open", "high", "low", "close", "vol", "amount"]\r\n    df = df[[c for c in std_cols if c in df.columns]].copy()\r\n    df["date"] = pd.to_datetime(df["date"]).dt.strftime("%Y-%m-%d")\r\n    for col in ("open", "high", "low", "close"):\r\n        if col in df.columns:\r\n            df[col] = pd.to_numeric(df[col], errors="coerce").astype("float32")\r\n    for col in ("vol", "amount"):\r\n        if col in df.columns:\r\n            df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0).astype("int64")\r\n    df.insert(0, "code",   code)\r\n    df.insert(1, "market", market)\r\n    df["source"] = "tdx"\r\n    df["adjust"] = "hfq"\r\n    return df.sort_values("date").reset_index(drop=True)\r\n\r\n\r\ndef _estimate_missing_bars(start_date: str, end_date: str) -> int:\r\n    try:\r\n        s = datetime.strptime(start_date, "%Y-%m-%d")\r\n        e = datetime.strptime(end_date, "%Y-%m-%d")\r\n        return max(1, int((e - s).days * 0.72)) + 1\r\n    except Exception:\r\n        return TOTAL_BARS\r\n\r\n\r\n# ============================================================================\r\n# \xe5\x8f\x8c\xe8\xbd\xa8\xe5\x90\x88\xe5\xb9\xb6\r\n# ============================================================================\r\n\r\ndef _merge_dual_track(\r\n    tdx_df: Optional[pd.DataFrame],\r\n    ak_df: Optional[pd.DataFrame],\r\n) -> Optional[pd.DataFrame]:\r\n    """\r\n    TDX OHLCV \xe4\xb8\x8e AKShare \xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5\xe5\x90\x88\xe5\xb9\xb6\xef\xbc\x88date \xe4\xb8\xba\xe9\x94\xae\xef\xbc\x8c\xe4\xb8\xa4\xe8\x80\x85\xe5\x9d\x87 hfq\xef\xbc\x89\xe3\x80\x82\r\n    """\r\n    if tdx_df is None and ak_df is None:\r\n        return None\r\n    if tdx_df is None:\r\n        return ak_df\r\n    if ak_df is None:\r\n        return tdx_df\r\n\r\n    extended = [c for c in ("turnover", "pct_change", "amplitude", "change")\r\n                if c in ak_df.columns]\r\n    if not extended:\r\n        return tdx_df\r\n\r\n    ak_ext = ak_df[["date"] + extended].copy()\r\n    merged = pd.merge(tdx_df, ak_ext, on="date", how="left")\r\n    merged["adjust"] = "hfq"\r\n    return merged.sort_values("date").reset_index(drop=True)\r\n\r\n\r\n# ============================================================================\r\n# \xe5\x8d\x95\xe8\x82\xa1\xe5\xae\x8c\xe6\x95\xb4\xe6\x9b\xb4\xe6\x96\xb0\xe6\xb5\x81\xe7\xa8\x8b\r\n# ============================================================================\r\n\r\ndef update_single_stock(\r\n    code: str,\r\n    market: int,\r\n    parquet_dir: Path,\r\n    tdx_pool: TDXConnectionPool,\r\n    ak_results: Dict[str, Optional[pd.DataFrame]],\r\n    report: RunReport,\r\n    force_full: bool = False,\r\n) -> Tuple[str, bool, str]:\r\n    """\r\n    \xe5\x8d\x95\xe8\x82\xa1\xe5\xae\x8c\xe6\x95\xb4\xe6\x9b\xb4\xe6\x96\xb0\xe6\xb5\x81\xe7\xa8\x8b\xe3\x80\x82\r\n    ak_results \xe5\x8f\xaf\xe4\xb8\xba\xe7\xa9\xba\xe5\xad\x97\xe5\x85\xb8\xef\xbc\x88enable_akshare=False \xe6\x97\xb6\xef\xbc\x89\xef\xbc\x8c\xe6\xad\xa4\xe6\x97\xb6\xe4\xbb\x85\xe7\x94\xa8 TDX \xe6\x95\xb0\xe6\x8d\xae\xe3\x80\x82\r\n    """\r\n    parquet_path = parquet_dir / f"{code}.parquet"\r\n    today_str    = date.today().strftime("%Y-%m-%d")\r\n\r\n    local_max_date = None if force_full else read_local_max_date(parquet_path)\r\n\r\n    if not force_full and is_up_to_date(local_max_date, today_str):\r\n        report.record_skipped(code, market)\r\n        return code, True, "skipped"\r\n\r\n    start_date, end_date = compute_missing_range(local_max_date, today_str)\r\n    if start_date == end_date and not force_full:\r\n        report.record_skipped(code, market, reason="same_day")\r\n        return code, True, "skipped"\r\n\r\n    missing_bars = _estimate_missing_bars(start_date, end_date)\r\n\r\n    # \xe8\xbd\xa8\xe9\x81\x93 A: TDX\r\n    tdx_df: Optional[pd.DataFrame] = None\r\n    try:\r\n        raw = _tdx_fetch_chunked(tdx_pool, code, market, missing_bars)\r\n        if raw is not None and not raw.empty:\r\n            tdx_df = raw[raw["date"] >= start_date].copy()\r\n            if tdx_df.empty:\r\n                tdx_df = None\r\n    except Exception as exc:\r\n        logger.debug("TDX \xe8\xbd\xa8\xe9\x81\x93\xe5\xbc\x82\xe5\xb8\xb8 (%s): %s", code, exc)\r\n\r\n    # \xe8\xbd\xa8\xe9\x81\x93 B: AKShare\xef\xbc\x88\xe5\x8f\xaf\xe8\x83\xbd\xe4\xb8\xba\xe7\xa9\xba\xe5\xad\x97\xe5\x85\xb8\xef\xbc\x89\r\n    ak_df: Optional[pd.DataFrame] = ak_results.get(code)\r\n    if ak_df is not None and not ak_df.empty:\r\n        ak_df = ak_df[ak_df["date"] >= start_date].copy()\r\n        if ak_df.empty:\r\n            ak_df = None\r\n\r\n    # \xe5\x8f\x8c\xe8\xbd\xa8\xe5\x90\x88\xe5\xb9\xb6\r\n    new_df = _merge_dual_track(tdx_df, ak_df)\r\n    source_tag = "merged" if (tdx_df is not None and ak_df is not None) \\\r\n        else ("tdx" if ak_df is None else "akshare")\r\n\r\n    # BaoStock \xe5\x85\x9c\xe5\xba\x95\r\n    if new_df is None:\r\n        bs_df = fetch_baostock(code, market, start_date, end_date)\r\n        if bs_df is not None and not bs_df.empty:\r\n            new_df     = bs_df\r\n            source_tag = "baostock"\r\n        else:\r\n            report.record_failed(code, market, reason="complete_fail")\r\n            return code, False, "failed"\r\n\r\n    # \xe6\x95\xb0\xe6\x8d\xae\xe9\xaa\x8c\xe8\xaf\x81\r\n    ok, reason = DataValidator.validate(new_df, code=code)\r\n    if not ok:\r\n        logger.warning("\xe6\x95\xb0\xe6\x8d\xae\xe9\xaa\x8c\xe8\xaf\x81\xe5\xa4\xb1\xe8\xb4\xa5 (%s): %s", code, reason)\r\n        report.record_validation_failure(code, reason)\r\n        report.record_failed(code, market, reason=f"validate:{reason}")\r\n        return code, False, "validate_fail"\r\n\r\n    # \xe5\xa2\x9e\xe9\x87\x8f\xe5\x90\x88\xe5\xb9\xb6\r\n    if force_full:\r\n        merged_df = new_df\r\n    else:\r\n        local_df  = load_local_df(parquet_path)\r\n        merged_df = merge_incremental(local_df, new_df)\r\n\r\n    ok2, reason2 = DataValidator.validate_merge_result(merged_df, code)\r\n    if not ok2:\r\n        logger.warning("\xe5\x90\x88\xe5\xb9\xb6\xe5\x90\x8e\xe9\xaa\x8c\xe8\xaf\x81\xe5\xa4\xb1\xe8\xb4\xa5 (%s): %s", code, reason2)\r\n        report.record_failed(code, market, reason=f"merge_validate:{reason2}")\r\n        return code, False, "merge_validate_fail"\r\n\r\n    # \xe6\xb5\x81\xe5\xbc\x8f\xe5\x86\x99\xe7\x9b\x98\r\n    ok3 = save_df(merged_df, parquet_path)\r\n    if not ok3:\r\n        report.record_failed(code, market, reason="save_failed")\r\n        return code, False, "save_failed"\r\n\r\n    report.record_success(code, market, source=source_tag, rows=len(merged_df))\r\n    return code, True, source_tag\r\n\r\n\r\n# ============================================================================\r\n# \xe4\xb8\xbb\xe5\xbc\x95\xe6\x93\x8e\xef\xbc\x9aStockDataPipeline V7.1\r\n# ============================================================================\r\n\r\nclass StockDataPipeline:\r\n    """\r\n    A \xe8\x82\xa1\xe6\x97\xa5\xe7\xba\xbf\xe9\x87\x87\xe9\x9b\x86\xe5\xbc\x95\xe6\x93\x8e V7.1 \xe4\xbf\xae\xe5\xa4\x8d\xe7\x89\x88\xe3\x80\x82\r\n\r\n    \xe3\x80\x90V7.1 \xe4\xbf\xae\xe5\xa4\x8d\xe8\xaf\xb4\xe6\x98\x8e\xe3\x80\x91\r\n    op-v3 \xe5\xb0\x86 AKShare \xe6\x94\xbe Phase 1\xef\xbc\x885190\xe5\x8f\xaa \xc3\x97 7s / 2\xe8\xbf\x9b\xe7\xa8\x8b = 5+\xe5\xb0\x8f\xe6\x97\xb6\xe5\x85\xa8\xe7\xa8\x8b\xe9\x98\xbb\xe5\xa1\x9e\xef\xbc\x89\xef\xbc\x8c\r\n    TDX \xe8\xa6\x81\xe7\xad\x89 AKShare \xe5\x85\xa8\xe9\x83\xa8\xe5\xae\x8c\xe6\x88\x90\xe6\x89\x8d\xe5\x90\xaf\xe5\x8a\xa8\xe3\x80\x82V7.1 \xe4\xbf\xae\xe5\xa4\x8d\xe4\xb8\xba TDX \xe5\x85\x88\xe3\x80\x81AKShare \xe5\x90\x8e\xe3\x80\x82\r\n\r\n    \xe6\x89\xa7\xe8\xa1\x8c\xe9\xa1\xba\xe5\xba\x8f (enable_akshare=False\xef\xbc\x8c\xe9\xbb\x98\xe8\xae\xa4\xe5\xbf\xab\xe9\x80\x9f\xe6\xa8\xa1\xe5\xbc\x8f):\r\n      Phase 1: TDX 8\xe7\xba\xbf\xe7\xa8\x8b\xe5\xb9\xb6\xe5\x8f\x91\xe9\x87\x87\xe9\x9b\x86\xef\xbc\x88~30\xe5\x88\x86\xe9\x92\x9f\xef\xbc\x89\xe2\x86\x92 \xe7\xab\x8b\xe5\x8d\xb3\xe6\xb5\x81\xe5\xbc\x8f\xe5\x86\x99\xe7\x9b\x98\r\n\r\n    \xe6\x89\xa7\xe8\xa1\x8c\xe9\xa1\xba\xe5\xba\x8f (enable_akshare=True\xef\xbc\x8c\xe5\xae\x8c\xe6\x95\xb4\xe5\x8f\x8c\xe8\xbd\xa8):\r\n      Phase 1: TDX 8\xe7\xba\xbf\xe7\xa8\x8b\xef\xbc\x88~30\xe5\x88\x86\xe9\x92\x9f\xef\xbc\x89\xe2\x86\x92 \xe6\xb5\x81\xe5\xbc\x8f\xe5\x86\x99\xe7\x9b\x98\r\n      Phase 2: AKShare 2\xe8\xbf\x9b\xe7\xa8\x8b\xe8\xa1\xa5\xe5\x85\x85 turnover/pct_change\xef\xbc\x88~2~4\xe5\xb0\x8f\xe6\x97\xb6\xef\xbc\x89\xe2\x86\x92 \xe5\x90\x88\xe5\xb9\xb6\xe5\x86\x99\xe7\x9b\x98\r\n\r\n    Args:\r\n        enable_akshare: False=\xe5\xbf\xab\xe9\x80\x9f(\xe4\xbb\x85TDX)\xef\xbc\x8cTrue=\xe5\x8f\x8c\xe8\xbd\xa8(TDX+AKShare)\r\n    """\r\n\r\n    def __init__(\r\n        self,\r\n        parquet_dir:    str   = "./data/parquet",\r\n        reports_dir:    str   = "./data/reports",\r\n        top_n_nodes:    int   = 5,\r\n        tdx_workers:    int   = 8,\r\n        ak_workers:     int   = 2,\r\n        node_timeout:   float = 3.0,\r\n        tdx_timeout:    float = 10.0,\r\n        ak_delay_min:   float = 0.3,\r\n        ak_delay_max:   float = 0.8,\r\n        ak_max_retries: int   = 3,\r\n        force_full:     bool  = False,\r\n        enable_akshare: bool  = False,  # V7.1: \xe9\xbb\x98\xe8\xae\xa4\xe5\x85\xb3\xe9\x97\xad\xef\xbc\x8c\xe5\x85\xa8\xe9\x87\x8f\xe6\x97\xb6\xe4\xb8\x8d\xe9\x98\xbb\xe5\xa1\x9e\r\n    ) -> None:\r\n        self.parquet_dir    = Path(parquet_dir)\r\n        self.parquet_dir.mkdir(parents=True, exist_ok=True)\r\n        self.reports_dir    = reports_dir\r\n        self.tdx_workers    = tdx_workers\r\n        self.ak_workers     = ak_workers\r\n        self.ak_delay_min   = ak_delay_min\r\n        self.ak_delay_max   = ak_delay_max\r\n        self.ak_max_retries = ak_max_retries\r\n        self.force_full     = force_full\r\n        self.enable_akshare = enable_akshare\r\n\r\n        logger.info("\xe8\x8a\x82\xe7\x82\xb9\xe8\xb5\x9b\xe9\xa9\xac\xe6\xb5\x8b\xe8\xaf\x95\xef\xbc\x88%d \xe4\xb8\xaa\xe5\x80\x99\xe9\x80\x89\xe8\x8a\x82\xe7\x82\xb9\xef\xbc\x89\xe2\x80\xa6", len(TDX_NODES))\r\n        self.top_nodes = get_fastest_nodes(top_n=top_n_nodes, timeout=node_timeout)\r\n        if self.top_nodes:\r\n            logger.info(\r\n                "\xe9\x80\x89\xe5\x87\xba\xe8\x8a\x82\xe7\x82\xb9: %s",\r\n                [f"{n[\'name\']}({n[\'latency_ms\']:.0f}ms)" for n in self.top_nodes],\r\n            )\r\n        else:\r\n            logger.warning("\xe6\x89\x80\xe6\x9c\x89\xe8\x8a\x82\xe7\x82\xb9\xe4\xb8\x8d\xe5\x8f\xaf\xe8\xbe\xbe")\r\n\r\n        self.tdx_pool = TDXConnectionPool(top_nodes=self.top_nodes, timeout=tdx_timeout)\r\n\r\n    # ------------------------------------------------------------------\r\n    # \xe4\xb8\xbb\xe5\x85\xa5\xe5\x8f\xa3\r\n    # ------------------------------------------------------------------\r\n\r\n    def run(self, stock_list: List[Tuple[str, int]]) -> Dict:\r\n        """\r\n        \xe6\x89\xb9\xe9\x87\x8f\xe6\x9b\xb4\xe6\x96\xb0\xe8\x82\xa1\xe7\xa5\xa8\xe6\x97\xa5\xe7\xba\xbf\xe6\x95\xb0\xe6\x8d\xae\xe3\x80\x82\r\n\r\n        V7.1 \xe9\xa1\xba\xe5\xba\x8f: Phase1=TDX\xe5\xb9\xb6\xe5\x8f\x91\xe5\x86\x99\xe7\x9b\x98\xef\xbc\x88\xe5\xbf\xab\xe9\x80\x9f\xe4\xb8\xbb\xe8\xbd\xa8\xef\xbc\x89\xe2\x86\x92 Phase2=AKShare\xe5\x8f\xaf\xe9\x80\x89\xe6\x89\xa9\xe5\xb1\x95\r\n        """\r\n        total  = len(stock_list)\r\n        report = RunReport(self.reports_dir)\r\n        today  = date.today().strftime("%Y-%m-%d")\r\n\r\n        mode_str = "\xe5\x8f\x8c\xe8\xbd\xa8(TDX+AKShare)" if self.enable_akshare else "\xe5\xbf\xab\xe9\x80\x9f(\xe4\xbb\x85TDX)"\r\n        logger.info("V7.1 \xe9\x87\x87\xe9\x9b\x86: %d \xe5\x8f\xaa | \xe6\xa8\xa1\xe5\xbc\x8f=%s | TDX=%d\xe7\xba\xbf\xe7\xa8\x8b", total, mode_str, self.tdx_workers)\r\n\r\n        # \xe2\x94\x80\xe2\x94\x80 Phase 1: TDX \xe5\xb9\xb6\xe5\x8f\x91\xe9\x87\x87\xe9\x9b\x86\xef\xbc\x88\xe5\xbf\xab\xe9\x80\x9f\xe4\xb8\xbb\xe8\xbd\xa8\xef\xbc\x89\xe2\x94\x80\xe2\x94\x80 #\r\n        logger.info("\xe2\x94\x80\xe2\x94\x80 Phase 1: TDX \xe5\xb9\xb6\xe5\x8f\x91\xe9\x87\x87\xe9\x9b\x86 + \xe6\xb5\x81\xe5\xbc\x8f\xe5\x86\x99\xe7\x9b\x98\xef\xbc\x88%d \xe5\x8f\xaa\xef\xbc\x89\xe2\x80\xa6", total)\r\n\r\n        t0   = time.perf_counter()\r\n        pbar = None\r\n        if _TQDM_AVAILABLE:\r\n            pbar = tqdm(total=total,\r\n                        desc=f"TDX\xe9\x87\x87\xe9\x9b\x86[{self.tdx_workers}\xe7\xba\xbf\xe7\xa8\x8b]",\r\n                        unit="\xe8\x82\xa1", colour="green", dynamic_ncols=True)\r\n\r\n        # Phase 1 \xe4\xb8\xad AKShare \xe7\xbb\x93\xe6\x9e\x9c\xe4\xb8\xba\xe7\xa9\xba\xef\xbc\x88\xe4\xb8\x8d\xe5\x90\xaf\xe5\x8a\xa8 AKShare \xe8\xbf\x9b\xe7\xa8\x8b\xef\xbc\x89\r\n        empty_ak: Dict[str, Optional[pd.DataFrame]] = {}\r\n\r\n        def _tdx_worker(args: Tuple[str, int]) -> Tuple[str, bool, str]:\r\n            code, market = args\r\n            return update_single_stock(\r\n                code=code, market=market,\r\n                parquet_dir=self.parquet_dir,\r\n                tdx_pool=self.tdx_pool,\r\n                ak_results=empty_ak,\r\n                report=report,\r\n                force_full=self.force_full,\r\n            )\r\n\r\n        with ThreadPoolExecutor(max_workers=self.tdx_workers) as executor:\r\n            future_map = {executor.submit(_tdx_worker, task): task for task in stock_list}\r\n            for future in as_completed(future_map):\r\n                try:\r\n                    _code, _ok, _src = future.result()\r\n                except Exception as exc:\r\n                    task = future_map[future]\r\n                    logger.error("TDX Worker \xe5\xbc\x82\xe5\xb8\xb8 (%s): %s", task[0], exc)\r\n                    report.record_failed(task[0], task[1], reason=f"worker_exception:{exc}")\r\n                if pbar is not None:\r\n                    pbar.update(1)\r\n                    pbar.set_postfix_str(report.summary_str())\r\n\r\n        if pbar is not None:\r\n            pbar.close()\r\n\r\n        t1 = time.perf_counter()\r\n        logger.info("Phase 1 TDX \xe5\xae\x8c\xe6\x88\x90: %s | %.1fs | %.1f\xe8\x82\xa1/s",\r\n                    report.summary_str(), t1 - t0,\r\n                    total / (t1 - t0) if t1 > t0 else 0)\r\n\r\n        # \xe2\x94\x80\xe2\x94\x80 Phase 2: AKShare \xe5\x8f\xaf\xe9\x80\x89\xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5 \xe2\x94\x80\xe2\x94\x80 #\r\n        if self.enable_akshare:\r\n            success_codes = set(report._success.keys())\r\n            ak_targets = [(c, m) for c, m in stock_list if c in success_codes]\r\n            if ak_targets:\r\n                logger.info("\xe2\x94\x80\xe2\x94\x80 Phase 2: AKShare \xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5\xe8\xa1\xa5\xe5\x85\x85\xef\xbc\x88%d \xe5\x8f\xaa\xef\xbc\x89\xe2\x80\xa6", len(ak_targets))\r\n                self._enrich_akshare_phase(ak_targets, report)\r\n            else:\r\n                logger.info("\xe2\x94\x80\xe2\x94\x80 Phase 2: \xe6\x97\xa0\xe6\x88\x90\xe5\x8a\x9f\xe8\x82\xa1\xe7\xa5\xa8\xef\xbc\x8c\xe8\xb7\xb3\xe8\xbf\x87 AKShare")\r\n\r\n        report.save()\r\n\r\n        elapsed = time.perf_counter() - t0\r\n        result = {\r\n            "total":           total,\r\n            "success":         report.total_success,\r\n            "failed":          report.total_failed,\r\n            "skipped":         report.total_skipped,\r\n            "elapsed_s":       round(elapsed, 2),\r\n            "speed":           round(total / elapsed, 2) if elapsed > 0 else 0,\r\n            "reports_dir":     str(self.reports_dir),\r\n            "akshare_enabled": self.enable_akshare,\r\n        }\r\n        logger.info("\xe9\x87\x87\xe9\x9b\x86\xe5\xae\x8c\xe6\x88\x90: %s | %.1fs | %.1f\xe8\x82\xa1/s",\r\n                    report.summary_str(), elapsed, result["speed"])\r\n        return result\r\n\r\n    # ------------------------------------------------------------------\r\n    # AKShare \xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5\xe7\x8b\xac\xe7\xab\x8b\xe8\xa1\xa5\xe5\x85\x85\xef\xbc\x88\xe5\x8f\xaf\xe5\x9c\xa8 TDX \xe9\x87\x87\xe9\x9b\x86\xe5\xae\x8c\xe6\x88\x90\xe5\x90\x8e\xe5\x8d\x95\xe7\x8b\xac\xe8\xb0\x83\xe7\x94\xa8\xef\xbc\x89\r\n    # ------------------------------------------------------------------\r\n\r\n    def enrich_akshare(self, stock_list: Optional[List[Tuple[str, int]]] = None) -> Dict:\r\n        """\r\n        \xe5\xaf\xb9\xe6\x9c\xac\xe5\x9c\xb0 Parquet \xe6\x96\x87\xe4\xbb\xb6\xe8\xa1\xa5\xe5\x85\x85 AKShare \xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5\xef\xbc\x88turnover / pct_change\xef\xbc\x89\xe3\x80\x82\r\n        \xe5\x8f\xaf\xe5\x9c\xa8 TDX \xe5\xbf\xab\xe9\x80\x9f\xe6\xa8\xa1\xe5\xbc\x8f\xe9\x87\x87\xe9\x9b\x86\xe5\xae\x8c\xe6\x88\x90\xe5\x90\x8e\xe5\x8d\x95\xe7\x8b\xac\xe8\xb0\x83\xe7\x94\xa8\xef\xbc\x8c\xe6\x97\xa0\xe9\x9c\x80\xe9\x87\x8d\xe8\xb7\x91 TDX\xe3\x80\x82\r\n\r\n        Args:\r\n            stock_list: [(code, market), ...] \xe8\x8b\xa5\xe4\xb8\xba None \xe5\x88\x99\xe8\x87\xaa\xe5\x8a\xa8\xe6\x89\xab\xe6\x8f\x8f\xe6\x9c\xac\xe5\x9c\xb0\xe6\x89\x80\xe6\x9c\x89 Parquet\r\n\r\n        Returns:\r\n            \xe7\xbb\x9f\xe8\xae\xa1\xe5\xad\x97\xe5\x85\xb8 {total, success, failed}\r\n        """\r\n        if stock_list is None:\r\n            codes = [f.stem for f in self.parquet_dir.glob("*.parquet")]\r\n            stock_list = []\r\n            for code in codes:\r\n                market = 1 if code.startswith(("60", "68")) else 0\r\n                stock_list.append((code, market))\r\n\r\n        if not stock_list:\r\n            logger.info("enrich_akshare: \xe6\x97\xa0\xe5\x8f\xaf\xe8\xa1\xa5\xe5\x85\x85\xe7\x9a\x84\xe8\x82\xa1\xe7\xa5\xa8")\r\n            return {"total": 0, "success": 0, "failed": 0}\r\n\r\n        report = RunReport(self.reports_dir)\r\n        logger.info("AKShare \xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5\xe8\xa1\xa5\xe5\x85\x85\xef\xbc\x88\xe7\x8b\xac\xe7\xab\x8b\xe6\xa8\xa1\xe5\xbc\x8f\xef\xbc\x89: %d \xe5\x8f\xaa", len(stock_list))\r\n        self._enrich_akshare_phase(stock_list, report)\r\n        report.save()\r\n        return {\r\n            "total":   len(stock_list),\r\n            "success": report.total_success,\r\n            "failed":  report.total_failed,\r\n        }\r\n\r\n    def _enrich_akshare_phase(\r\n        self,\r\n        stock_list: List[Tuple[str, int]],\r\n        report: RunReport,\r\n    ) -> None:\r\n        """\r\n        \xe5\x86\x85\xe9\x83\xa8\xef\xbc\x9aAKShare \xe8\xbf\x9b\xe7\xa8\x8b\xe6\xb1\xa0\xe6\x89\xb9\xe9\x87\x8f\xe9\x87\x87\xe9\x9b\x86\xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5\xef\xbc\x8c\xe5\x86\x8d LEFT JOIN \xe5\x86\x99\xe5\x85\xa5\xe6\x9c\xac\xe5\x9c\xb0 Parquet\xe3\x80\x82\r\n        """\r\n        today = date.today().strftime("%Y-%m-%d")\r\n\r\n        ak_tasks = []\r\n        for code, _market in stock_list:\r\n            parquet_path   = self.parquet_dir / f"{code}.parquet"\r\n            local_max_date = read_local_max_date(parquet_path)\r\n            start_date, end_date = compute_missing_range(local_max_date, today)\r\n            if start_date != end_date or self.force_full:\r\n                ak_tasks.append((code, start_date, end_date))\r\n\r\n        if not ak_tasks:\r\n            logger.info("AKShare \xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5: \xe6\x89\x80\xe6\x9c\x89\xe8\x82\xa1\xe7\xa5\xa8\xe5\xb7\xb2\xe6\x98\xaf\xe6\x9c\x80\xe6\x96\xb0\xef\xbc\x8c\xe8\xb7\xb3\xe8\xbf\x87")\r\n            return\r\n\r\n        ak_pbar = None\r\n        if _TQDM_AVAILABLE:\r\n            ak_pbar = tqdm(total=len(ak_tasks), desc="AKShare\xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5",\r\n                           unit="\xe8\x82\xa1", colour="blue", dynamic_ncols=True)\r\n\r\n        def _ak_cb(code: str, success: bool, error) -> None:\r\n            if ak_pbar:\r\n                ak_pbar.update(1)\r\n                ak_pbar.set_postfix_str(f"{\'OK\' if success else \'NG\'} {code}")\r\n\r\n        ak_results = run_akshare_batch(\r\n            stock_list=ak_tasks,\r\n            max_workers=self.ak_workers,\r\n            max_retries=self.ak_max_retries,\r\n            delay_min=self.ak_delay_min,\r\n            delay_max=self.ak_delay_max,\r\n            progress_callback=_ak_cb,\r\n        )\r\n        if ak_pbar:\r\n            ak_pbar.close()\r\n\r\n        ak_ok = sum(1 for v in ak_results.values() if v is not None)\r\n        logger.info("AKShare \xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5\xe9\x87\x87\xe9\x9b\x86\xe5\xae\x8c\xe6\x88\x90: %d/%d \xe6\x88\x90\xe5\x8a\x9f", ak_ok, len(ak_tasks))\r\n\r\n        # \xe5\xb0\x86 AKShare \xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5 LEFT JOIN \xe5\x86\x99\xe5\x9b\x9e\xe6\x9c\xac\xe5\x9c\xb0 Parquet\r\n        merged_count = 0\r\n        for code, ak_df in ak_results.items():\r\n            if ak_df is None or ak_df.empty:\r\n                continue\r\n            try:\r\n                parquet_path = self.parquet_dir / f"{code}.parquet"\r\n                local_df = load_local_df(parquet_path)\r\n                if local_df is None or local_df.empty:\r\n                    continue\r\n                extended = [c for c in ("turnover", "pct_change", "amplitude", "change")\r\n                            if c in ak_df.columns]\r\n                if not extended:\r\n                    continue\r\n                ak_ext   = ak_df[["date"] + extended].copy()\r\n                drop_old = [c for c in extended if c in local_df.columns]\r\n                if drop_old:\r\n                    local_df = local_df.drop(columns=drop_old)\r\n                merged_df = pd.merge(local_df, ak_ext, on="date", how="left")\r\n                ok_v, _ = DataValidator.validate_merge_result(merged_df, code)\r\n                if ok_v:\r\n                    save_df(merged_df, parquet_path)\r\n                    merged_count += 1\r\n                    report.record_success(code, 0, source="akshare_enrich",\r\n                                          rows=len(merged_df))\r\n            except Exception as exc:\r\n                logger.warning("AKShare \xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5\xe5\x86\x99\xe5\x85\xa5\xe5\xa4\xb1\xe8\xb4\xa5 (%s): %s", code, exc)\r\n\r\n        logger.info("AKShare \xe6\x89\xa9\xe5\xb1\x95\xe5\xad\x97\xe6\xae\xb5\xe5\x86\x99\xe5\x85\xa5 %d \xe5\x8f\xaa\xe8\x82\xa1\xe7\xa5\xa8", merged_count)\r\n\r\n    # ------------------------------------------------------------------\r\n    # \xe5\xb7\xa5\xe5\x85\xb7\xe6\x96\xb9\xe6\xb3\x95\r\n    # ------------------------------------------------------------------\r\n\r\n    def download_all_a_stocks(self) -> Dict:\r\n        """\xe4\xb8\x80\xe9\x94\xae\xe4\xb8\x8b\xe8\xbd\xbd\xe5\x85\xa8\xe9\x87\x8f A \xe8\x82\xa1\xe3\x80\x82"""\r\n        stock_list = self._get_all_a_stock_list()\r\n        if not stock_list:\r\n            logger.error("\xe8\x8e\xb7\xe5\x8f\x96 A \xe8\x82\xa1\xe5\x88\x97\xe8\xa1\xa8\xe5\xa4\xb1\xe8\xb4\xa5")\r\n            return {}\r\n        return self.run(stock_list)\r\n\r\n    def retry_failed(self, reports_dir: Optional[str] = None) -> Dict:\r\n        """\xe4\xbb\x8e failed_stocks.txt \xe5\x8a\xa0\xe8\xbd\xbd\xe5\xa4\xb1\xe8\xb4\xa5\xe5\x88\x97\xe8\xa1\xa8\xef\xbc\x8c\xe9\x87\x8d\xe6\x96\xb0\xe9\x87\x87\xe9\x9b\x86\xe3\x80\x82"""\r\n        rdir = reports_dir or self.reports_dir\r\n        failed_list = RunReport.load_failed_list(rdir)\r\n        if not failed_list:\r\n            logger.info("failed_stocks.txt \xe4\xb8\xba\xe7\xa9\xba\xe6\x88\x96\xe4\xb8\x8d\xe5\xad\x98\xe5\x9c\xa8\xef\xbc\x8c\xe6\x97\xa0\xe9\x9c\x80\xe8\xa1\xa5\xe9\x87\x87")\r\n            return {"total": 0}\r\n        logger.info("\xe5\xbc\x80\xe5\xa7\x8b\xe8\xa1\xa5\xe9\x87\x87 %d \xe5\x8f\xaa\xe5\xa4\xb1\xe8\xb4\xa5\xe8\x82\xa1\xe7\xa5\xa8\xe2\x80\xa6", len(failed_list))\r\n        old_force = self.force_full\r\n        self.force_full = True\r\n        result = self.run(failed_list)\r\n        self.force_full = old_force\r\n        return result\r\n\r\n    def _get_all_a_stock_list(self) -> List[Tuple[str, int]]:\r\n        """\xe9\x80\x9a\xe8\xbf\x87 TDX \xe8\x8e\xb7\xe5\x8f\x96\xe5\x85\xa8\xe9\x87\x8f A \xe8\x82\xa1\xe4\xbb\xa3\xe7\xa0\x81\xe5\x88\x97\xe8\xa1\xa8\xe3\x80\x82"""\r\n        api = self.tdx_pool.get_connection()\r\n        if api is None:\r\n            return []\r\n        try:\r\n            stocks: List[Tuple[str, int]] = []\r\n            for market in (0, 1):\r\n                count = api.get_security_count(market)\r\n                logger.info("\xe5\xb8\x82\xe5\x9c\xba %d \xe6\x80\xbb\xe8\xae\xb0\xe5\xbd\x95\xe6\x95\xb0: %d", market, count)\r\n                for start in range(0, count, 1000):\r\n                    batch = api.get_security_list(market, start)\r\n                    if not batch:\r\n                        continue\r\n                    for item in batch:\r\n                        code = item["code"]\r\n                        if market == 0 and code.startswith(("00", "30")):\r\n                            stocks.append((code, market))\r\n                        elif market == 1 and code.startswith(("60", "68")):\r\n                            stocks.append((code, market))\r\n            stocks = list(set(stocks))\r\n            logger.info("A \xe8\x82\xa1\xe6\x80\xbb\xe6\x95\xb0: %d", len(stocks))\r\n            return stocks\r\n        except Exception as exc:\r\n            logger.error("\xe8\x8e\xb7\xe5\x8f\x96\xe8\x82\xa1\xe7\xa5\xa8\xe5\x88\x97\xe8\xa1\xa8\xe5\xa4\xb1\xe8\xb4\xa5: %s", exc)\r\n            return []\r\n'

FILE_src_engine_init_py = b'#!/usr/bin/env python3\r\n"""Q-UNITY-V6 \xe6\x89\xa7\xe8\xa1\x8c\xe5\xbc\x95\xe6\x93\x8e\xe6\xa8\xa1\xe5\x9d\x97"""\r\nfrom .execution import BacktestEngine, Account, PositionManager, PerformanceCalculator\r\n__all__ = ["BacktestEngine", "Account", "PositionManager", "PerformanceCalculator"]\r\n'

FILE_src_engine_execution_py = b'#!/usr/bin/env python3\r\n"""\r\nQ-UNITY-V6 \xe5\x9b\x9e\xe6\xb5\x8b\xe6\x89\xa7\xe8\xa1\x8c\xe5\xbc\x95\xe6\x93\x8e \xe2\x80\x94 \xe5\x85\xa8\xe9\x87\x8f Bug \xe4\xbf\xae\xe5\xa4\x8d\xe7\x89\x88\r\n\xe4\xbf\xae\xe5\xa4\x8d\xe6\xb8\x85\xe5\x8d\x95:\r\n  NB-01: \xe4\xbf\xa1\xe5\x8f\xb7\xe7\x94\xa8T-1\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x8cT\xe6\x97\xa5\xe5\xbc\x80\xe7\x9b\x98\xe6\x89\xa7\xe8\xa1\x8c(\xe6\x97\xa0\xe5\x89\x8d\xe8\xa7\x86\xe5\x81\x8f\xe5\xb7\xae)\r\n  NB-02: available_cash = max(0, cash - frozen_cash) @property\r\n  NB-03: trade_win_rate \xe7\x94\xa8FIFO\xe9\x85\x8d\xe5\xaf\xb9\xe8\xae\xa1\xe7\xae\x97\r\n  NB-04: \xe5\xb9\xb4\xe5\x8c\x96\xe6\x94\xb6\xe7\x9b\x8a\xe7\x8e\x87\xe5\x88\x86\xe6\xaf\x8d = n_trading_days - 1\r\n  NB-05: Account.__init__ \xe7\xab\x8b\xe5\x8d\xb3\xe8\xae\xb0\xe5\xbd\x95\xe5\x88\x9d\xe5\xa7\x8b\xe5\xbf\xab\xe7\x85\xa7\r\n  NB-06: commission \xe5\x8f\x8c\xe8\xbe\xb9\xe6\x94\xb6\xe5\x8f\x96\xef\xbc\x88\xe4\xb9\xb0\xe5\x8d\x96\xe5\x9d\x87\xe7\xae\x97\xef\xbc\x89\r\n  NB-07: slippage \xe6\x96\xb9\xe5\x90\x91\xe4\xbf\xae\xe6\xad\xa3\xef\xbc\x88\xe4\xb9\xb0\xe5\x8a\xa0/\xe5\x8d\x96\xe5\x87\x8f\xef\xbc\x89\r\n  NB-08: trailing_stop watermark \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96\xe4\xb8\xba entry_price\r\n  NB-09: get_latest_factor \xe5\xa2\x9e\xe5\x8a\xa0 date_boundary_idx \xe5\x8f\x82\xe6\x95\xb0\r\n  NB-10: \xe6\x9c\x80\xe5\xa4\xa7\xe5\x9b\x9e\xe6\x92\xa4\xe5\xb3\xb0\xe5\x80\xbc\xe7\xb4\xa2\xe5\xbc\x95\xe6\xad\xa3\xe7\xa1\xae\xe5\xa4\x84\xe7\x90\x86\r\n  NB-11: Sortino = inf \xe5\xbd\x93\xe6\x97\xa0\xe8\xb4\x9f\xe5\x81\x8f\xe7\xa6\xbb\r\n  NB-12: \xe7\x86\x94\xe6\x96\xad cooldown_days \xe5\x90\x8e\xe8\x87\xaa\xe5\x8a\xa8\xe8\xa7\xa3\xe9\x99\xa4\r\n  NB-13: position.available_volume \xe5\x86\xbb\xe7\xbb\x93\xe6\x97\xb6\xe5\x87\x8f\xe5\xb0\x91\r\n  NB-14: \xe7\x9f\xad\xe7\xba\xbf\xe7\xad\x96\xe7\x95\xa5\xe6\x97\xb6\xe9\x97\xb4\xe6\xad\xa2\xe6\x8d\x9f\xe7\x94\xa8\xe6\x97\xa5\xe5\x8e\x86\xe6\x97\xa5\r\n  NB-15: \xe6\xad\xa2\xe6\x8d\x9f\xe7\x94\xa8 pos.avg_cost\xef\xbc\x88\xe4\xb8\x8d\xe7\xbc\x93\xe5\xad\x98\xe4\xbb\xb7\xe6\xa0\xbc\xef\xbc\x89\r\n  NB-16: \xe4\xbb\x93\xe4\xbd\x8d\xe6\x9d\x83\xe9\x87\x8d\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\r\n  NB-17: RSRS\xe9\x98\x88\xe5\x80\xbc\xe7\xad\x89\xe6\x95\x88\xe8\xaf\xb4\xe6\x98\x8e\xef\xbc\x88\xe8\xa7\x81constants\xef\xbc\x89\r\n  NB-18: \xe9\x99\xa4\xe6\x9d\x83\xe6\x97\xa5\xe5\x90\x8e\xe5\xa4\x8d\xe6\x9d\x83\xe4\xbb\xb7\xe4\xbf\xae\xe6\xad\xa3\r\n  NB-19: \xe8\xa1\x8c\xe4\xb8\x9a\xe9\x99\x90\xe4\xbb\x93\xe8\xb7\xa8\xe7\xad\x96\xe7\x95\xa5\xe5\x90\x88\xe5\xb9\xb6\xe8\xae\xa1\xe7\xae\x97\r\n  NB-20: \xe5\x81\x9c\xe7\x89\x8c\xe8\x82\xa1\xe6\x8a\x98\xe4\xbb\xb7\xe4\xbc\xb0\xe5\x80\xbc\r\n"""\r\nfrom __future__ import annotations\r\nimport logging\r\nimport uuid\r\nfrom collections import deque\r\nfrom datetime import datetime, date, timedelta\r\nfrom typing import Any, Callable, Dict, List, Optional, Tuple\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\nfrom ..types import (\r\n    AccountSnapshot, Fill, Order, OrderSide, OrderStatus, OrderType,\r\n    PositionDirection, PositionState, RiskMetrics, Signal, TradeRecord,\r\n)\r\nfrom ..constants import (\r\n    DEFAULT_COMMISSION_RATE, DEFAULT_SLIPPAGE_RATE, MIN_COMMISSION,\r\n    STAMP_TAX_RATE, TRADING_DAYS_PER_YEAR,\r\n)\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\n# ============================================================================\r\n# Position Manager\r\n# ============================================================================\r\n\r\nclass PositionManager:\r\n    """\xe6\x8c\x81\xe4\xbb\x93\xe7\xae\xa1\xe7\x90\x86\xef\xbc\x9a\xe5\x8c\x85\xe5\x90\xab NB-03 FIFO \xe9\x85\x8d\xe5\xaf\xb9 + NB-08 \xe8\xbf\xbd\xe8\xb8\xaa\xe6\xad\xa2\xe6\x8d\x9f\xe6\xb0\xb4\xe4\xbd\x8d"""\r\n\r\n    def __init__(self) -> None:\r\n        self._positions: Dict[str, PositionState] = {}\r\n        # NB-03: FIFO \xe6\x89\xb9\xe6\xac\xa1\xe9\x98\x9f\xe5\x88\x97  {code: deque[(qty, cost)]}\r\n        self._lots: Dict[str, deque] = {}\r\n        # NB-08: \xe8\xbf\xbd\xe8\xb8\xaa\xe6\xad\xa2\xe6\x8d\x9f\xe6\xb0\xb4\xe4\xbd\x8d {code: float}\r\n        self._trailing_watermarks: Dict[str, float] = {}\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe5\x9f\xba\xe7\xa1\x80\xe8\xae\xbf\xe9\x97\xae \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    def get(self, code: str) -> Optional[PositionState]:\r\n        return self._positions.get(code)\r\n\r\n    def get_all(self) -> Dict[str, PositionState]:\r\n        return dict(self._positions)\r\n\r\n    def has(self, code: str) -> bool:\r\n        return code in self._positions\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe5\xbb\xba\xe4\xbb\x93 / \xe5\x8a\xa0\xe4\xbb\x93 \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    def open_position(\r\n        self, code: str, price: float, volume: int,\r\n        direction: PositionDirection = PositionDirection.LONG,\r\n        entry_date: Optional[datetime] = None,\r\n    ) -> PositionState:\r\n        if code in self._positions:\r\n            pos = self._positions[code]\r\n            pos.add_volume(volume, price)\r\n            self._lots[code].append((volume, price))\r\n            # NB-08: \xe6\xb0\xb4\xe4\xbd\x8d\xe8\xb7\x9f\xe8\xbf\x9b\xe8\x87\xb3\xe6\x9c\x80\xe6\x96\xb0\xe5\x9d\x87\xe6\x88\x90\xe6\x9c\xac\xef\xbc\x88\xe4\xb8\x8d\xe9\x99\x8d\xe4\xbd\x8e\xef\xbc\x89\r\n            if pos.current_price > self._trailing_watermarks.get(code, 0):\r\n                self._trailing_watermarks[code] = pos.current_price\r\n            return pos\r\n\r\n        pos = PositionState(\r\n            code=code,\r\n            direction=direction,\r\n            volume=volume,\r\n            available_volume=volume,\r\n            frozen_volume=0,\r\n            avg_cost=price,\r\n            current_price=price,\r\n            market_value=price * volume,\r\n            profit_loss=0.0,\r\n            profit_loss_pct=0.0,\r\n            entry_date=entry_date or datetime.now(),   # NB-08\r\n        )\r\n        self._positions[code] = pos\r\n        self._lots[code] = deque([(volume, price)])\r\n        self._trailing_watermarks[code] = price        # NB-08: \xe5\x88\x9d\xe5\xa7\x8b=\xe5\xbb\xba\xe4\xbb\x93\xe4\xbb\xb7\r\n        return pos\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe5\xb9\xb3\xe4\xbb\x93 / \xe5\x87\x8f\xe4\xbb\x93 \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    def close_position(\r\n        self, code: str, price: float, volume: int\r\n    ) -> Tuple[float, float]:\r\n        """\r\n        FIFO \xe5\xb9\xb3\xe4\xbb\x93\r\n        Returns:\r\n            realized_pnl, trade_win (1.0 / 0.0 / -1.0)\r\n        """\r\n        pos = self._positions.get(code)\r\n        if not pos:\r\n            return 0.0, 0.0\r\n\r\n        # NB-03: FIFO \xe9\x85\x8d\xe5\xaf\xb9\r\n        lots = self._lots.get(code, deque())\r\n        remaining = volume\r\n        realized = 0.0\r\n        while remaining > 0 and lots:\r\n            lot_qty, lot_cost = lots[0]\r\n            used = min(remaining, lot_qty)\r\n            realized += (price - lot_cost) * used\r\n            remaining -= used\r\n            if used == lot_qty:\r\n                lots.popleft()\r\n            else:\r\n                lots[0] = (lot_qty - used, lot_cost)\r\n\r\n        win = 1.0 if realized > 0 else (0.0 if realized == 0 else -1.0)\r\n\r\n        pos.reduce_volume(volume)\r\n        if pos.volume <= 0:\r\n            del self._positions[code]\r\n            self._trailing_watermarks.pop(code, None)\r\n            self._lots.pop(code, None)\r\n        else:\r\n            pos.update_price(price)\r\n\r\n        return realized, win\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe4\xbb\xb7\xe6\xa0\xbc\xe6\x9b\xb4\xe6\x96\xb0 \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    def update_prices(self, prices: Dict[str, float]) -> None:\r\n        for code, price in prices.items():\r\n            pos = self._positions.get(code)\r\n            if pos and price > 0:\r\n                pos.update_price(price)\r\n                # NB-08: \xe8\xbf\xbd\xe8\xb8\xaa\xe6\xb0\xb4\xe4\xbd\x8d\xe5\x8f\xaa\xe4\xb8\x8a\xe5\x8d\x87\xe4\xb8\x8d\xe4\xb8\x8b\xe9\x99\x8d\r\n                if price > self._trailing_watermarks.get(code, 0):\r\n                    self._trailing_watermarks[code] = price\r\n\r\n    def get_trailing_watermark(self, code: str) -> float:\r\n        return self._trailing_watermarks.get(code, 0.0)\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe5\x86\xbb\xe7\xbb\x93 / \xe8\xa7\xa3\xe5\x86\xbb \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    def freeze(self, code: str, volume: int) -> bool:\r\n        pos = self._positions.get(code)\r\n        if not pos or pos.available_volume < volume:\r\n            return False\r\n        pos.available_volume -= volume\r\n        pos.frozen_volume += volume\r\n        return True\r\n\r\n    def unfreeze(self, code: str, volume: int) -> None:\r\n        pos = self._positions.get(code)\r\n        if pos:\r\n            freed = min(volume, pos.frozen_volume)\r\n            pos.frozen_volume -= freed\r\n            pos.available_volume += freed\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe4\xbc\xb0\xe5\x80\xbc\xef\xbc\x88\xe5\x90\xab\xe5\x81\x9c\xe7\x89\x8c\xe5\xa4\x84\xe7\x90\x86 NB-20\xef\xbc\x89\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    def get_total_market_value(\r\n        self,\r\n        suspended_codes: Optional[set] = None,\r\n        suspension_discount: float = 0.98,\r\n    ) -> float:\r\n        total = 0.0\r\n        for code, pos in self._positions.items():\r\n            mv = pos.market_value\r\n            if suspended_codes and code in suspended_codes:\r\n                mv *= suspension_discount   # NB-20: \xe5\x81\x9c\xe7\x89\x8c\xe6\x8a\x98\xe4\xbb\xb7\r\n            total += mv\r\n        return total\r\n\r\n\r\n# ============================================================================\r\n# Account\r\n# ============================================================================\r\n\r\nclass Account:\r\n    """\xe8\xb4\xa6\xe6\x88\xb7\xef\xbc\x9a\xe8\xb5\x84\xe9\x87\x91\xe7\xae\xa1\xe7\x90\x86 + NB-02 available_cash + NB-05 \xe5\x88\x9d\xe5\xa7\x8b\xe5\xbf\xab\xe7\x85\xa7"""\r\n\r\n    def __init__(self, initial_cash: float = 1_000_000.0) -> None:\r\n        self._cash: float = initial_cash\r\n        self._frozen_cash: float = 0.0\r\n        self._initial_cash: float = initial_cash\r\n        self._snapshots: List[AccountSnapshot] = []\r\n        self._total_trades: int = 0\r\n\r\n        # NB-05: \xe7\xab\x8b\xe5\x8d\xb3\xe8\xae\xb0\xe5\xbd\x95\xe5\x88\x9d\xe5\xa7\x8b\xe5\xbf\xab\xe7\x85\xa7\r\n        self._record_snapshot(datetime.now(), 0, 0.0)\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 NB-02: available_cash \xe4\xbd\x9c\xe4\xb8\xba property \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    @property\r\n    def cash(self) -> float:\r\n        return self._cash\r\n\r\n    @property\r\n    def frozen_cash(self) -> float:\r\n        return self._frozen_cash\r\n\r\n    @property\r\n    def available_cash(self) -> float:\r\n        return max(0.0, self._cash - self._frozen_cash)   # NB-02\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe8\xb5\x84\xe9\x87\x91\xe6\x93\x8d\xe4\xbd\x9c \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    def freeze_cash(self, amount: float) -> bool:\r\n        if self.available_cash < amount:\r\n            return False\r\n        self._frozen_cash += amount\r\n        return True\r\n\r\n    def unfreeze_cash(self, amount: float) -> None:\r\n        self._frozen_cash = max(0.0, self._frozen_cash - amount)\r\n\r\n    def deduct(self, amount: float) -> None:\r\n        self._frozen_cash = max(0.0, self._frozen_cash - amount)\r\n        self._cash -= amount\r\n\r\n    def credit(self, amount: float) -> None:\r\n        self._cash += amount\r\n\r\n    def record_trade(self) -> None:\r\n        self._total_trades += 1\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe5\xbf\xab\xe7\x85\xa7 \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    def _record_snapshot(\r\n        self,\r\n        ts: datetime,\r\n        positions_count: int,\r\n        market_value: float,\r\n    ) -> None:\r\n        total = self._cash + market_value\r\n        self._snapshots.append(AccountSnapshot(\r\n            timestamp=ts,\r\n            total_value=total,\r\n            cash=self._cash,\r\n            market_value=market_value,\r\n            frozen_cash=self._frozen_cash,\r\n            available_cash=self.available_cash,\r\n            positions_count=positions_count,\r\n            total_trades=self._total_trades,\r\n        ))\r\n\r\n    def snapshot(self, ts: datetime, pm: PositionManager) -> AccountSnapshot:\r\n        mv = pm.get_total_market_value()\r\n        self._record_snapshot(ts, len(pm.get_all()), mv)\r\n        return self._snapshots[-1]\r\n\r\n    def get_snapshots(self) -> List[AccountSnapshot]:\r\n        return list(self._snapshots)\r\n\r\n\r\n# ============================================================================\r\n# Performance Calculator\r\n# ============================================================================\r\n\r\nclass PerformanceCalculator:\r\n    """\xe7\xbb\xa9\xe6\x95\x88\xe8\xae\xa1\xe7\xae\x97\xe5\x99\xa8 \xe2\x80\x94 NB-03, NB-04, NB-10, NB-11"""\r\n\r\n    def __init__(self, initial_cash: float) -> None:\r\n        self.initial_cash = initial_cash\r\n        self._wins: List[float] = []   # NB-03: FIFO \xe7\x9b\x88\xe4\xba\x8f\xe8\xae\xb0\xe5\xbd\x95\r\n\r\n    def record_trade_result(self, realized_pnl: float) -> None:\r\n        self._wins.append(realized_pnl)\r\n\r\n    # NB-03: \xe8\x83\x9c\xe7\x8e\x87 = \xe7\x9b\x88\xe5\x88\xa9\xe7\xac\x94\xe6\x95\xb0 / \xe6\x80\xbb\xe7\xac\x94\xe6\x95\xb0\r\n    def trade_win_rate(self) -> float:\r\n        if not self._wins:\r\n            return 0.0\r\n        return sum(1 for w in self._wins if w > 0) / len(self._wins)\r\n\r\n    def calculate(self, snapshots: List[AccountSnapshot]) -> Dict[str, float]:\r\n        if len(snapshots) < 2:\r\n            return {}\r\n        values = np.array([s.total_value for s in snapshots])\r\n        n = len(values)\r\n        total_return = values[-1] / self.initial_cash - 1.0\r\n        # NB-04: \xe5\xb9\xb4\xe5\x8c\x96\xe7\x94\xa8 n_days - 1 \xe4\xbd\x9c\xe5\x88\x86\xe6\xaf\x8d\r\n        n_days = n - 1\r\n        annual_return = (values[-1] / self.initial_cash) ** (TRADING_DAYS_PER_YEAR / max(n_days, 1)) - 1.0\r\n\r\n        daily_returns = np.diff(values) / values[:-1]\r\n        volatility = float(np.std(daily_returns) * np.sqrt(TRADING_DAYS_PER_YEAR))\r\n        rf = 0.03 / TRADING_DAYS_PER_YEAR\r\n        excess = daily_returns - rf\r\n        sharpe = float(annual_return / volatility) if volatility > 1e-9 else 0.0\r\n\r\n        # NB-11: Sortino \xe2\x80\x94 \xe6\x97\xa0\xe8\xb4\x9f\xe5\x81\x8f\xe7\xa6\xbb\xe6\x97\xb6\xe8\xbf\x94\xe5\x9b\x9e inf\r\n        neg_excess = excess[excess < 0]\r\n        if len(neg_excess) == 0:\r\n            sortino = float("inf")\r\n        else:\r\n            down_dev = float(np.std(neg_excess) * np.sqrt(TRADING_DAYS_PER_YEAR))\r\n            sortino = float(annual_return / down_dev) if down_dev > 1e-9 else float("inf")\r\n\r\n        # NB-10: \xe6\x9c\x80\xe5\xa4\xa7\xe5\x9b\x9e\xe6\x92\xa4\xe5\xb3\xb0\xe5\x80\xbc\xe7\xb4\xa2\xe5\xbc\x95\r\n        peak = values[0]\r\n        max_dd = 0.0\r\n        for v in values:\r\n            if v > peak:\r\n                peak = v\r\n            dd = (peak - v) / peak if peak > 1e-9 else 0.0\r\n            if dd > max_dd:\r\n                max_dd = dd\r\n\r\n        return {\r\n            "total_return":    float(total_return),\r\n            "annual_return":   float(annual_return),\r\n            "volatility":      volatility,\r\n            "sharpe_ratio":    sharpe,\r\n            "sortino_ratio":   sortino,\r\n            "max_drawdown":    float(max_dd),\r\n            "trade_win_rate":  self.trade_win_rate(),\r\n            "total_trades":    float(len(self._wins)),\r\n        }\r\n\r\n\r\n# ============================================================================\r\n# Order Manager\r\n# ============================================================================\r\n\r\nclass OrderManager:\r\n    """\xe8\xae\xa2\xe5\x8d\x95\xe7\xae\xa1\xe7\x90\x86\xef\xbc\x9a\xe5\xa7\x94\xe6\x89\x98 \xe2\x86\x92 \xe6\x88\x90\xe4\xba\xa4 \xe2\x86\x92 \xe4\xba\xa4\xe5\x89\xb2"""\r\n\r\n    def __init__(\r\n        self,\r\n        commission_rate: float = DEFAULT_COMMISSION_RATE,\r\n        slippage_rate: float = DEFAULT_SLIPPAGE_RATE,\r\n    ) -> None:\r\n        self.commission_rate = commission_rate\r\n        self.slippage_rate   = slippage_rate\r\n        self._orders: Dict[str, Order] = {}\r\n        self._fills: List[Fill] = []\r\n\r\n    # NB-06: \xe5\x8f\x8c\xe8\xbe\xb9\xe6\x89\x8b\xe7\xbb\xad\xe8\xb4\xb9; NB-07: \xe6\xbb\x91\xe7\x82\xb9\xe6\x96\xb9\xe5\x90\x91\xe6\xad\xa3\xe7\xa1\xae\r\n    def compute_execution_price(self, price: float, side: OrderSide) -> float:\r\n        if side == OrderSide.BUY:\r\n            return price * (1.0 + self.slippage_rate)   # NB-07 \xe4\xb9\xb0\xe5\x85\xa5\xe4\xbb\xb7\xe4\xb8\x8a\xe6\xb5\xae\r\n        else:\r\n            return price * (1.0 - self.slippage_rate)   # NB-07 \xe5\x8d\x96\xe5\x87\xba\xe4\xbb\xb7\xe4\xb8\x8b\xe6\xb5\xae\r\n\r\n    def compute_commission(self, price: float, volume: int) -> float:\r\n        amount = price * volume\r\n        comm = max(MIN_COMMISSION, amount * self.commission_rate)\r\n        return comm  # NB-06 \xe5\x8f\x8c\xe8\xbe\xb9\xe5\x9d\x87\xe6\x94\xb6\r\n\r\n    def compute_tax(self, price: float, volume: int, side: OrderSide) -> float:\r\n        if side == OrderSide.SELL:\r\n            return price * volume * STAMP_TAX_RATE\r\n        return 0.0\r\n\r\n    def create_order(\r\n        self,\r\n        code: str,\r\n        side: OrderSide,\r\n        price: float,\r\n        volume: int,\r\n        ts: datetime,\r\n        reason: str = "",\r\n    ) -> Order:\r\n        oid = str(uuid.uuid4())[:8]\r\n        order = Order(\r\n            order_id=oid,\r\n            timestamp=ts,\r\n            code=code,\r\n            side=side,\r\n            order_type=OrderType.MARKET,\r\n            status=OrderStatus.PENDING,\r\n            price=price,\r\n            volume=volume,\r\n            reason=reason,\r\n        )\r\n        self._orders[oid] = order\r\n        return order\r\n\r\n    def fill_order(\r\n        self, order: Order, fill_price: float, fill_volume: int, ts: datetime\r\n    ) -> Tuple[Fill, float, float, float]:\r\n        exec_price = self.compute_execution_price(fill_price, order.side)\r\n        comm  = self.compute_commission(exec_price, fill_volume)\r\n        tax   = self.compute_tax(exec_price, fill_volume, order.side)\r\n        amount = exec_price * fill_volume\r\n        net   = amount + comm + tax if order.side == OrderSide.BUY else amount - comm - tax\r\n\r\n        order.filled_volume += fill_volume\r\n        order.filled_price = exec_price\r\n        order.commission += comm\r\n        order.status = OrderStatus.FILLED if order.filled_volume >= order.volume else OrderStatus.PARTIAL\r\n\r\n        fill = Fill(\r\n            order_id=order.order_id,\r\n            code=order.code,\r\n            side=order.side,\r\n            price=exec_price,\r\n            volume=fill_volume,\r\n            timestamp=ts,\r\n        )\r\n        self._fills.append(fill)\r\n        return fill, amount, comm, tax\r\n\r\n\r\n# ============================================================================\r\n# BacktestEngine\r\n# ============================================================================\r\n\r\nclass BacktestEngine:\r\n    """\r\n    \xe5\x9b\x9e\xe6\xb5\x8b\xe5\xbc\x95\xe6\x93\x8e\xe4\xb8\xbb\xe4\xbd\x93\r\n    \xe4\xb8\xa5\xe6\xa0\xbc T+1: \xe4\xbf\xa1\xe5\x8f\xb7\xe5\x9c\xa8T\xe6\x97\xa5\xe6\x94\xb6\xe7\x9b\x98\xe5\x90\x8e\xe5\x9f\xba\xe4\xba\x8eT-1\xe6\x95\xb0\xe6\x8d\xae\xe7\x94\x9f\xe6\x88\x90\xef\xbc\x8cT+1\xe6\x97\xa5\xe5\xbc\x80\xe7\x9b\x98\xe6\x89\xa7\xe8\xa1\x8c(NB-01)\r\n    """\r\n\r\n    def __init__(\r\n        self,\r\n        initial_cash: float = 1_000_000.0,\r\n        commission_rate: float = DEFAULT_COMMISSION_RATE,\r\n        slippage_rate: float  = DEFAULT_SLIPPAGE_RATE,\r\n        stop_loss_pct: float  = 0.10,\r\n        take_profit_pct: float = 0.20,\r\n        trailing_stop_pct: float = 0.05,\r\n        max_position_pct: float = 0.10,\r\n        circuit_breaker_max_dd: float = 0.20,\r\n        circuit_breaker_cooldown_days: int = 5,   # NB-12\r\n    ) -> None:\r\n        self.initial_cash = initial_cash\r\n        self.stop_loss_pct = stop_loss_pct\r\n        self.take_profit_pct = take_profit_pct\r\n        self.trailing_stop_pct = trailing_stop_pct\r\n        self.max_position_pct = max_position_pct\r\n        self.circuit_breaker_max_dd = circuit_breaker_max_dd\r\n        self.circuit_breaker_cooldown_days = circuit_breaker_cooldown_days\r\n\r\n        self.account = Account(initial_cash)\r\n        self.pm      = PositionManager()\r\n        self.om      = OrderManager(commission_rate, slippage_rate)\r\n        self.perf    = PerformanceCalculator(initial_cash)\r\n\r\n        # NB-12: \xe7\x86\x94\xe6\x96\xad\xe7\x8a\xb6\xe6\x80\x81\r\n        self._circuit_broken: bool = False\r\n        self._circuit_break_date: Optional[date] = None\r\n\r\n        # NB-01: \xe5\xbe\x85\xe6\x89\xa7\xe8\xa1\x8c\xe4\xbf\xa1\xe5\x8f\xb7\xe9\x98\x9f\xe5\x88\x97\xef\xbc\x88\xe4\xb8\x8b\xe4\xb8\x80\xe4\xb8\xaa bar \xe6\x89\xa7\xe8\xa1\x8c\xef\xbc\x89\r\n        self._pending_signals: List[Signal] = []\r\n\r\n        self._trade_records: List[TradeRecord] = []\r\n        self._current_date: Optional[date] = None\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe7\x86\x94\xe6\x96\xad\xe6\xa3\x80\xe6\xb5\x8b (NB-12) \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    def _check_circuit_breaker(self, current_date: date) -> None:\r\n        snapshots = self.account.get_snapshots()\r\n        if len(snapshots) < 2:\r\n            return\r\n        values = [s.total_value for s in snapshots]\r\n        peak = max(values)\r\n        curr = values[-1]\r\n        dd = (peak - curr) / peak if peak > 1e-9 else 0.0\r\n        if not self._circuit_broken and dd >= self.circuit_breaker_max_dd:\r\n            self._circuit_broken = True\r\n            self._circuit_break_date = current_date\r\n            logger.warning(f"\xe7\x86\x94\xe6\x96\xad\xe8\xa7\xa6\xe5\x8f\x91! \xe6\x9c\x80\xe5\xa4\xa7\xe5\x9b\x9e\xe6\x92\xa4 {dd:.2%} \xe8\xb6\x85\xe9\x99\x90 {current_date}")\r\n        # NB-12: cooldown \xe5\x90\x8e\xe8\x87\xaa\xe5\x8a\xa8\xe8\xa7\xa3\xe9\x99\xa4\r\n        elif self._circuit_broken and self._circuit_break_date:\r\n            elapsed = (current_date - self._circuit_break_date).days\r\n            if elapsed >= self.circuit_breaker_cooldown_days:\r\n                self._circuit_broken = False\r\n                self._circuit_break_date = None\r\n                logger.info(f"\xe7\x86\x94\xe6\x96\xad\xe8\xa7\xa3\xe9\x99\xa4 (\xe5\x86\xb7\xe5\x8d\xb4 {elapsed}\xe5\xa4\xa9) {current_date}")\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe6\xad\xa2\xe6\x8d\x9f / \xe6\xad\xa2\xe7\x9b\x88 (NB-08 NB-15) \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    def _check_stop_conditions(\r\n        self, code: str, current_price: float, current_date: date\r\n    ) -> Optional[str]:\r\n        pos = self.pm.get(code)\r\n        if not pos:\r\n            return None\r\n\r\n        # NB-15: \xe6\xad\xa2\xe6\x8d\x9f\xe4\xbb\xa5 avg_cost \xe4\xb8\xba\xe5\x9f\xba\xe5\x87\x86\xef\xbc\x88\xe4\xb8\x8d\xe7\x94\xa8\xe7\xbc\x93\xe5\xad\x98\xe4\xbb\xb7\xe6\xa0\xbc\xef\xbc\x89\r\n        cost = pos.avg_cost\r\n        if cost <= 1e-9:\r\n            return None\r\n\r\n        pnl_pct = (current_price - cost) / cost\r\n\r\n        # \xe5\x9b\xba\xe5\xae\x9a\xe6\xad\xa2\xe6\x8d\x9f\r\n        if pnl_pct <= -self.stop_loss_pct:\r\n            return f"\xe6\xad\xa2\xe6\x8d\x9f({pnl_pct:.2%})"\r\n\r\n        # \xe5\x9b\xba\xe5\xae\x9a\xe6\xad\xa2\xe7\x9b\x88\r\n        if pnl_pct >= self.take_profit_pct:\r\n            return f"\xe6\xad\xa2\xe7\x9b\x88({pnl_pct:.2%})"\r\n\r\n        # NB-08: \xe8\xbf\xbd\xe8\xb8\xaa\xe6\xad\xa2\xe6\x8d\x9f \xe2\x80\x94 watermark \xe5\x8f\xaa\xe4\xb8\x8a\xe5\x8d\x87\xe4\xb8\x8d\xe4\xb8\x8b\xe9\x99\x8d\r\n        wm = self.pm.get_trailing_watermark(code)\r\n        if wm > cost:\r\n            trail_dd = (wm - current_price) / wm\r\n            if trail_dd >= self.trailing_stop_pct:\r\n                return f"\xe8\xbf\xbd\xe8\xb8\xaa\xe6\xad\xa2\xe6\x8d\x9f(\xe6\xb0\xb4\xe4\xbd\x8d{wm:.2f}\xe2\x86\x92{current_price:.2f})"\r\n\r\n        return None\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe6\xa0\xb8\xe5\xbf\x83: \xe5\x8d\x95\xe4\xb8\xaa bar \xe6\x8e\xa8\xe8\xbf\x9b \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    def step(\r\n        self,\r\n        bar_date: date,\r\n        price_data: Dict[str, Dict[str, float]],   # {code: {open,high,low,close,volume}}\r\n        new_signals: List[Signal],                  # \xe7\xad\x96\xe7\x95\xa5\xe5\x9c\xa8 T-1 \xe6\x94\xb6\xe7\x9b\x98\xe7\x94\x9f\xe6\x88\x90\xe3\x80\x81T \xe6\x97\xa5\xe6\x89\xa7\xe8\xa1\x8c\r\n        suspended_codes: Optional[set] = None,\r\n    ) -> Dict[str, Any]:\r\n        self._current_date = bar_date\r\n        suspended_codes = suspended_codes or set()\r\n\r\n        # 1) \xe6\x9b\xb4\xe6\x96\xb0\xe6\x8c\x81\xe4\xbb\x93\xe6\x94\xb6\xe7\x9b\x98\xe4\xbb\xb7\r\n        close_prices = {c: d["close"] for c, d in price_data.items() if "close" in d}\r\n        self.pm.update_prices(close_prices)\r\n\r\n        # 2) \xe7\x86\x94\xe6\x96\xad\xe6\xa3\x80\xe6\xb5\x8b (NB-12)\r\n        self._check_circuit_breaker(bar_date)\r\n\r\n        # 3) \xe6\x89\xa7\xe8\xa1\x8c\xe4\xb8\x8a\xe4\xb8\x80 bar \xe7\xbc\x93\xe5\xad\x98\xe7\x9a\x84\xe4\xbf\xa1\xe5\x8f\xb7\xef\xbc\x88NB-01\xef\xbc\x9aT+1 \xe6\x89\xa7\xe8\xa1\x8c\xef\xbc\x89\r\n        executions = []\r\n        if not self._circuit_broken:\r\n            for sig in self._pending_signals:\r\n                if sig.code in suspended_codes:\r\n                    continue\r\n                # \xe4\xbd\xbf\xe7\x94\xa8\xe4\xbb\x8a\xe6\x97\xa5 open \xe4\xbb\xb7\xe6\x89\xa7\xe8\xa1\x8c\r\n                bar = price_data.get(sig.code, {})\r\n                exec_price = bar.get("open", bar.get("close", 0.0))\r\n                if exec_price <= 0:\r\n                    continue\r\n                result = self._execute_signal(sig, exec_price, bar_date)\r\n                if result:\r\n                    executions.append(result)\r\n\r\n        # 4) \xe7\xbc\x93\xe5\xad\x98\xe6\x96\xb0\xe4\xbf\xa1\xe5\x8f\xb7\xef\xbc\x8c\xe4\xb8\x8b\xe4\xb8\x80 bar \xe6\x89\xa7\xe8\xa1\x8c\xef\xbc\x88NB-01\xef\xbc\x89\r\n        self._pending_signals = [s for s in new_signals if s.code not in suspended_codes]\r\n\r\n        # 5) \xe6\xad\xa2\xe6\x8d\x9f/\xe6\xad\xa2\xe7\x9b\x88\xe6\xa3\x80\xe6\xb5\x8b\xef\xbc\x88\xe7\x94\xa8\xe6\x94\xb6\xe7\x9b\x98\xe4\xbb\xb7\xef\xbc\x89\r\n        stops = []\r\n        for code, pos in list(self.pm.get_all().items()):\r\n            if code in suspended_codes:\r\n                continue\r\n            close = close_prices.get(code, 0.0)\r\n            if close <= 0:\r\n                continue\r\n            reason = self._check_stop_conditions(code, close, bar_date)\r\n            if reason:\r\n                result = self._execute_sell(code, close, pos.available_volume,\r\n                                             bar_date, reason)\r\n                if result:\r\n                    stops.append(result)\r\n\r\n        # 6) \xe8\xb4\xa6\xe6\x88\xb7\xe5\xbf\xab\xe7\x85\xa7\r\n        snap = self.account.snapshot(datetime.combine(bar_date, datetime.min.time()), self.pm)\r\n\r\n        return {\r\n            "date": bar_date,\r\n            "executions": executions,\r\n            "stops": stops,\r\n            "snapshot": snap,\r\n            "circuit_broken": self._circuit_broken,\r\n        }\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe6\x89\xa7\xe8\xa1\x8c\xe4\xb9\xb0\xe5\x8d\x96 \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    def _execute_signal(self, sig: Signal, price: float, bar_date: date) -> Optional[Dict]:\r\n        if sig.side == OrderSide.BUY:\r\n            # NB-16: \xe4\xbb\x93\xe4\xbd\x8d\xe6\x9d\x83\xe9\x87\x8d\xe5\xb7\xb2\xe5\x9c\xa8\xe7\xad\x96\xe7\x95\xa5\xe5\xb1\x82\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\r\n            weight = min(sig.weight, self.max_position_pct)\r\n            total_val = self.account.cash + self.pm.get_total_market_value()\r\n            budget = total_val * weight\r\n            budget = min(budget, self.account.available_cash)\r\n            if budget < price * 100:\r\n                return None\r\n            volume = int(budget / price / 100) * 100\r\n            if volume <= 0:\r\n                return None\r\n            cost = price * volume\r\n            comm = self.om.compute_commission(price, volume)\r\n            total_cost = cost + comm\r\n            if not self.account.freeze_cash(total_cost):\r\n                return None\r\n            ts = datetime.combine(bar_date, datetime.min.time())\r\n            order = self.om.create_order(sig.code, OrderSide.BUY, price, volume, ts, sig.reason)\r\n            fill, amount, comm2, tax = self.om.fill_order(order, price, volume, ts)\r\n            self.account.deduct(total_cost)\r\n            self.pm.open_position(sig.code, fill.price, volume, entry_date=ts)\r\n            self.account.record_trade()\r\n            return {"type": "BUY", "code": sig.code, "price": fill.price, "volume": volume}\r\n        elif sig.side == OrderSide.SELL:\r\n            pos = self.pm.get(sig.code)\r\n            if not pos or pos.available_volume <= 0:\r\n                return None\r\n            return self._execute_sell(sig.code, price, pos.available_volume, bar_date, sig.reason)\r\n        return None\r\n\r\n    def _execute_sell(self, code: str, price: float, volume: int,\r\n                      bar_date: date, reason: str) -> Optional[Dict]:\r\n        pos = self.pm.get(code)\r\n        if not pos or volume <= 0:\r\n            return None\r\n        ts = datetime.combine(bar_date, datetime.min.time())\r\n        order = self.om.create_order(code, OrderSide.SELL, price, volume, ts, reason)\r\n        fill, amount, comm, tax = self.om.fill_order(order, price, volume, ts)\r\n        net_proceed = amount - comm - tax\r\n        realized, win = self.pm.close_position(code, fill.price, volume)\r\n        self.account.credit(net_proceed)\r\n        self.perf.record_trade_result(realized)\r\n        self.account.record_trade()\r\n        return {"type": "SELL", "code": code, "price": fill.price, "volume": volume,\r\n                "realized_pnl": realized, "reason": reason}\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe7\xbb\x93\xe6\x9e\x9c\xe6\xb1\x87\xe6\x80\xbb \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    def get_performance(self) -> Dict[str, float]:\r\n        return self.perf.calculate(self.account.get_snapshots())\r\n\r\n    def get_equity_curve(self) -> pd.DataFrame:\r\n        snaps = self.account.get_snapshots()\r\n        if not snaps:\r\n            return pd.DataFrame()\r\n        return pd.DataFrame({\r\n            "timestamp":    [s.timestamp for s in snaps],\r\n            "total_value":  [s.total_value for s in snaps],\r\n            "cash":         [s.cash for s in snaps],\r\n            "market_value": [s.market_value for s in snaps],\r\n        }).set_index("timestamp")\r\n'

FILE_src_factors_init_py = b'#!/usr/bin/env python3\r\n"""Q-UNITY-V6 \xe5\x9b\xa0\xe5\xad\x90\xe6\xa8\xa1\xe5\x9d\x97"""\r\nfrom .alpha_engine import AlphaEngine\r\n__all__ = ["AlphaEngine"]\r\n'

FILE_src_factors_alpha_engine_py = b'#!/usr/bin/env python3\r\n"""\r\nQ-UNITY-V6 \xe5\xa4\x9a\xe5\x9b\xa0\xe5\xad\x90 Alpha \xe5\xbc\x95\xe6\x93\x8e\r\n\xe9\x9b\x86\xe6\x88\x90:\r\n  - RSRS: \xe9\x98\xbb\xe5\x8a\x9b\xe6\x94\xaf\xe6\x92\x91\xe4\xbd\x8d\xe7\x9b\xb8\xe5\xaf\xb9\xe5\xbc\xba\xe5\xba\xa6\r\n  - \xe5\x8a\xa8\xe9\x87\x8f\xe5\x9b\xa0\xe5\xad\x90\r\n  - \xe6\xb3\xa2\xe5\x8a\xa8\xe7\x8e\x87\xe5\x9b\xa0\xe5\xad\x90\r\n  - \xe8\xb4\xa8\xe9\x87\x8f\xe5\x9b\xa0\xe5\xad\x90\xef\xbc\x88ROE/\xe5\x87\x80\xe5\x88\xa9\xe6\xb6\xa6TTM\xef\xbc\x89\r\n  - NB-09: get_latest_factor \xe5\xa2\x9e\xe5\x8a\xa0 date_boundary_idx\r\n  - NB-21 @@NB21-CLOSED-LOOP-PATCH-v2@@ \xe6\x96\xb0\xe8\x82\xa1\xe9\x98\xb2\xe5\xbe\xa1\xe8\x92\x99\xe7\x8c\xb4\xe8\xa1\xa5\xe4\xb8\x81\xef\xbc\x88\xe6\x96\x87\xe4\xbb\xb6\xe6\x9c\xab\xef\xbc\x89\r\n"""\r\nfrom __future__ import annotations\r\nimport logging\r\nfrom typing import Any, Dict, List, Optional, Tuple\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\nfrom .technical.rsrs import compute_rsrs\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\nclass AlphaEngine:\r\n    """\xe5\xa4\x9a\xe5\x9b\xa0\xe5\xad\x90 Alpha \xe5\xbc\x95\xe6\x93\x8e"""\r\n\r\n    def __init__(\r\n        self,\r\n        rsrs_window:   int = 18,\r\n        zscore_window: int = 600,\r\n        mom_window:    int = 20,\r\n        vol_window:    int = 20,\r\n    ) -> None:\r\n        self.rsrs_window   = rsrs_window\r\n        self.zscore_window = zscore_window\r\n        self.mom_window    = mom_window\r\n        self.vol_window    = vol_window\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe5\x9b\xa0\xe5\xad\x90\xe8\xae\xa1\xe7\xae\x97 \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    def compute_factors(self, df: pd.DataFrame) -> pd.DataFrame:\r\n        """\r\n        \xe8\xae\xa1\xe7\xae\x97\xe6\x89\x80\xe6\x9c\x89 Alpha \xe5\x9b\xa0\xe5\xad\x90\r\n        \xe8\xbe\x93\xe5\x85\xa5: OHLCV DataFrame\xef\xbc\x8cindex=datetime\r\n        \xe8\xbe\x93\xe5\x87\xba: \xe5\x8e\x9f df + \xe5\x9b\xa0\xe5\xad\x90\xe5\x88\x97\r\n        """\r\n        df = df.copy()\r\n\r\n        # RSRS \xe5\x9b\xa0\xe5\xad\x90\xef\xbc\x88\xe5\x90\xab NB-21 min_valid_rows \xe4\xbf\x9d\xe6\x8a\xa4\xef\xbc\x89\r\n        if "high" in df.columns and "low" in df.columns:\r\n            df = compute_rsrs(df, self.rsrs_window, self.zscore_window,\r\n                              min_valid_rows=self.rsrs_window * 2)\r\n\r\n        # \xe5\x8a\xa8\xe9\x87\x8f\xe5\x9b\xa0\xe5\xad\x90\xef\xbc\x9aN\xe6\x97\xa5\xe7\xb4\xaf\xe8\xae\xa1\xe6\x94\xb6\xe7\x9b\x8a\r\n        if "close" in df.columns:\r\n            close = df["close"]\r\n            df["mom"] = close.pct_change(self.mom_window)\r\n\r\n            # \xe6\xb3\xa2\xe5\x8a\xa8\xe7\x8e\x87\xe5\x9b\xa0\xe5\xad\x90\xef\xbc\x88\xe4\xbd\x8e\xe6\xb3\xa2\xe5\x8a\xa8\xe4\xb8\xba\xe4\xbc\x98\xef\xbc\x89\r\n            df["volatility"] = close.pct_change().rolling(self.vol_window).std()\r\n            df["vol_factor"] = -df["volatility"]   # \xe5\x8f\x96\xe8\xb4\x9f\xef\xbc\x9a\xe4\xbd\x8e\xe6\xb3\xa2\xe5\x8a\xa8=\xe9\xab\x98\xe5\x88\x86\r\n\r\n            # \xe6\x8d\xa2\xe6\x89\x8b\xe7\x8e\x87\xe5\x8a\xa8\xe9\x87\x8f\xef\xbc\x88\xe9\x9c\x80 volume\xef\xbc\x89\r\n            if "volume" in df.columns:\r\n                df["turnover"] = df["volume"] / df["volume"].rolling(self.vol_window).mean()\r\n\r\n        return df\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 NB-09: \xe8\x8e\xb7\xe5\x8f\x96\xe6\x88\xaa\xe6\xad\xa2\xe6\x9f\x90\xe6\x97\xa5\xe7\x9a\x84\xe6\x9c\x80\xe6\x96\xb0\xe5\x9b\xa0\xe5\xad\x90\xe5\x80\xbc \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    def get_latest_factor(\r\n        self,\r\n        df: pd.DataFrame,\r\n        factor: str,\r\n        date_boundary: Optional[pd.Timestamp] = None,\r\n        date_boundary_idx: Optional[int] = None,   # NB-09: \xe5\x8f\xaf\xe6\x8c\x87\xe5\xae\x9a\xe6\x95\xb4\xe6\x95\xb0\xe7\xb4\xa2\xe5\xbc\x95\r\n    ) -> Optional[float]:\r\n        """\r\n        \xe8\x8e\xb7\xe5\x8f\x96 df[factor] \xe5\x9c\xa8 date_boundary \xe4\xb9\x8b\xe5\x89\x8d\xe7\x9a\x84\xe6\x9c\x80\xe6\x96\xb0\xe9\x9d\x9e NaN \xe5\x80\xbc\r\n        NB-09: \xe6\x94\xaf\xe6\x8c\x81 date_boundary_idx\xef\xbc\x88\xe6\x95\xb4\xe6\x95\xb0\xe8\xa1\x8c\xe7\xb4\xa2\xe5\xbc\x95\xe4\xb8\x8a\xe7\x95\x8c\xef\xbc\x89\xef\xbc\x8c\xe9\x98\xb2\xe5\x89\x8d\xe8\xa7\x86\r\n        """\r\n        if factor not in df.columns:\r\n            return None\r\n\r\n        series = df[factor].dropna()\r\n        if series.empty:\r\n            return None\r\n\r\n        # \xe6\x95\xb4\xe6\x95\xb0\xe7\xb4\xa2\xe5\xbc\x95\xe6\x88\xaa\xe6\x96\xad\xef\xbc\x88\xe4\xbc\x98\xe5\x85\x88\xef\xbc\x89\r\n        if date_boundary_idx is not None:\r\n            series = series.iloc[:date_boundary_idx]\r\n        elif date_boundary is not None:\r\n            series = series.loc[series.index <= date_boundary]\r\n\r\n        if series.empty:\r\n            return None\r\n        return float(series.iloc[-1])\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe6\x89\xb9\xe9\x87\x8f\xe8\xaf\x84\xe5\x88\x86 \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    def score_universe(\r\n        self,\r\n        factor_data: Dict[str, pd.DataFrame],\r\n        eval_date: pd.Timestamp,\r\n        weights: Optional[Dict[str, float]] = None,\r\n    ) -> pd.Series:\r\n        """\r\n        \xe5\xaf\xb9\xe8\x82\xa1\xe7\xa5\xa8\xe6\xb1\xa0\xe6\x89\x93\xe5\x88\x86\xef\xbc\x88\xe6\x88\xaa\xe9\x9d\xa2 Z-score + \xe5\x8a\xa0\xe6\x9d\x83\xe5\x90\x88\xe6\x88\x90\xef\xbc\x89\r\n        factor_data: {code: factor_df}\r\n        weights: {factor_name: weight}  \xe9\xbb\x98\xe8\xae\xa4\xe7\xad\x89\xe6\x9d\x83\r\n        """\r\n        if weights is None:\r\n            weights = {"rsrs_adaptive": 0.4, "mom": 0.3, "vol_factor": 0.3}\r\n\r\n        rows = {}\r\n        for code, df in factor_data.items():\r\n            row = {}\r\n            for fn in weights:\r\n                v = self.get_latest_factor(df, fn, eval_date)\r\n                row[fn] = v if v is not None else np.nan\r\n            rows[code] = row\r\n\r\n        scores_df = pd.DataFrame(rows).T\r\n        # \xe6\x88\xaa\xe9\x9d\xa2 Z-score\r\n        for col in scores_df.columns:\r\n            s = scores_df[col]\r\n            std = s.std()\r\n            if std > 1e-9:\r\n                scores_df[col] = (s - s.mean()) / std\r\n            else:\r\n                scores_df[col] = 0.0\r\n\r\n        # \xe5\x8a\xa0\xe6\x9d\x83\xe5\x90\x88\xe6\x88\x90\r\n        total_w = sum(weights.values())\r\n        composite = sum(\r\n            scores_df.get(fn, pd.Series(0, index=scores_df.index)) * w\r\n            for fn, w in weights.items()\r\n        ) / (total_w if total_w > 0 else 1.0)\r\n\r\n        return composite.sort_values(ascending=False)\r\n\r\n    # \xe2\x94\x80\xe2\x94\x80 \xe6\x89\xb9\xe9\x87\x8f\xe8\xae\xa1\xe7\xae\x97\xef\xbc\x88\xe7\xb1\xbb\xe6\x96\xb9\xe6\xb3\x95\xe6\x8e\xa5\xe5\x8f\xa3\xef\xbc\x8c\xe4\xbe\x9b\xe7\xad\x96\xe7\x95\xa5\xe8\xb0\x83\xe7\x94\xa8\xef\xbc\x89\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\n    @classmethod\r\n    def compute_from_history(\r\n        cls,\r\n        history: pd.DataFrame,\r\n        rsrs_window: int = 18,\r\n        zscore_window: int = 600,\r\n    ) -> pd.DataFrame:\r\n        """\r\n        \xe4\xbb\x8e\xe5\x8e\x86\xe5\x8f\xb2\xe8\xa1\x8c\xe6\x83\x85\xe8\xae\xa1\xe7\xae\x97 RSRS \xe5\x9b\xa0\xe5\xad\x90 DataFrame\r\n        \xe6\xad\xa4\xe6\x96\xb9\xe6\xb3\x95\xe4\xbc\x9a\xe8\xa2\xab NB-21 Monkey-Patch \xe6\x9b\xbf\xe6\x8d\xa2\xef\xbc\x88\xe8\xa7\x81\xe6\x96\x87\xe4\xbb\xb6\xe6\x9c\xab\xef\xbc\x89\r\n        """\r\n        engine = cls(rsrs_window=rsrs_window, zscore_window=zscore_window)\r\n        return engine.compute_factors(history)\r\n\r\n\r\n# ============================================================================\r\n# @@NB21-CLOSED-LOOP-PATCH-v2@@\r\n# NB-21 \xe6\x96\xb0\xe8\x82\xa1\xe9\x98\xb2\xe5\xbe\xa1\xe9\x97\xad\xe7\x8e\xaf\xe4\xbf\xae\xe8\xa1\xa5\r\n# \xe7\xad\x96\xe7\x95\xa5: valid_count >= rsrs_window * 2 \xe6\x89\x8d\xe5\x85\x81\xe8\xae\xb8\xe8\xae\xa1\xe7\xae\x97\r\n#       \xe5\x90\xa6\xe5\x88\x99\xe5\x85\xa8\xe9\x83\xa8\xe5\x9b\xa0\xe5\xad\x90\xe5\x88\x97\xe5\xbc\xba\xe5\x88\xb6\xe7\xbd\xae NaN\xef\xbc\x8c\xe9\x98\xb2\xe6\xad\xa2 RSRS \xe5\x9c\xa8\xe4\xb8\x8a\xe5\xb8\x82\xe9\xa6\x96\xe5\x87\xa0\xe5\xa4\xa9\xe4\xba\xa7\xe7\x94\x9f\xe5\x99\xaa\xe5\xa3\xb0\xe4\xbf\xa1\xe5\x8f\xb7\r\n# ============================================================================\r\n\r\ndef _nb21_valid_mask(history: pd.DataFrame, rsrs_window: int) -> np.ndarray:\r\n    """\r\n    \xe7\x94\x9f\xe6\x88\x90\xe6\xaf\x8f\xe8\xa1\x8c\xe7\x9a\x84\xe6\x9c\x89\xe6\x95\x88\xe5\xb8\x83\xe5\xb0\x94\xe6\x8e\xa9\xe7\xa0\x81:\r\n    \xe4\xbb\x85\xe5\xbd\x93\xe5\x88\xb0\xe5\xbd\x93\xe5\x89\x8d\xe8\xa1\x8c\xe4\xb8\xba\xe6\xad\xa2\xe5\xb7\xb2\xe6\x9c\x89 >= rsrs_window*2 \xe8\xa1\x8c\xe9\x9d\x9e NaN \xe6\x94\xb6\xe7\x9b\x98\xe4\xbb\xb7\xe6\x97\xb6\xe6\x89\x8d\xe6\x9c\x89\xe6\x95\x88\r\n    """\r\n    if "close" not in history.columns:\r\n        return np.zeros(len(history), dtype=bool)\r\n    close_valid = history["close"].notna().values.astype(int)\r\n    cumcount = np.cumsum(close_valid)\r\n    return cumcount >= (rsrs_window * 2)\r\n\r\n\r\ndef _apply_nb21_mask_to_rsrs(df: pd.DataFrame, mask: np.ndarray) -> pd.DataFrame:\r\n    """\xe5\xb0\x86\xe6\x89\x80\xe6\x9c\x89 rsrs_* \xe5\x88\x97\xe5\x9c\xa8 mask=False \xe5\xa4\x84\xe5\xbc\xba\xe5\x88\xb6\xe7\xbd\xae NaN"""\r\n    rsrs_cols = [c for c in df.columns if c.startswith("rsrs_") or c == "resid_std"]\r\n    for col in rsrs_cols:\r\n        df.loc[~mask, col] = np.nan\r\n    return df\r\n\r\n\r\ndef _patched_compute_from_history(\r\n    history: pd.DataFrame,\r\n    rsrs_window: int = 18,\r\n    zscore_window: int = 600,\r\n) -> pd.DataFrame:\r\n    """NB-21 \xe9\x97\xad\xe7\x8e\xaf\xe7\x89\x88: \xe5\x85\x88\xe6\xad\xa3\xe5\xb8\xb8\xe8\xae\xa1\xe7\xae\x97\xef\xbc\x8c\xe5\x86\x8d\xe7\x94\xa8\xe6\x9c\x89\xe6\x95\x88\xe6\x8e\xa9\xe7\xa0\x81\xe6\xb8\x85\xe6\xb4\x97\xe6\x96\xb0\xe8\x82\xa1\xe5\x99\xaa\xe5\xa3\xb0"""\r\n    engine = AlphaEngine(rsrs_window=rsrs_window, zscore_window=zscore_window)\r\n    df = engine.compute_factors(history)\r\n    mask = _nb21_valid_mask(history, rsrs_window)\r\n    df = _apply_nb21_mask_to_rsrs(df, mask)\r\n    return df\r\n\r\n\r\n# \xe6\x89\xa7\xe8\xa1\x8c Monkey-Patch\r\nAlphaEngine.compute_from_history = staticmethod(_patched_compute_from_history)\r\nlogger.debug("AlphaEngine.compute_from_history \xe5\xb7\xb2\xe5\xba\x94\xe7\x94\xa8 NB-21 \xe9\x97\xad\xe7\x8e\xaf\xe8\xa1\xa5\xe4\xb8\x81 v2")\r\n'

FILE_src_factors_technical_init_py = b'#!/usr/bin/env python3\r\n"""\xe6\x8a\x80\xe6\x9c\xaf\xe5\x9b\xa0\xe5\xad\x90\xe5\xad\x90\xe6\xa8\xa1\xe5\x9d\x97"""\r\n'

FILE_src_factors_technical_rsrs_py = b'#!/usr/bin/env python3\r\n"""\r\nQ-UNITY-V6 RSRS \xe5\x9b\xa0\xe5\xad\x90\xe8\xae\xa1\xe7\xae\x97\r\n  - \xe5\x90\x91\xe9\x87\x8f\xe5\x8c\x96 OLS\xef\xbc\x88numpy lstsq\xef\xbc\x8c\xe9\x80\x9f\xe5\xba\xa6\xe5\xbf\xab10x\xef\xbc\x89\r\n  - NB-17: high/low \xe7\xaa\x97\xe5\x8f\xa3\xe5\x9d\x87\xe5\x80\xbc\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\r\n  - NB-21: \xe6\x96\xb0\xe8\x82\xa1\xe4\xbf\x9d\xe6\x8a\xa4\xef\xbc\x88\xe6\x9c\x89\xe6\x95\x88\xe8\xa1\x8c\xe6\x95\xb0 >= rsrs_window * 2 \xe6\x89\x8d\xe8\xae\xa1\xe7\xae\x97\xef\xbc\x89\r\n  - \xe8\xbf\x94\xe5\x9b\x9e rsrs_raw / rsrs_zscore / rsrs_r2 / rsrs_adaptive\r\n"""\r\nfrom __future__ import annotations\r\nimport logging\r\nfrom typing import Optional\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\ndef _rolling_ols(high: np.ndarray, low: np.ndarray, window: int) -> tuple:\r\n    """\r\n    \xe5\x90\x91\xe9\x87\x8f\xe5\x8c\x96\xe6\xbb\x9a\xe5\x8a\xa8 OLS: high = beta * low + alpha\r\n    \xe8\xbf\x94\xe5\x9b\x9e (betas, r2s, resid_stds) \xe2\x80\x94 \xe5\x9d\x87\xe4\xb8\xba len(high) \xe5\xa4\xa7\xe5\xb0\x8f\xef\xbc\x8c\xe5\x89\x8d window-1 \xe8\xa1\x8c\xe4\xb8\xba NaN\r\n    """\r\n    n = len(high)\r\n    betas     = np.full(n, np.nan)\r\n    r2s       = np.full(n, np.nan)\r\n    resid_std = np.full(n, np.nan)\r\n\r\n    for i in range(window - 1, n):\r\n        x = low[i - window + 1: i + 1]\r\n        y = high[i - window + 1: i + 1]\r\n        valid = np.isfinite(x) & np.isfinite(y)\r\n        if valid.sum() < window // 2:\r\n            continue\r\n        xv, yv = x[valid], y[valid]\r\n        X = np.column_stack([np.ones(len(xv)), xv])\r\n        try:\r\n            coef, *_ = np.linalg.lstsq(X, yv, rcond=None)\r\n        except Exception:\r\n            continue\r\n        alpha, beta = coef\r\n        y_hat = alpha + beta * xv\r\n        ss_res = np.sum((yv - y_hat) ** 2)\r\n        ss_tot = np.sum((yv - yv.mean()) ** 2)\r\n        r2 = 1.0 - ss_res / ss_tot if ss_tot > 1e-12 else 0.0\r\n        betas[i]     = beta\r\n        r2s[i]       = max(0.0, r2)\r\n        resid_std[i] = np.std(yv - y_hat)\r\n\r\n    return betas, r2s, resid_std\r\n\r\n\r\ndef compute_rsrs(\r\n    df: pd.DataFrame,\r\n    regression_window: int = 18,\r\n    zscore_window:     int = 600,\r\n    min_valid_rows:    Optional[int] = None,   # NB-21: \xe8\x8b\xa5\xe6\x8c\x87\xe5\xae\x9a\xe5\x88\x99\xe8\xbf\x87\xe6\xbb\xa4\xe6\x96\xb0\xe8\x82\xa1\r\n) -> pd.DataFrame:\r\n    """\r\n    \xe8\xae\xa1\xe7\xae\x97 RSRS \xe5\x9b\xa0\xe5\xad\x90\xe5\x85\xa8\xe7\xb3\xbb\xe5\x88\x97\r\n    \xe8\xbe\x93\xe5\x85\xa5 df \xe5\xbf\x85\xe9\xa1\xbb\xe5\x8c\x85\xe5\x90\xab\xe5\x88\x97: high, low (\xe5\xb7\xb2\xe5\x89\x8d\xe5\xa4\x8d\xe6\x9d\x83)\r\n    \xe8\xbe\x93\xe5\x87\xba\xe6\x96\xb0\xe5\x88\x97: rsrs_raw, rsrs_zscore, rsrs_r2, rsrs_adaptive, resid_std\r\n    """\r\n    if "high" not in df.columns or "low" not in df.columns:\r\n        raise ValueError("df \xe5\xbf\x85\xe9\xa1\xbb\xe5\x8c\x85\xe5\x90\xab high, low \xe5\x88\x97")\r\n\r\n    df = df.copy()\r\n\r\n    # NB-17: \xe7\xaa\x97\xe5\x8f\xa3\xe5\x9d\x87\xe5\x80\xbc\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\r\n    low_mean  = df["low"].rolling(regression_window, min_periods=1).mean()\r\n    high_mean = df["high"].rolling(regression_window, min_periods=1).mean()\r\n    low_norm  = (df["low"]  / low_mean.replace(0, np.nan)).fillna(1.0)\r\n    high_norm = (df["high"] / high_mean.replace(0, np.nan)).fillna(1.0)\r\n\r\n    high_arr = high_norm.values\r\n    low_arr  = low_norm.values\r\n\r\n    # NB-21: \xe6\x9c\x89\xe6\x95\x88\xe8\xa1\x8c\xe6\x95\xb0\xe4\xbf\x9d\xe6\x8a\xa4\r\n    if min_valid_rows is None:\r\n        min_valid_rows = regression_window * 2\r\n    n_valid = int(np.isfinite(high_arr).sum())\r\n    if n_valid < min_valid_rows:\r\n        logger.debug(f"\xe6\x9c\x89\xe6\x95\x88\xe8\xa1\x8c\xe6\x95\xb0 {n_valid} < {min_valid_rows}\xef\xbc\x8c\xe8\xb7\xb3\xe8\xbf\x87RSRS\xe8\xae\xa1\xe7\xae\x97")\r\n        for col in ["rsrs_raw", "rsrs_zscore", "rsrs_r2", "rsrs_adaptive", "resid_std"]:\r\n            df[col] = np.nan\r\n        return df\r\n\r\n    betas, r2s, rstd = _rolling_ols(high_arr, low_arr, regression_window)\r\n\r\n    df["rsrs_raw"]  = betas\r\n    df["rsrs_r2"]   = r2s\r\n    df["resid_std"] = rstd\r\n\r\n    # Z-score \xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96\r\n    roll_mean = pd.Series(betas).rolling(zscore_window, min_periods=30).mean()\r\n    roll_std  = pd.Series(betas).rolling(zscore_window, min_periods=30).std()\r\n    zscore    = (betas - roll_mean.values) / (roll_std.values + 1e-9)\r\n    df["rsrs_zscore"] = zscore\r\n\r\n    # \xe4\xbf\xae\xe6\xad\xa3RSRS = zscore * R\xc2\xb2\r\n    df["rsrs_adaptive"] = zscore * r2s\r\n\r\n    return df\r\n'

FILE_src_factors_technical_alpha_py = b'#!/usr/bin/env python3\r\n"""\xe6\x8a\x80\xe6\x9c\xaf\xe9\x9d\xa2 Alpha \xe5\x9b\xa0\xe5\xad\x90\xe5\xba\x93\xef\xbc\x88\xe9\x87\x8f\xe4\xbb\xb7\xe7\xb1\xbb\xef\xbc\x89"""\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\n\r\ndef momentum_factor(close: pd.Series, window: int = 20) -> pd.Series:\r\n    return close.pct_change(window)\r\n\r\n\r\ndef volatility_factor(close: pd.Series, window: int = 20) -> pd.Series:\r\n    return -close.pct_change().rolling(window).std()\r\n\r\n\r\ndef volume_momentum(volume: pd.Series, window: int = 20) -> pd.Series:\r\n    return volume / volume.rolling(window).mean()\r\n\r\n\r\ndef price_volume_corr(close: pd.Series, volume: pd.Series, window: int = 20) -> pd.Series:\r\n    return close.rolling(window).corr(volume)\r\n'

FILE_src_risk_init_py = b'#!/usr/bin/env python3\r\n"""Q-UNITY-V6 \xe9\xa3\x8e\xe6\x8e\xa7\xe6\xa8\xa1\xe5\x9d\x97"""\r\nfrom .risk_control import RiskController\r\n__all__ = ["RiskController"]\r\n'

FILE_src_risk_risk_control_py = b'#!/usr/bin/env python3\r\n"""\r\nQ-UNITY-V6 \xe4\xb8\x89\xe5\xb1\x82\xe9\xa3\x8e\xe6\x8e\xa7\xe4\xbd\x93\xe7\xb3\xbb\r\n  L1: \xe4\xbb\x93\xe4\xbd\x8d\xe9\xa3\x8e\xe6\x8e\xa7\xef\xbc\x88\xe5\x8d\x95\xe8\x82\xa1+\xe8\xa1\x8c\xe4\xb8\x9a\xef\xbc\x8cNB-16\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xef\xbc\x89\r\n  L2: \xe6\xad\xa2\xe6\x8d\x9f\xe6\xad\xa2\xe7\x9b\x88\xef\xbc\x88\xe7\x94\xb1\xe6\x89\xa7\xe8\xa1\x8c\xe5\xbc\x95\xe6\x93\x8e\xe5\xa4\x84\xe7\x90\x86\xef\xbc\x8c\xe8\xa7\x81execution.py\xef\xbc\x89\r\n  L3: \xe7\xbb\x84\xe5\x90\x88\xe9\xa3\x8e\xe6\x8e\xa7\xef\xbc\x88\xe6\x9c\x80\xe5\xa4\xa7\xe5\x9b\x9e\xe6\x92\xa4\xe7\x86\x94\xe6\x96\xad\xef\xbc\x8cNB-12 cooldown\xef\xbc\x89\r\n"""\r\nfrom __future__ import annotations\r\nimport logging\r\nfrom typing import Dict, List, Optional, Set\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\nclass RiskController:\r\n    """\xe4\xb8\x89\xe5\xb1\x82\xe9\xa3\x8e\xe6\x8e\xa7\xe6\x8e\xa7\xe5\x88\xb6\xe5\x99\xa8"""\r\n\r\n    def __init__(\r\n        self,\r\n        max_position_pct: float = 0.10,\r\n        max_industry_pct: float = 0.30,   # NB-19 \xe8\xa1\x8c\xe4\xb8\x9a\xe9\x99\x90\xe4\xbb\x93\r\n        max_drawdown:     float = 0.20,\r\n        cooldown_days:    int   = 5,       # NB-12\r\n    ) -> None:\r\n        self.max_position_pct = max_position_pct\r\n        self.max_industry_pct = max_industry_pct\r\n        self.max_drawdown     = max_drawdown\r\n        self.cooldown_days    = cooldown_days\r\n\r\n    def filter_signals_by_position(\r\n        self,\r\n        signals: list,\r\n        current_positions: Dict[str, object],\r\n        total_value: float,\r\n        available_cash: float,\r\n    ) -> list:\r\n        """L1: \xe8\xbf\x87\xe6\xbb\xa4\xe8\xb6\x85\xe4\xbb\x93\xe4\xbf\xa1\xe5\x8f\xb7 (NB-16: \xe6\x9d\x83\xe9\x87\x8d\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe5\x90\x8e\xe5\x86\x8d\xe8\xbf\x87\xe6\xbb\xa4)"""\r\n        if not signals:\r\n            return []\r\n\r\n        buy_signals = [s for s in signals if hasattr(s, "side") and s.side.value == "BUY"]\r\n        sell_signals = [s for s in signals if hasattr(s, "side") and s.side.value == "SELL"]\r\n\r\n        # NB-16: \xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe4\xb9\xb0\xe5\x85\xa5\xe6\x9d\x83\xe9\x87\x8d\r\n        total_w = sum(s.weight for s in buy_signals) if buy_signals else 0\r\n        if total_w > 1.0:\r\n            for s in buy_signals:\r\n                s.weight /= total_w\r\n\r\n        # \xe8\xbf\x87\xe6\xbb\xa4\xe8\xb6\x85\xe8\xbf\x87\xe5\x8d\x95\xe8\x82\xa1\xe4\xb8\x8a\xe9\x99\x90\r\n        filtered_buy = [\r\n            s for s in buy_signals\r\n            if s.weight <= self.max_position_pct\r\n        ]\r\n        return filtered_buy + sell_signals\r\n\r\n    def filter_signals_by_industry(\r\n        self,\r\n        signals: list,\r\n        current_positions: Dict[str, object],\r\n        industry_map: Optional[Dict[str, str]],\r\n        total_value: float,\r\n    ) -> list:\r\n        """NB-19: \xe8\xa1\x8c\xe4\xb8\x9a\xe6\x9a\xb4\xe9\x9c\xb2\xe8\xb7\xa8\xe7\xad\x96\xe7\x95\xa5\xe5\x90\x88\xe5\xb9\xb6\xe6\xa3\x80\xe6\xb5\x8b"""\r\n        if not industry_map or not signals:\r\n            return signals\r\n\r\n        # \xe5\xbd\x93\xe5\x89\x8d\xe8\xa1\x8c\xe4\xb8\x9a\xe6\x8c\x81\xe4\xbb\x93\xe6\xaf\x94\xe4\xbe\x8b\r\n        industry_exposure: Dict[str, float] = {}\r\n        for code, pos in current_positions.items():\r\n            ind = industry_map.get(code, "\xe6\x9c\xaa\xe7\x9f\xa5")\r\n            mv  = getattr(pos, "market_value", 0.0)\r\n            industry_exposure[ind] = industry_exposure.get(ind, 0.0) + mv / max(total_value, 1)\r\n\r\n        out = []\r\n        for sig in signals:\r\n            if not (hasattr(sig, "side") and sig.side.value == "BUY"):\r\n                out.append(sig)\r\n                continue\r\n            ind = industry_map.get(sig.code, "\xe6\x9c\xaa\xe7\x9f\xa5")\r\n            proj = industry_exposure.get(ind, 0.0) + sig.weight\r\n            if proj <= self.max_industry_pct:\r\n                out.append(sig)\r\n                industry_exposure[ind] = proj\r\n            else:\r\n                logger.debug(f"\xe8\xa1\x8c\xe4\xb8\x9a\xe9\x99\x90\xe4\xbb\x93\xe8\xbf\x87\xe6\xbb\xa4 {sig.code} ({ind}): {proj:.1%} > {self.max_industry_pct:.1%}")\r\n        return out\r\n\r\n    def check_portfolio_risk(\r\n        self,\r\n        equity_curve: "np.ndarray",\r\n    ) -> Dict[str, float]:\r\n        """L3: \xe7\xbb\x84\xe5\x90\x88\xe9\xa3\x8e\xe9\x99\xa9\xe6\xa3\x80\xe6\xb5\x8b"""\r\n        if len(equity_curve) < 2:\r\n            return {"current_drawdown": 0.0, "max_drawdown": 0.0}\r\n        peak = np.maximum.accumulate(equity_curve)\r\n        dd_series = (peak - equity_curve) / np.where(peak > 0, peak, 1)\r\n        return {\r\n            "current_drawdown": float(dd_series[-1]),\r\n            "max_drawdown":     float(dd_series.max()),\r\n        }\r\n'

FILE_src_strategy_init_py = b'#!/usr/bin/env python3\r\n"""Q-UNITY-V6 \xe7\xad\x96\xe7\x95\xa5\xe6\xa8\xa1\xe5\x9d\x97"""\r\nfrom .strategies import (\r\n    BaseStrategy, RSRSMomentumStrategy, AlphaHunterStrategy,\r\n    RSRSAdvancedStrategy, ShortTermStrategy, MomentumReversalStrategy,\r\n    SentimentReversalStrategy, KunpengV10Strategy, AlphaMaxV5FixedStrategy,\r\n    STRATEGY_REGISTRY, create_strategy,\r\n)\r\n__all__ = [\r\n    "BaseStrategy", "RSRSMomentumStrategy", "AlphaHunterStrategy",\r\n    "RSRSAdvancedStrategy", "ShortTermStrategy", "MomentumReversalStrategy",\r\n    "SentimentReversalStrategy", "KunpengV10Strategy", "AlphaMaxV5FixedStrategy",\r\n    "STRATEGY_REGISTRY", "create_strategy",\r\n]\r\n'

FILE_src_strategy_strategies_py = b'#!/usr/bin/env python3\r\n"""\r\nQ-UNITY-V6 \xe7\xad\x96\xe7\x95\xa5\xe5\x85\xa8\xe9\x9b\x86\xef\xbc\x888\xe5\xa4\xa7\xe7\xad\x96\xe7\x95\xa5\xef\xbc\x89\r\n  1. RSRSMomentumStrategy     \xe2\x80\x94 \xe5\x9f\xba\xe7\xa1\x80RSRS\xe5\x8a\xa8\xe9\x87\x8f\r\n  2. AlphaHunterStrategy      \xe2\x80\x94 \xe9\xab\x98\xe9\xa2\x91\xe5\xa4\x9a\xe5\xb1\x82\xe9\x94\x81\r\n  3. RSRSAdvancedStrategy     \xe2\x80\x94 R\xc2\xb2\xe8\xbf\x87\xe6\xbb\xa4+\xe9\x87\x8f\xe4\xbb\xb7\xe5\x85\xb1\xe6\x8c\xaf\r\n  4. ShortTermStrategy        \xe2\x80\x94 \xe5\xbf\xab\xe8\xbf\x9b\xe5\xbf\xab\xe5\x87\xba+\xe6\x97\xa5\xe5\x8e\x86\xe6\xad\xa2\xe6\x97\xb6 (NB-14)\r\n  5. MomentumReversalStrategy \xe2\x80\x94 \xe5\x8f\x8c\xe6\xa8\xa1\xe5\xbc\x8f 60/40\r\n  6. SentimentReversalStrategy\xe2\x80\x94 \xe8\xb6\x85\xe5\x8d\x96\xe5\x8f\x8d\xe8\xbd\xac\r\n  7. KunpengV10Strategy       \xe2\x80\x94 \xe5\xbe\xae\xe7\xbb\x93\xe6\x9e\x84(\xe8\x81\xaa\xe6\x98\x8e\xe9\x92\xb1+\xe7\xa8\xb3\xe5\xae\x9a\xe9\x9d\x9e\xe6\xb5\x81\xe5\x8a\xa8\xe6\x80\xa7+\xe7\xbc\xba\xe5\x8f\xa3\xe6\x83\xa9\xe7\xbd\x9a)+\xe5\xae\xbd\xe5\xba\xa6\xe7\x86\x94\xe6\x96\xad\r\n  8. AlphaMaxV5FixedStrategy  \xe2\x80\x94 \xe6\x9c\xba\xe6\x9e\x84\xe5\xa4\x9a\xe5\x9b\xa0\xe5\xad\x90(EP/\xe6\x88\x90\xe9\x95\xbf/\xe5\x8a\xa8\xe9\x87\x8f/\xe8\xb4\xa8\xe9\x87\x8f/REV/\xe6\xb5\x81\xe5\x8a\xa8/\xe6\xae\x8b\xe5\xb7\xae\xe6\xb3\xa2\xe5\x8a\xa8)+\xe8\xa1\x8c\xe4\xb8\x9a\xe4\xb8\xad\xe6\x80\xa7+\xe9\xa3\x8e\xe9\x99\xa9\xe5\xb9\xb3\xe4\xbb\xb7\r\n"""\r\nfrom __future__ import annotations\r\nimport logging\r\nfrom abc import ABC, abstractmethod\r\nfrom datetime import datetime, timedelta\r\nfrom typing import Any, Dict, List, Optional\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\nfrom ..types import OrderSide, Signal\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\n# ============================================================================\r\n# \xe5\x9f\xba\xe7\xb1\xbb\r\n# ============================================================================\r\n\r\nclass BaseStrategy(ABC):\r\n    """\xe7\xad\x96\xe7\x95\xa5\xe5\x9f\xba\xe7\xb1\xbb"""\r\n\r\n    name: str = "BaseStrategy"\r\n\r\n    def __init__(self, config: Optional[Dict] = None) -> None:\r\n        self.config = config or {}\r\n        self._state: Dict[str, Any] = {}\r\n\r\n    @abstractmethod\r\n    def generate_signals(\r\n        self,\r\n        universe: List[str],\r\n        market_data: Dict[str, pd.DataFrame],\r\n        factor_data: Dict[str, pd.DataFrame],\r\n        current_date: datetime,\r\n        positions: Dict[str, Any],\r\n    ) -> List[Signal]:\r\n        ...\r\n\r\n    def _make_buy(self, code: str, score: float, weight: float,\r\n                  ts: datetime, reason: str = "") -> Signal:\r\n        return Signal(timestamp=ts, code=code, side=OrderSide.BUY,\r\n                      score=score, weight=weight, reason=reason,\r\n                      strategy_name=self.name)\r\n\r\n    def _make_sell(self, code: str, ts: datetime, reason: str = "") -> Signal:\r\n        return Signal(timestamp=ts, code=code, side=OrderSide.SELL,\r\n                      score=0.0, weight=0.0, reason=reason,\r\n                      strategy_name=self.name)\r\n\r\n\r\n# ============================================================================\r\n# 1. RSRSMomentumStrategy\r\n# ============================================================================\r\n\r\nclass RSRSMomentumStrategy(BaseStrategy):\r\n    """\r\n    RSRS \xe5\x8a\xa8\xe9\x87\x8f\xe7\xad\x96\xe7\x95\xa5\r\n    - \xe4\xb9\xb0\xe5\x85\xa5: rsrs_adaptive > threshold\xef\xbc\x88\xe4\xb9\xb0\xe5\x85\xa5\xe5\x89\x8dN\xe5\x8f\xaa\xef\xbc\x89\r\n    - \xe5\x8d\x96\xe5\x87\xba: rsrs_adaptive < -threshold\r\n    """\r\n    name = "RSRSMomentum"\r\n\r\n    def __init__(self, config: Optional[Dict] = None) -> None:\r\n        super().__init__(config)\r\n        self.top_n = self.config.get("top_n", 10)\r\n        self.rsrs_threshold = self.config.get("rsrs_threshold", 0.5)\r\n\r\n    def generate_signals(self, universe, market_data, factor_data,\r\n                         current_date, positions) -> List[Signal]:\r\n        signals = []\r\n        scores = {}\r\n\r\n        for code in universe:\r\n            fd = factor_data.get(code)\r\n            if fd is None or fd.empty or "rsrs_adaptive" not in fd.columns:\r\n                continue\r\n            # NB-01: \xe4\xbd\xbf\xe7\x94\xa8 T-1 \xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x88\xe6\x88\xaa\xe6\xad\xa2 current_date \xe5\x89\x8d\xe4\xb8\x80\xe8\xa1\x8c\xef\xbc\x89\r\n            vals = fd["rsrs_adaptive"].dropna()\r\n            if vals.empty:\r\n                continue\r\n            v = float(vals.iloc[-1])\r\n            if v > self.rsrs_threshold:\r\n                scores[code] = v\r\n\r\n        # \xe9\x80\x80\xe5\x87\xba\xe4\xbf\xa1\xe5\x8f\xb7\r\n        for code in list(positions.keys()):\r\n            fd = factor_data.get(code)\r\n            if fd is None or fd.empty:\r\n                continue\r\n            vals = fd.get("rsrs_adaptive", pd.Series()).dropna()\r\n            if vals.empty:\r\n                continue\r\n            if float(vals.iloc[-1]) < -self.rsrs_threshold:\r\n                signals.append(self._make_sell(code, current_date, "RSRS\xe8\xb7\x8c\xe7\xa0\xb4\xe4\xb8\x8b\xe9\x99\x90"))\r\n\r\n        # \xe4\xb9\xb0\xe5\x85\xa5\xe4\xbf\xa1\xe5\x8f\xb7\xef\xbc\x88Top-N\xef\xbc\x89\r\n        top = sorted(scores, key=scores.__getitem__, reverse=True)[: self.top_n]\r\n        weight = 1.0 / max(len(top), 1)\r\n        for code in top:\r\n            if code not in positions:\r\n                signals.append(self._make_buy(code, scores[code], weight,\r\n                                              current_date, "RSRS\xe5\xbc\xba\xe5\x8a\xbf"))\r\n        return signals\r\n\r\n\r\n# ============================================================================\r\n# 2. AlphaHunterStrategy\r\n# ============================================================================\r\n\r\nclass AlphaHunterStrategy(BaseStrategy):\r\n    """\r\n    Alpha \xe7\x8c\x8e\xe6\x89\x8b\xe7\xad\x96\xe7\x95\xa5\xef\xbc\x88\xe5\xa4\x9a\xe5\xb1\x82\xe8\xaf\x84\xe5\x88\x86\xe9\x94\x81\xe5\xae\x9a\xef\xbc\x89\r\n    \xe7\xbb\xbc\xe5\x90\x88 rsrs_adaptive + mom + vol_factor \xe4\xb8\x89\xe5\x9b\xa0\xe5\xad\x90\xe5\x8a\xa0\xe6\x9d\x83\xe6\x89\x93\xe5\x88\x86\r\n    """\r\n    name = "AlphaHunter"\r\n\r\n    def __init__(self, config: Optional[Dict] = None) -> None:\r\n        super().__init__(config)\r\n        self.top_n    = self.config.get("top_n", 15)\r\n        self.min_score = self.config.get("min_score", 0.3)\r\n        self.factor_weights = self.config.get("factor_weights", {\r\n            "rsrs_adaptive": 0.5, "mom": 0.3, "vol_factor": 0.2,\r\n        })\r\n\r\n    def _get_score(self, fd: pd.DataFrame) -> float:\r\n        score = 0.0\r\n        total_w = 0.0\r\n        for fn, w in self.factor_weights.items():\r\n            if fn in fd.columns:\r\n                vals = fd[fn].dropna()\r\n                if not vals.empty:\r\n                    score += float(vals.iloc[-1]) * w\r\n                    total_w += w\r\n        return score / total_w if total_w > 0 else 0.0\r\n\r\n    def generate_signals(self, universe, market_data, factor_data,\r\n                         current_date, positions) -> List[Signal]:\r\n        signals = []\r\n        scores = {}\r\n\r\n        for code in universe:\r\n            fd = factor_data.get(code)\r\n            if fd is not None and not fd.empty:\r\n                s = self._get_score(fd)\r\n                if s >= self.min_score:\r\n                    scores[code] = s\r\n\r\n        # \xe9\x80\x80\xe5\x87\xba\xe4\xbd\x8e\xe5\x88\x86\xe6\x8c\x81\xe4\xbb\x93\r\n        for code in list(positions.keys()):\r\n            fd = factor_data.get(code)\r\n            if fd is not None and not fd.empty:\r\n                s = self._get_score(fd)\r\n                if s < -self.min_score:\r\n                    signals.append(self._make_sell(code, current_date, f"\xe5\xa4\x9a\xe5\x9b\xa0\xe5\xad\x90\xe5\x88\x86\xe6\x95\xb0{s:.2f}"))\r\n\r\n        top = sorted(scores, key=scores.__getitem__, reverse=True)[: self.top_n]\r\n        weight = 1.0 / max(len(top), 1)\r\n        for code in top:\r\n            if code not in positions:\r\n                signals.append(self._make_buy(code, scores[code], weight,\r\n                                              current_date, f"\xe5\xa4\x9a\xe5\x9b\xa0\xe5\xad\x90{scores[code]:.2f}"))\r\n        return signals\r\n\r\n\r\n# ============================================================================\r\n# 3. RSRSAdvancedStrategy\r\n# ============================================================================\r\n\r\nclass RSRSAdvancedStrategy(BaseStrategy):\r\n    """\r\n    \xe9\xab\x98\xe7\xba\xa7RSRS\xe7\xad\x96\xe7\x95\xa5: R\xc2\xb2\xe8\xbf\x87\xe6\xbb\xa4 + \xe9\x87\x8f\xe4\xbb\xb7\xe5\x85\xb1\xe6\x8c\xaf\xe7\xa1\xae\xe8\xae\xa4\r\n    - \xe4\xbb\x85\xe5\x9c\xa8 rsrs_r2 > r2_threshold \xe6\x97\xb6\xe4\xb9\xb0\xe5\x85\xa5\r\n    - \xe9\x87\x8f\xe4\xbb\xb7\xe5\x85\xb1\xe6\x8c\xaf: turnover \xe9\x9c\x80\xe9\xab\x98\xe4\xba\x8e\xe5\x9d\x87\xe5\x80\xbc\r\n    """\r\n    name = "RSRSAdvanced"\r\n\r\n    def __init__(self, config: Optional[Dict] = None) -> None:\r\n        super().__init__(config)\r\n        self.top_n         = self.config.get("top_n", 10)\r\n        self.rsrs_threshold = self.config.get("rsrs_threshold", 0.5)\r\n        self.r2_threshold  = self.config.get("r2_threshold", 0.7)\r\n\r\n    def generate_signals(self, universe, market_data, factor_data,\r\n                         current_date, positions) -> List[Signal]:\r\n        signals = []\r\n        candidates = {}\r\n\r\n        for code in universe:\r\n            fd = factor_data.get(code)\r\n            if fd is None or fd.empty:\r\n                continue\r\n            ra = fd.get("rsrs_adaptive", pd.Series()).dropna()\r\n            r2 = fd.get("rsrs_r2", pd.Series()).dropna()\r\n            if ra.empty or r2.empty:\r\n                continue\r\n            # R\xc2\xb2 \xe8\xbf\x87\xe6\xbb\xa4\r\n            if float(r2.iloc[-1]) < self.r2_threshold:\r\n                continue\r\n            v = float(ra.iloc[-1])\r\n            if v > self.rsrs_threshold:\r\n                # \xe9\x87\x8f\xe4\xbb\xb7\xe5\x85\xb1\xe6\x8c\xaf\r\n                if "turnover" in fd.columns:\r\n                    to = fd["turnover"].dropna()\r\n                    if not to.empty and float(to.iloc[-1]) < 1.0:\r\n                        continue   # \xe6\x8d\xa2\xe6\x89\x8b\xe4\xbd\x8e\xef\xbc\x8c\xe8\xb7\xb3\xe8\xbf\x87\r\n                candidates[code] = v\r\n\r\n        for code in list(positions.keys()):\r\n            fd = factor_data.get(code)\r\n            if fd is not None and not fd.empty:\r\n                ra = fd.get("rsrs_adaptive", pd.Series()).dropna()\r\n                if not ra.empty and float(ra.iloc[-1]) < -self.rsrs_threshold:\r\n                    signals.append(self._make_sell(code, current_date, "RSRS\xe9\xab\x98\xe7\xba\xa7\xe9\x80\x80\xe5\x87\xba"))\r\n\r\n        top = sorted(candidates, key=candidates.__getitem__, reverse=True)[: self.top_n]\r\n        weight = 1.0 / max(len(top), 1)\r\n        for code in top:\r\n            if code not in positions:\r\n                signals.append(self._make_buy(code, candidates[code], weight,\r\n                                              current_date, f"RSRS+R\xc2\xb2+\xe9\x87\x8f\xe4\xbb\xb7\xe5\x85\xb1\xe6\x8c\xaf"))\r\n        return signals\r\n\r\n\r\n# ============================================================================\r\n# 4. ShortTermStrategy  (NB-14 \xe6\x97\xa5\xe5\x8e\x86\xe6\x97\xa5\xe6\xad\xa2\xe6\x97\xb6)\r\n# ============================================================================\r\n\r\nclass ShortTermStrategy(BaseStrategy):\r\n    """\r\n    \xe7\x9f\xad\xe7\xba\xbf\xe5\xbf\xab\xe8\xbf\x9b\xe5\xbf\xab\xe5\x87\xba\xe7\xad\x96\xe7\x95\xa5\r\n    NB-14: \xe6\x97\xb6\xe9\x97\xb4\xe6\xad\xa2\xe6\x8d\x9f\xe5\x9f\xba\xe4\xba\x8e\xe6\x97\xa5\xe5\x8e\x86\xe6\x97\xa5\xef\xbc\x88\xe4\xb8\x8d\xe6\x98\xaf\xe4\xba\xa4\xe6\x98\x93\xe6\x97\xa5\xef\xbc\x89\r\n    """\r\n    name = "ShortTerm"\r\n\r\n    def __init__(self, config: Optional[Dict] = None) -> None:\r\n        super().__init__(config)\r\n        self.top_n    = self.config.get("top_n", 5)\r\n        self.hold_calendar_days = self.config.get("hold_calendar_days", 7)  # NB-14\r\n        self.mom_threshold = self.config.get("mom_threshold", 0.03)\r\n\r\n    def generate_signals(self, universe, market_data, factor_data,\r\n                         current_date, positions) -> List[Signal]:\r\n        signals = []\r\n        scores = {}\r\n\r\n        # NB-14: \xe6\x97\xa5\xe5\x8e\x86\xe6\x97\xa5\xe6\x97\xb6\xe9\x97\xb4\xe6\xad\xa2\xe6\x8d\x9f\xe6\xa3\x80\xe6\x9f\xa5\r\n        for code, pos in positions.items():\r\n            entry = getattr(pos, "entry_date", None)\r\n            if entry is not None:\r\n                held_calendar = (current_date - entry).days   # \xe6\x97\xa5\xe5\x8e\x86\xe6\x97\xa5\r\n                if held_calendar >= self.hold_calendar_days:\r\n                    signals.append(self._make_sell(code, current_date,\r\n                                                   f"\xe6\x97\xb6\xe9\x97\xb4\xe6\xad\xa2\xe6\x8d\x9f{held_calendar}\xe6\x97\xa5\xe5\x8e\x86\xe6\x97\xa5"))\r\n                    continue\r\n            # \xe5\x8a\xa8\xe9\x87\x8f\xe9\x80\x80\xe5\x87\xba\r\n            fd = factor_data.get(code)\r\n            if fd is not None and "mom" in fd.columns:\r\n                m = fd["mom"].dropna()\r\n                if not m.empty and float(m.iloc[-1]) < -self.mom_threshold:\r\n                    signals.append(self._make_sell(code, current_date, "\xe5\x8a\xa8\xe9\x87\x8f\xe5\x8f\x8d\xe8\xbd\xac"))\r\n\r\n        for code in universe:\r\n            fd = factor_data.get(code)\r\n            if fd is None or fd.empty or "mom" not in fd.columns:\r\n                continue\r\n            m = fd["mom"].dropna()\r\n            if m.empty:\r\n                continue\r\n            v = float(m.iloc[-1])\r\n            if v > self.mom_threshold:\r\n                scores[code] = v\r\n\r\n        top = sorted(scores, key=scores.__getitem__, reverse=True)[: self.top_n]\r\n        weight = 1.0 / max(len(top), 1)\r\n        for code in top:\r\n            if code not in positions:\r\n                signals.append(self._make_buy(code, scores[code], weight,\r\n                                              current_date, "\xe7\x9f\xad\xe7\xba\xbf\xe5\x8a\xa8\xe9\x87\x8f"))\r\n        return signals\r\n\r\n\r\n# ============================================================================\r\n# 5. MomentumReversalStrategy\r\n# ============================================================================\r\n\r\nclass MomentumReversalStrategy(BaseStrategy):\r\n    """\xe5\x8f\x8c\xe6\xa8\xa1\xe5\xbc\x8f: \xe5\xbc\xba\xe5\x8a\xbf\xe5\xb8\x82\xe5\x9c\xba\xe8\xbf\xbd\xe5\x8a\xa8\xe9\x87\x8f(60%) / \xe5\xbc\xb1\xe5\x8a\xbf\xe5\xb8\x82\xe5\x9c\xba\xe5\x81\x9a\xe5\x8f\x8d\xe8\xbd\xac(40%)"""\r\n    name = "MomentumReversal"\r\n\r\n    def __init__(self, config: Optional[Dict] = None) -> None:\r\n        super().__init__(config)\r\n        self.top_n = self.config.get("top_n", 10)\r\n        self.market_thresh = self.config.get("market_thresh", 0.0)\r\n\r\n    def _get_market_mode(self, market_data: Dict) -> str:\r\n        mom_list = []\r\n        for code, df in market_data.items():\r\n            if "close" in df.columns and len(df) > 20:\r\n                ret = float(df["close"].iloc[-1] / df["close"].iloc[-20] - 1)\r\n                mom_list.append(ret)\r\n        if not mom_list:\r\n            return "neutral"\r\n        avg = np.mean(mom_list)\r\n        return "bull" if avg > self.market_thresh else "bear"\r\n\r\n    def generate_signals(self, universe, market_data, factor_data,\r\n                         current_date, positions) -> List[Signal]:\r\n        mode = self._get_market_mode(market_data)\r\n        signals = []\r\n        scores = {}\r\n\r\n        for code in universe:\r\n            fd = factor_data.get(code)\r\n            if fd is None or fd.empty:\r\n                continue\r\n            m = fd.get("mom", pd.Series()).dropna()\r\n            if m.empty:\r\n                continue\r\n            v = float(m.iloc[-1])\r\n            if mode == "bull":\r\n                if v > 0:\r\n                    scores[code] = v      # \xe8\xbf\xbd\xe5\x8a\xa8\xe9\x87\x8f\r\n            else:\r\n                if v < -0.05:\r\n                    scores[code] = -v     # \xe5\x81\x9a\xe5\x8f\x8d\xe8\xbd\xac\xef\xbc\x88\xe8\xb6\x85\xe5\x8d\x96\xef\xbc\x89\r\n\r\n        for code in list(positions.keys()):\r\n            if code not in scores:\r\n                signals.append(self._make_sell(code, current_date, f"\xe6\xa8\xa1\xe5\xbc\x8f\xe5\x88\x87\xe6\x8d\xa2{mode}"))\r\n\r\n        top = sorted(scores, key=scores.__getitem__, reverse=True)[: self.top_n]\r\n        weight = 1.0 / max(len(top), 1)\r\n        for code in top:\r\n            if code not in positions:\r\n                signals.append(self._make_buy(code, scores[code], weight,\r\n                                              current_date, f"{mode}\xe6\xa8\xa1\xe5\xbc\x8f"))\r\n        return signals\r\n\r\n\r\n# ============================================================================\r\n# 6. SentimentReversalStrategy\r\n# ============================================================================\r\n\r\nclass SentimentReversalStrategy(BaseStrategy):\r\n    """\xe6\x83\x85\xe7\xbb\xaa\xe5\x8f\x8d\xe8\xbd\xac: \xe8\xb6\x85\xe5\x8d\x96\xe4\xb9\xb0\xe5\x85\xa5\xef\xbc\x8c\xe8\xb6\x85\xe6\xb6\xa8\xe5\x8d\x96\xe5\x87\xba"""\r\n    name = "SentimentReversal"\r\n\r\n    def __init__(self, config: Optional[Dict] = None) -> None:\r\n        super().__init__(config)\r\n        self.top_n   = self.config.get("top_n", 10)\r\n        self.oversold_z = self.config.get("oversold_z", -1.5)\r\n        self.overbought_z = self.config.get("overbought_z", 1.5)\r\n\r\n    def generate_signals(self, universe, market_data, factor_data,\r\n                         current_date, positions) -> List[Signal]:\r\n        signals = []\r\n        scores = {}\r\n\r\n        for code in universe:\r\n            fd = factor_data.get(code)\r\n            if fd is None or fd.empty:\r\n                continue\r\n            rs = fd.get("rsrs_zscore", pd.Series()).dropna()\r\n            if rs.empty:\r\n                continue\r\n            z = float(rs.iloc[-1])\r\n            if z < self.oversold_z:\r\n                scores[code] = -z   # \xe8\xb6\x8a\xe8\xb6\x85\xe5\x8d\x96\xe8\xb6\x8a\xe9\xab\x98\xe5\x88\x86\r\n\r\n        for code in list(positions.keys()):\r\n            fd = factor_data.get(code)\r\n            if fd is not None and not fd.empty:\r\n                rs = fd.get("rsrs_zscore", pd.Series()).dropna()\r\n                if not rs.empty and float(rs.iloc[-1]) > self.overbought_z:\r\n                    signals.append(self._make_sell(code, current_date, "\xe8\xb6\x85\xe4\xb9\xb0\xe9\x80\x80\xe5\x87\xba"))\r\n\r\n        top = sorted(scores, key=scores.__getitem__, reverse=True)[: self.top_n]\r\n        weight = 1.0 / max(len(top), 1)\r\n        for code in top:\r\n            if code not in positions:\r\n                signals.append(self._make_buy(code, scores[code], weight,\r\n                                              current_date, "\xe8\xb6\x85\xe5\x8d\x96\xe5\x8f\x8d\xe8\xbd\xac"))\r\n        return signals\r\n\r\n\r\n# ============================================================================\r\n# 7. KunpengV10Strategy \xe2\x80\x94 \xe5\xbe\xae\xe7\xbb\x93\xe6\x9e\x84\xe7\xad\x96\xe7\x95\xa5\r\n# ============================================================================\r\n\r\nclass KunpengV10Strategy(BaseStrategy):\r\n    """\r\n    \xe9\xb2\xb2\xe9\xb9\x8fV10\xe7\xad\x96\xe7\x95\xa5 \xe2\x80\x94 \xe5\xb8\x82\xe5\x9c\xba\xe5\xbe\xae\xe7\xbb\x93\xe6\x9e\x84\xe5\x9b\xa0\xe5\xad\x90\r\n    \xe4\xb8\x89\xe6\xa0\xb8\xe5\xbf\x83\xe5\x9b\xa0\xe5\xad\x90:\r\n      SmartMoney  = \xe5\xa4\xa7\xe5\x8d\x95\xe5\x87\x80\xe6\xb5\x81\xe5\x85\xa5\xe5\x8d\xa0\xe6\xaf\x94\xef\xbc\x88\xe7\x94\xa8 (close-low)/(high-low) * vol \xe8\xbf\x91\xe4\xbc\xbc\xef\xbc\x89\r\n      StableIlliq = Amihud \xe9\x9d\x9e\xe6\xb5\x81\xe5\x8a\xa8\xe6\x80\xa7\xe7\xa8\xb3\xe5\xae\x9a\xe6\x80\xa7\xef\xbc\x88\xe4\xbd\x8e\xe6\xb3\xa2\xe5\x8a\xa8\xe9\x9d\x9e\xe6\xb5\x81\xe5\x8a\xa8 > \xe7\xa8\xb3\xe5\xae\x9a\xe6\x8c\x81\xe6\x9c\x89\xe8\x80\x85\xe5\xad\x98\xe5\x9c\xa8\xef\xbc\x89\r\n      GapPenalty  = \xe8\xb7\xb3\xe7\xa9\xba\xe7\xbc\xba\xe5\x8f\xa3\xe6\x83\xa9\xe7\xbd\x9a\xef\xbc\x88\xe8\xb7\xb3\xe7\xa9\xba\xe8\xbf\x87\xe5\xa4\xa7\xe9\x99\x8d\xe6\x9d\x83\xef\xbc\x89\r\n    \xe5\xae\xbd\xe5\xba\xa6\xe7\x86\x94\xe6\x96\xad: \xe8\x8b\xa5\xe6\xb6\xa8\xe5\x81\x9c\xe6\x95\xb0/\xe8\xb7\x8c\xe5\x81\x9c\xe6\x95\xb0\xe5\xbc\x82\xe5\xb8\xb8\xe5\x88\x99\xe6\x9a\x82\xe5\x81\x9c\xe4\xb9\xb0\xe5\x85\xa5\r\n    """\r\n    name = "KunpengV10"\r\n\r\n    def __init__(self, config: Optional[Dict] = None) -> None:\r\n        super().__init__(config)\r\n        self.top_n           = self.config.get("top_n", 15)\r\n        self.illiq_window    = self.config.get("illiq_window", 20)\r\n        self.smart_window    = self.config.get("smart_window", 10)\r\n        self.breadth_limit   = self.config.get("breadth_limit", 0.15)  # \xe5\xae\xbd\xe5\xba\xa6\xe7\x86\x94\xe6\x96\xad\xe9\x98\x88\xe5\x80\xbc\r\n\r\n    def _smart_money(self, df: pd.DataFrame) -> float:\r\n        if not all(c in df.columns for c in ["high", "low", "close", "volume"]):\r\n            return 0.0\r\n        w = self.smart_window\r\n        sub = df.tail(w)\r\n        hl  = (sub["high"] - sub["low"]).replace(0, np.nan)\r\n        buy_vol = (sub["close"] - sub["low"]) / hl * sub["volume"]\r\n        sell_vol = (sub["high"] - sub["close"]) / hl * sub["volume"]\r\n        total_vol = sub["volume"].sum()\r\n        if total_vol < 1:\r\n            return 0.0\r\n        return float((buy_vol.sum() - sell_vol.sum()) / total_vol)\r\n\r\n    def _amihud_stable(self, df: pd.DataFrame) -> float:\r\n        if not all(c in df.columns for c in ["close", "volume", "amount"]):\r\n            return 0.0\r\n        sub = df.tail(self.illiq_window).copy()\r\n        ret = sub["close"].pct_change().abs()\r\n        amt = sub["amount"].replace(0, np.nan)\r\n        illiq = (ret / amt).dropna()\r\n        if len(illiq) < 5:\r\n            return 0.0\r\n        return float(-illiq.std())  # \xe7\xa8\xb3\xe5\xae\x9a=\xe4\xbd\x8e\xe6\xb3\xa2\xe5\x8a\xa8=\xe9\xab\x98\xe5\x88\x86\r\n\r\n    def _gap_penalty(self, df: pd.DataFrame) -> float:\r\n        if "open" not in df.columns or "close" not in df.columns or len(df) < 2:\r\n            return 0.0\r\n        gap = abs(float(df["open"].iloc[-1]) - float(df["close"].iloc[-2]))\r\n        ref = float(df["close"].iloc[-2]) if df["close"].iloc[-2] > 0 else 1\r\n        gap_pct = gap / ref\r\n        return -min(gap_pct, 0.1) * 10   # \xe6\x9c\x80\xe5\xa4\xa7\xe6\x83\xa9\xe7\xbd\x9a -1.0\r\n\r\n    def _breadth_check(self, market_data: Dict) -> bool:\r\n        """\xe5\xae\xbd\xe5\xba\xa6\xe7\x86\x94\xe6\x96\xad\xef\xbc\x9a\xe6\xb6\xa8\xe8\xb7\x8c\xe5\x81\x9c\xe6\xaf\x94\xe4\xbe\x8b\xe8\xb6\x85\xe9\x99\x90\xe8\xbf\x94\xe5\x9b\x9e True\xef\xbc\x88\xe9\x9c\x80\xe6\x9a\x82\xe5\x81\x9c\xe4\xb9\xb0\xe5\x85\xa5\xef\xbc\x89"""\r\n        limit_up = limit_dn = total = 0\r\n        for code, df in market_data.items():\r\n            if "close" not in df.columns or "open" not in df.columns or len(df) < 2:\r\n                continue\r\n            chg = float(df["close"].iloc[-1]) / float(df["close"].iloc[-2]) - 1\r\n            total += 1\r\n            if chg >= 0.095:\r\n                limit_up += 1\r\n            elif chg <= -0.095:\r\n                limit_dn += 1\r\n        if total == 0:\r\n            return False\r\n        return (limit_dn / total) > self.breadth_limit\r\n\r\n    def generate_signals(self, universe, market_data, factor_data,\r\n                         current_date, positions) -> List[Signal]:\r\n        signals = []\r\n\r\n        # \xe5\xae\xbd\xe5\xba\xa6\xe7\x86\x94\xe6\x96\xad\xe6\xa3\x80\xe6\xb5\x8b\r\n        if self._breadth_check(market_data):\r\n            logger.info(f"KunpengV10 \xe5\xae\xbd\xe5\xba\xa6\xe7\x86\x94\xe6\x96\xad\xe8\xa7\xa6\xe5\x8f\x91 {current_date}\xef\xbc\x8c\xe6\x9a\x82\xe5\x81\x9c\xe4\xb9\xb0\xe5\x85\xa5")\r\n            # \xe4\xbb\x8d\xe5\x8f\xaf\xe5\x8d\x96\xe5\x87\xba\r\n            for code in list(positions.keys()):\r\n                df = market_data.get(code)\r\n                if df is not None and len(df) >= 2:\r\n                    chg = float(df["close"].iloc[-1]) / float(df["close"].iloc[-2]) - 1\r\n                    if chg <= -0.09:\r\n                        signals.append(self._make_sell(code, current_date, "\xe5\xae\xbd\xe5\xba\xa6\xe7\x86\x94\xe6\x96\xad\xe5\x8d\x96\xe5\x87\xba"))\r\n            return signals\r\n\r\n        scores = {}\r\n        for code in universe:\r\n            df = market_data.get(code)\r\n            if df is None or len(df) < self.illiq_window:\r\n                continue\r\n            sm  = self._smart_money(df)\r\n            asi = self._amihud_stable(df)\r\n            gp  = self._gap_penalty(df)\r\n            scores[code] = 0.5 * sm + 0.3 * asi + 0.2 * gp\r\n\r\n        for code in list(positions.keys()):\r\n            if code not in scores or scores[code] < -0.3:\r\n                signals.append(self._make_sell(code, current_date, "\xe5\xbe\xae\xe7\xbb\x93\xe6\x9e\x84\xe9\x80\x80\xe5\x8c\x96"))\r\n\r\n        top = sorted(scores, key=scores.__getitem__, reverse=True)[: self.top_n]\r\n        weight = 1.0 / max(len(top), 1)\r\n        for code in top:\r\n            if code not in positions and scores[code] > 0.1:\r\n                signals.append(self._make_buy(code, scores[code], weight,\r\n                                              current_date, f"\xe5\xbe\xae\xe7\xbb\x93\xe6\x9e\x84{scores[code]:.2f}"))\r\n        return signals\r\n\r\n\r\n# ============================================================================\r\n# 8. AlphaMaxV5FixedStrategy \xe2\x80\x94 \xe6\x9c\xba\xe6\x9e\x84\xe5\xa4\x9a\xe5\x9b\xa0\xe5\xad\x90\r\n# ============================================================================\r\n\r\nclass AlphaMaxV5FixedStrategy(BaseStrategy):\r\n    """\r\n    AlphaMax V5 (Fixed) \xe2\x80\x94 \xe6\x9c\xba\xe6\x9e\x84\xe7\xba\xa7\xe5\xa4\x9a\xe5\x9b\xa0\xe5\xad\x90\xe7\xad\x96\xe7\x95\xa5\r\n    \xe4\xb8\x83\xe5\xa4\xa7\xe5\x9b\xa0\xe5\xad\x90:\r\n      EP          = \xe7\x9b\x88\xe5\x88\xa9\xe6\x94\xb6\xe7\x9b\x8a\xe7\x8e\x87 (1/PE_TTM)\r\n      Growth      = \xe5\x87\x80\xe5\x88\xa9\xe6\xb6\xa6\xe5\x90\x8c\xe6\xaf\x94\xe5\xa2\x9e\xe9\x80\x9f\r\n      Momentum    = 20\xe6\x97\xa5\xe4\xbb\xb7\xe6\xa0\xbc\xe5\x8a\xa8\xe9\x87\x8f\r\n      Quality     = ROE_TTM\r\n      Reversal    = \xe7\x9f\xad\xe6\x9c\x9f\xe5\x8f\x8d\xe8\xbd\xac (-5\xe6\x97\xa5\xe6\x94\xb6\xe7\x9b\x8a)\r\n      Liquidity   = \xe9\x9d\x9e\xe6\xb5\x81\xe5\x8a\xa8\xe6\x80\xa7 (Amihud)\r\n      ResidualVol = \xe6\xae\x8b\xe5\xb7\xae\xe6\xb3\xa2\xe5\x8a\xa8\xe7\x8e\x87\xef\xbc\x88\xe7\x89\xb9\xe8\xb4\xa8\xe9\xa3\x8e\xe9\x99\xa9\xef\xbc\x89\r\n    \xe7\x89\xb9\xe6\x80\xa7: \xe8\xa1\x8c\xe4\xb8\x9a\xe4\xb8\xad\xe6\x80\xa7 + \xe9\xa3\x8e\xe9\x99\xa9\xe5\xb9\xb3\xe4\xbb\xb7\xe6\x9d\x83\xe9\x87\x8d\r\n    """\r\n    name = "AlphaMaxV5Fixed"\r\n\r\n    def __init__(self, config: Optional[Dict] = None) -> None:\r\n        super().__init__(config)\r\n        self.top_n       = self.config.get("top_n", 20)\r\n        self.ep_weight   = self.config.get("ep_weight",   0.20)\r\n        self.growth_w    = self.config.get("growth_w",    0.15)\r\n        self.mom_w       = self.config.get("mom_w",       0.15)\r\n        self.quality_w   = self.config.get("quality_w",  0.20)\r\n        self.rev_w       = self.config.get("rev_w",       0.10)\r\n        self.liq_w       = self.config.get("liq_w",       0.10)\r\n        self.res_vol_w   = self.config.get("res_vol_w",  0.10)\r\n\r\n    def _compute_ep(self, fundamental: Optional[Dict]) -> float:\r\n        if not fundamental:\r\n            return 0.0\r\n        pe = fundamental.get("pe_ttm")\r\n        if pe and abs(pe) > 1e-6:\r\n            return 1.0 / pe\r\n        return 0.0\r\n\r\n    def _compute_resid_vol(self, df: pd.DataFrame, market_df: Optional[pd.DataFrame]) -> float:\r\n        """\xe6\xae\x8b\xe5\xb7\xae\xe6\xb3\xa2\xe5\x8a\xa8\xe7\x8e\x87\xef\xbc\x88\xe7\x89\xb9\xe8\xb4\xa8\xe9\xa3\x8e\xe9\x99\xa9\xef\xbc\x89= std(\xe8\x82\xa1\xe7\xa5\xa8\xe6\x97\xa5\xe6\x94\xb6\xe7\x9b\x8a - beta*\xe5\xb8\x82\xe5\x9c\xba\xe6\x97\xa5\xe6\x94\xb6\xe7\x9b\x8a)"""\r\n        if "close" not in df.columns or len(df) < 20:\r\n            return 0.0\r\n        ret = df["close"].pct_change().tail(60).dropna()\r\n        if market_df is not None and "close" in market_df.columns:\r\n            mkt = market_df["close"].pct_change().reindex(ret.index).dropna()\r\n            common = ret.reindex(mkt.index).dropna()\r\n            mkt = mkt.reindex(common.index)\r\n            if len(common) > 10:\r\n                cov = np.cov(common, mkt)\r\n                beta = cov[0, 1] / (cov[1, 1] + 1e-9) if cov[1, 1] > 1e-9 else 1.0\r\n                resid = common - beta * mkt\r\n                return float(-resid.std())   # \xe4\xbd\x8e\xe6\xae\x8b\xe5\xb7\xae\xe6\xb3\xa2\xe5\x8a\xa8=\xe9\xab\x98\xe5\x88\x86\r\n        return float(-ret.std())\r\n\r\n    def _zscore_cross_section(self, scores: Dict[str, Dict]) -> Dict[str, float]:\r\n        """\xe6\x88\xaa\xe9\x9d\xa2Z-score + \xe5\x8a\xa0\xe6\x9d\x83\xe5\x90\x88\xe6\x88\x90"""\r\n        if not scores:\r\n            return {}\r\n        df = pd.DataFrame(scores).T.astype(float)\r\n        for col in df.columns:\r\n            s = df[col]\r\n            std = s.std()\r\n            df[col] = (s - s.mean()) / (std + 1e-9) if std > 1e-9 else 0.0\r\n\r\n        weights = {\r\n            "ep": self.ep_weight, "growth": self.growth_w,\r\n            "mom": self.mom_w, "quality": self.quality_w,\r\n            "rev": self.rev_w, "liq": self.liq_w, "resvol": self.res_vol_w,\r\n        }\r\n        total_w = sum(weights.values())\r\n        composite = {}\r\n        for code in df.index:\r\n            s = sum(df.loc[code].get(fn, 0.0) * w for fn, w in weights.items())\r\n            composite[code] = s / total_w\r\n        return composite\r\n\r\n    def generate_signals(self, universe, market_data, factor_data,\r\n                         current_date, positions,\r\n                         fundamental_data: Optional[Dict] = None,\r\n                         index_df: Optional[pd.DataFrame] = None) -> List[Signal]:\r\n        signals = []\r\n        raw_scores: Dict[str, Dict] = {}\r\n\r\n        for code in universe:\r\n            df  = market_data.get(code)\r\n            fd  = factor_data.get(code)\r\n            fun = (fundamental_data or {}).get(code)\r\n\r\n            if df is None or len(df) < 20:\r\n                continue\r\n\r\n            close = df["close"]\r\n            pct   = close.pct_change()\r\n\r\n            ep      = self._compute_ep(fun)\r\n            growth  = float(fun.get("net_profit_growth", 0.0) or 0.0) if fun else 0.0\r\n            mom     = float(pct.tail(20).add(1).prod() - 1) if len(pct) >= 20 else 0.0\r\n            quality = float(fun.get("roe_ttm", 0.0) or 0.0) if fun else 0.0\r\n            rev     = -float(pct.tail(5).sum()) if len(pct) >= 5 else 0.0\r\n\r\n            # Amihud \xe9\x9d\x9e\xe6\xb5\x81\xe5\x8a\xa8\xe6\x80\xa7\xef\xbc\x88\xe8\xb4\x9f\xe5\x90\x91\xef\xbc\x8c\xe8\xb6\x8a\xe4\xbd\x8e\xe8\xb6\x8a\xe5\xa5\xbd\xef\xbc\x89\r\n            if "amount" in df.columns:\r\n                amt = df["amount"].tail(20).replace(0, np.nan)\r\n                liq = float(-(pct.tail(20).abs() / amt).mean()) if not amt.isna().all() else 0.0\r\n            else:\r\n                liq = 0.0\r\n\r\n            resvol = self._compute_resid_vol(df, index_df)\r\n\r\n            raw_scores[code] = {\r\n                "ep": ep, "growth": growth, "mom": mom,\r\n                "quality": quality, "rev": rev, "liq": liq, "resvol": resvol,\r\n            }\r\n\r\n        # \xe6\x88\xaa\xe9\x9d\xa2\xe6\xa0\x87\xe5\x87\x86\xe5\x8c\x96 + \xe5\x8a\xa0\xe6\x9d\x83\r\n        composite = self._zscore_cross_section(raw_scores)\r\n\r\n        # \xe9\x80\x80\xe5\x87\xba\xe4\xbd\x8e\xe5\x88\x86\xe6\x8c\x81\xe4\xbb\x93\r\n        for code in list(positions.keys()):\r\n            if composite.get(code, -999) < -0.5:\r\n                signals.append(self._make_sell(code, current_date, "\xe5\xa4\x9a\xe5\x9b\xa0\xe5\xad\x90\xe7\xbb\xbc\xe5\x90\x88\xe5\x88\x86\xe5\x81\x8f\xe4\xbd\x8e"))\r\n\r\n        # \xe4\xb9\xb0\xe5\x85\xa5 Top-N\xef\xbc\x88\xe9\xa3\x8e\xe9\x99\xa9\xe5\xb9\xb3\xe4\xbb\xb7\xe6\x9d\x83\xe9\x87\x8d\xe9\x9c\x80\xe5\xa4\x96\xe9\x83\xa8\xe4\xbc\xa0\xe5\x85\xa5\xe6\xb3\xa2\xe5\x8a\xa8\xe7\x8e\x87\xef\xbc\x8c\xe6\xad\xa4\xe5\xa4\x84\xe7\xae\x80\xe5\x8c\x96\xe7\xad\x89\xe6\x9d\x83\xef\xbc\x89\r\n        top = sorted(composite, key=composite.__getitem__, reverse=True)[: self.top_n]\r\n        weight = 1.0 / max(len(top), 1)\r\n        for code in top:\r\n            if code not in positions and composite[code] > 0.3:\r\n                signals.append(self._make_buy(code, composite[code], weight,\r\n                                              current_date, f"AlphaMax\xe5\xa4\x9a\xe5\x9b\xa0\xe5\xad\x90{composite[code]:.2f}"))\r\n        return signals\r\n\r\n\r\n# ============================================================================\r\n# \xe7\xad\x96\xe7\x95\xa5\xe6\xb3\xa8\xe5\x86\x8c\xe8\xa1\xa8\r\n# ============================================================================\r\n\r\nSTRATEGY_REGISTRY: Dict[str, type] = {\r\n    "rsrs_momentum":       RSRSMomentumStrategy,\r\n    "alpha_hunter":        AlphaHunterStrategy,\r\n    "rsrs_advanced":       RSRSAdvancedStrategy,\r\n    "short_term":          ShortTermStrategy,\r\n    "momentum_reversal":   MomentumReversalStrategy,\r\n    "sentiment_reversal":  SentimentReversalStrategy,\r\n    "kunpeng_v10":         KunpengV10Strategy,\r\n    "alpha_max_v5_fixed":  AlphaMaxV5FixedStrategy,\r\n}\r\n\r\n\r\ndef create_strategy(name: str, config: Optional[Dict] = None) -> BaseStrategy:\r\n    cls = STRATEGY_REGISTRY.get(name)\r\n    if cls is None:\r\n        raise ValueError(f"\xe6\x9c\xaa\xe7\x9f\xa5\xe7\xad\x96\xe7\x95\xa5: {name}\xef\xbc\x8c\xe5\x8f\xaf\xe7\x94\xa8: {list(STRATEGY_REGISTRY.keys())}")\r\n    return cls(config)\r\n'

FILE_tests_init_py = b'#!/usr/bin/env python3\r\n"""Q-UNITY-V7.1 \xe6\xb5\x8b\xe8\xaf\x95\xe5\xa5\x97\xe4\xbb\xb6"""\r\n'

FILE_tests_conftest_py = b'#!/usr/bin/env python3\r\n"""pytest \xe9\x85\x8d\xe7\xbd\xae"""\r\nimport sys\r\nfrom pathlib import Path\r\nsys.path.insert(0, str(Path(__file__).parent.parent))\r\n'

FILE_tests_test_collector_py = b'#!/usr/bin/env python3\r\n# -*- coding: utf-8 -*-\r\n"""\r\ntest_collector.py \xe2\x80\x94 \xe5\x8f\x8c\xe8\xbd\xa8\xe9\x87\x87\xe9\x9b\x86\xe5\xbc\x95\xe6\x93\x8e\xe5\x8d\x95\xe5\x85\x83\xe6\xb5\x8b\xe8\xaf\x95 (patch_v9)\r\n=====================================================\r\nT1: \xe8\x8a\x82\xe7\x82\xb9\xe6\x89\xab\xe6\x8f\x8f\xe5\x99\xa8\xef\xbc\x8824\xe8\x8a\x82\xe7\x82\xb9 / \xe6\x8e\x92\xe5\xba\x8f\xe9\x80\xbb\xe8\xbe\x91\xef\xbc\x89\r\nT2: TDXConnectionPool\xef\xbc\x88\xe7\xba\xbf\xe7\xa8\x8b\xe9\x9a\x94\xe7\xa6\xbb\xef\xbc\x89\r\nT3: \xe5\xa2\x9e\xe9\x87\x8f\xe6\x9b\xb4\xe6\x96\xb0\xe9\x80\xbb\xe8\xbe\x91\xef\xbc\x88max_date / merge / \xe5\x8e\xbb\xe9\x87\x8d\xef\xbc\x89\r\nT4: DataValidator\xef\xbc\x88\xe4\xb8\x89\xe5\xb1\x82\xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x89\r\nT5: RunReport\xef\xbc\x88\xe6\x8c\x81\xe4\xb9\x85\xe5\x8c\x96 / \xe5\x8a\xa0\xe8\xbd\xbd\xef\xbc\x89\r\nT6: \xe5\x8f\x8c\xe8\xbd\xa8\xe5\x90\x88\xe5\xb9\xb6\xe9\x80\xbb\xe8\xbe\x91\xef\xbc\x88TDX + AKShare merge\xef\xbc\x89\r\nT7: \xe4\xb8\x89\xe7\xba\xa7\xe9\x99\x8d\xe7\xba\xa7\xe7\xae\xa1\xe9\x81\x93\xef\xbc\x88\xe5\x85\xa8 Mock\xef\xbc\x89\r\nT8: AKShare \xe8\xbf\x9b\xe7\xa8\x8b\xe9\x9a\x94\xe7\xa6\xbb\xe9\x80\x80\xe9\x81\xbf\xef\xbc\x88\xe9\x99\x90\xe6\xb5\x81\xe6\xa3\x80\xe6\xb5\x8b\xef\xbc\x89\r\n"""\r\n\r\nimport json\r\nimport math\r\nimport tempfile\r\nimport threading\r\nimport unittest\r\nfrom datetime import date, timedelta\r\nfrom pathlib import Path\r\nfrom typing import Optional\r\nfrom unittest.mock import MagicMock, patch, call\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n\r\n# \xe2\x94\x80\xe2\x94\x80 \xe8\xbe\x85\xe5\x8a\xa9\xe5\x87\xbd\xe6\x95\xb0 \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\ndef _make_ohlcv(n: int, code: str = "000001", seed: int = 42) -> pd.DataFrame:\r\n    rng   = np.random.RandomState(seed)\r\n    dates = pd.date_range("2023-01-01", periods=n, freq="B").strftime("%Y-%m-%d")\r\n    base  = 10.0 + rng.randn(n).cumsum() * 0.5\r\n    base  = np.abs(base) + 5  # \xe7\xa1\xae\xe4\xbf\x9d\xe6\xad\xa3\xe6\x95\xb0\r\n    return pd.DataFrame({\r\n        "code":   code,\r\n        "date":   dates,\r\n        "open":   base.astype("float32"),\r\n        "high":   (base * 1.02).astype("float32"),\r\n        "low":    (base * 0.98).astype("float32"),\r\n        "close":  (base * 1.005).astype("float32"),\r\n        "vol":    np.ones(n, dtype="int64") * 100000,\r\n        "amount": np.ones(n, dtype="int64") * 1000000,\r\n        "source": "tdx",\r\n        "adjust": "hfq",\r\n    })\r\n\r\n\r\ndef _make_akshare_df(n: int, code: str = "000001") -> pd.DataFrame:\r\n    dates = pd.date_range("2023-01-01", periods=n, freq="B").strftime("%Y-%m-%d")\r\n    return pd.DataFrame({\r\n        "code":      code,\r\n        "date":      dates,\r\n        "open":      np.ones(n, dtype="float32") * 10.0,\r\n        "high":      np.ones(n, dtype="float32") * 10.5,\r\n        "low":       np.ones(n, dtype="float32") * 9.5,\r\n        "close":     np.ones(n, dtype="float32") * 10.2,\r\n        "vol":       np.ones(n, dtype="int64") * 100000,\r\n        "turnover":  np.random.rand(n).astype("float32") * 5,\r\n        "pct_change":np.random.randn(n).astype("float32"),\r\n        "source":    "akshare",\r\n        "adjust":    "hfq",\r\n    })\r\n\r\n\r\n# ============================================================================\r\n# T1: \xe8\x8a\x82\xe7\x82\xb9\xe6\x89\xab\xe6\x8f\x8f\xe5\x99\xa8\r\n# ============================================================================\r\nclass TestNodeScanner(unittest.TestCase):\r\n\r\n    def test_node_count_equals_24(self):\r\n        from src.data.collector.node_scanner import TDX_NODES\r\n        self.assertEqual(len(TDX_NODES), 24)\r\n\r\n    def test_all_nodes_port_7709(self):\r\n        from src.data.collector.node_scanner import TDX_NODES\r\n        for n in TDX_NODES:\r\n            self.assertEqual(n["port"], 7709)\r\n            self.assertIn("host", n)\r\n            self.assertIn("name", n)\r\n\r\n    def test_sort_ok_before_failed(self):\r\n        from src.data.collector.node_scanner import _sort_results\r\n        data = [\r\n            {"name": "a", "host": "1.1.1.1", "port": 7709, "latency_ms": 80.0, "status": "ok"},\r\n            {"name": "b", "host": "2.2.2.2", "port": 7709, "latency_ms": -1.0, "status": "fail:x"},\r\n            {"name": "c", "host": "3.3.3.3", "port": 7709, "latency_ms": 20.0, "status": "ok"},\r\n        ]\r\n        s = _sort_results(data)\r\n        self.assertEqual(s[0]["name"], "c")\r\n        self.assertEqual(s[1]["name"], "a")\r\n        self.assertEqual(s[2]["name"], "b")\r\n\r\n    def test_probe_unreachable(self):\r\n        from src.data.collector.node_scanner import _probe_sync\r\n        node = {"name": "x", "host": "10.255.255.1", "port": 1}\r\n        r    = _probe_sync(node, timeout=0.3)\r\n        self.assertLess(r["latency_ms"], 0)\r\n        self.assertTrue(r["status"].startswith("fail"))\r\n\r\n\r\n# ============================================================================\r\n# T2: TDXConnectionPool \xe7\xba\xbf\xe7\xa8\x8b\xe9\x9a\x94\xe7\xa6\xbb\r\n# ============================================================================\r\nclass TestTDXConnectionPool(unittest.TestCase):\r\n\r\n    def test_empty_nodes_raises(self):\r\n        import src.data.collector.tdx_pool as pool_mod\r\n        with patch.object(pool_mod, "_PYTDX_AVAILABLE", True):\r\n            from src.data.collector.tdx_pool import TDXConnectionPool\r\n            with self.assertRaises(ValueError):\r\n                TDXConnectionPool([], timeout=1.0)\r\n\r\n    def test_local_storage_per_thread(self):\r\n        """threading.local \xe4\xbf\x9d\xe8\xaf\x81\xe4\xb8\x8d\xe5\x90\x8c\xe7\xba\xbf\xe7\xa8\x8b\xe7\x9c\x8b\xe5\x88\xb0\xe5\x90\x84\xe8\x87\xaa\xe7\x9a\x84 api \xe5\xae\x9e\xe4\xbe\x8b\xe3\x80\x82"""\r\n        import threading\r\n        import src.data.collector.tdx_pool as pool_mod\r\n        from src.data.collector.tdx_pool import TDXConnectionPool\r\n\r\n        nodes = [{"name": "n0", "host": "127.0.0.1", "port": 7709}]\r\n\r\n        with patch.object(pool_mod, "_PYTDX_AVAILABLE", True):\r\n            pool = TDXConnectionPool(nodes, timeout=0.1)\r\n\r\n        captured = {}\r\n\r\n        def _set_local(tid, val):\r\n            pool._local.api = val\r\n            import time; time.sleep(0.05)\r\n            captured[tid] = pool._local.api\r\n\r\n        threads = [threading.Thread(target=_set_local, args=(i, MagicMock())) for i in range(4)]\r\n        for t in threads: t.start()\r\n        for t in threads: t.join()\r\n\r\n        # \xe6\xaf\x8f\xe4\xb8\xaa\xe7\xba\xbf\xe7\xa8\x8b\xe5\x86\x99\xe5\x85\xa5\xe8\x87\xaa\xe5\xb7\xb1\xe7\x9a\x84\xe5\x80\xbc\r\n        ids = list(set(id(v) for v in captured.values()))\r\n        # 4 \xe4\xb8\xaa\xe7\xba\xbf\xe7\xa8\x8b\xe5\xba\x94\xe8\xaf\xa5\xe6\x9c\x89 4 \xe4\xb8\xaa\xe4\xb8\x8d\xe5\x90\x8c\xe7\x9a\x84 mock \xe5\xaf\xb9\xe8\xb1\xa1\xef\xbc\x88\xe5\x90\x84\xe8\x87\xaa\xe9\x9a\x94\xe7\xa6\xbb\xef\xbc\x89\r\n        self.assertEqual(len(ids), 4)\r\n\r\n\r\n# ============================================================================\r\n# T3: \xe5\xa2\x9e\xe9\x87\x8f\xe6\x9b\xb4\xe6\x96\xb0\xe9\x80\xbb\xe8\xbe\x91\r\n# ============================================================================\r\nclass TestIncremental(unittest.TestCase):\r\n\r\n    def _write_parquet(self, df: pd.DataFrame) -> Path:\r\n        f = tempfile.NamedTemporaryFile(suffix=".parquet", delete=False)\r\n        path = Path(f.name)\r\n        df.to_parquet(path, index=False)\r\n        return path\r\n\r\n    def test_read_local_max_date_no_file(self):\r\n        from src.data.collector.incremental import read_local_max_date\r\n        self.assertIsNone(read_local_max_date(Path("/tmp/nonexistent_xyz999.parquet")))\r\n\r\n    def test_read_local_max_date_correct(self):\r\n        from src.data.collector.incremental import read_local_max_date\r\n        df   = _make_ohlcv(30)\r\n        path = self._write_parquet(df)\r\n        self.assertEqual(read_local_max_date(path), df["date"].max())\r\n        path.unlink(missing_ok=True)\r\n\r\n    def test_compute_missing_range_full(self):\r\n        from src.data.collector.incremental import compute_missing_range\r\n        s, e = compute_missing_range(None, "2024-03-01", "2005-01-01")\r\n        self.assertEqual(s, "2005-01-01")\r\n        self.assertEqual(e, "2024-03-01")\r\n\r\n    def test_compute_missing_range_incremental(self):\r\n        from src.data.collector.incremental import compute_missing_range\r\n        s, e = compute_missing_range("2024-01-10", "2024-01-20")\r\n        self.assertEqual(s, "2024-01-11")\r\n        self.assertEqual(e, "2024-01-20")\r\n\r\n    def test_merge_no_duplicates(self):\r\n        from src.data.collector.incremental import merge_incremental\r\n        old = _make_ohlcv(30)\r\n        new = _make_ohlcv(20)   # \xe5\x8f\xaf\xe8\x83\xbd\xe6\x9c\x89\xe6\x97\xa5\xe6\x9c\x9f\xe9\x87\x8d\xe5\x8f\xa0\r\n        m   = merge_incremental(old, new)\r\n        self.assertFalse(m.duplicated(subset=["date"]).any())\r\n        self.assertEqual(m["date"].tolist(), sorted(m["date"].tolist()))\r\n\r\n    def test_is_up_to_date_yesterday(self):\r\n        from src.data.collector.incremental import is_up_to_date\r\n        yest = (date.today() - timedelta(days=1)).strftime("%Y-%m-%d")\r\n        self.assertTrue(is_up_to_date(yest))\r\n\r\n    def test_is_up_to_date_old(self):\r\n        from src.data.collector.incremental import is_up_to_date\r\n        old = (date.today() - timedelta(days=30)).strftime("%Y-%m-%d")\r\n        self.assertFalse(is_up_to_date(old))\r\n\r\n\r\n# ============================================================================\r\n# T4: DataValidator \xe2\x80\x94 \xe4\xb8\x89\xe5\xb1\x82\xe9\xaa\x8c\xe8\xaf\x81\r\n# ============================================================================\r\nclass TestDataValidator(unittest.TestCase):\r\n\r\n    def test_none_df_fails(self):\r\n        from src.data.collector.validator import DataValidator\r\n        ok, reason = DataValidator.validate(None)\r\n        self.assertFalse(ok)\r\n        self.assertEqual(reason, "df_is_none")\r\n\r\n    def test_empty_df_fails(self):\r\n        from src.data.collector.validator import DataValidator\r\n        ok, reason = DataValidator.validate(pd.DataFrame())\r\n        self.assertFalse(ok)\r\n        self.assertEqual(reason, "df_empty")\r\n\r\n    def test_too_few_rows_fails(self):\r\n        from src.data.collector.validator import DataValidator\r\n        df         = _make_ohlcv(5)\r\n        ok, reason = DataValidator.validate(df, min_rows=10)\r\n        self.assertFalse(ok)\r\n        self.assertTrue(reason.startswith("too_few_rows"))\r\n\r\n    def test_missing_col_fails(self):\r\n        from src.data.collector.validator import DataValidator\r\n        df         = _make_ohlcv(20).drop(columns=["close"])\r\n        ok, reason = DataValidator.validate(df)\r\n        self.assertFalse(ok)\r\n        self.assertIn("missing_cols", reason)\r\n\r\n    def test_high_lt_low_fails(self):\r\n        from src.data.collector.validator import DataValidator\r\n        df = _make_ohlcv(20)\r\n        # \xe4\xba\xba\xe5\xb7\xa5\xe5\x88\xb6\xe9\x80\xa0 high < low\r\n        df.loc[5, "high"] = df.loc[5, "low"] - 1.0\r\n        ok, reason = DataValidator.validate(df)\r\n        self.assertFalse(ok)\r\n        self.assertIn("high_lt_low", reason)\r\n\r\n    def test_negative_close_fails(self):\r\n        from src.data.collector.validator import DataValidator\r\n        df = _make_ohlcv(20)\r\n        df.loc[3, "close"] = -1.0\r\n        ok, reason = DataValidator.validate(df)\r\n        self.assertFalse(ok)\r\n        self.assertIn("negative_close", reason)\r\n\r\n    def test_valid_df_passes(self):\r\n        from src.data.collector.validator import DataValidator\r\n        df         = _make_ohlcv(30)\r\n        ok, reason = DataValidator.validate(df)\r\n        self.assertTrue(ok)\r\n        self.assertEqual(reason, "ok")\r\n\r\n    def test_validate_merge_result_sorted(self):\r\n        from src.data.collector.validator import DataValidator\r\n        df = _make_ohlcv(20)\r\n        # \xe6\x95\x85\xe6\x84\x8f\xe4\xb9\xb1\xe5\xba\x8f\r\n        df = df.sample(frac=1, random_state=42).reset_index(drop=True)\r\n        ok, reason = DataValidator.validate_merge_result(df)\r\n        self.assertFalse(ok)\r\n        self.assertEqual(reason, "date_not_sorted")\r\n\r\n\r\n# ============================================================================\r\n# T5: RunReport \xe6\x8c\x81\xe4\xb9\x85\xe5\x8c\x96\r\n# ============================================================================\r\nclass TestRunReport(unittest.TestCase):\r\n\r\n    def setUp(self):\r\n        self.tmpdir = tempfile.mkdtemp()\r\n\r\n    def test_record_and_save(self):\r\n        from src.data.collector.run_report import RunReport\r\n        report = RunReport(self.tmpdir)\r\n        report.record_success("000001", 0, source="tdx",      rows=1000)\r\n        report.record_success("600000", 1, source="akshare",  rows=800)\r\n        report.record_failed ("000002", 0, reason="complete_fail")\r\n        report.record_skipped("000003", 0)\r\n        report.save()\r\n\r\n        failed_path = Path(self.tmpdir) / "failed_stocks.txt"\r\n        self.assertTrue(failed_path.exists())\r\n        content = failed_path.read_text()\r\n        self.assertIn("000002", content)\r\n        self.assertNotIn("000001", content)\r\n\r\n        # JSON \xe5\xad\x98\xe5\x9c\xa8\r\n        json_files = list(Path(self.tmpdir).glob("run_stats_*.json"))\r\n        self.assertEqual(len(json_files), 1)\r\n        with open(json_files[0]) as f:\r\n            stats = json.load(f)\r\n        self.assertEqual(stats["success"], 2)\r\n        self.assertEqual(stats["failed"], 1)\r\n\r\n    def test_load_failed_list(self):\r\n        from src.data.collector.run_report import RunReport\r\n        report = RunReport(self.tmpdir)\r\n        report.record_failed("000001", 0, reason="complete_fail")\r\n        report.record_failed("600000", 1, reason="validate:too_few_rows")\r\n        report.save()\r\n\r\n        loaded = RunReport.load_failed_list(self.tmpdir)\r\n        codes  = [c for c, _ in loaded]\r\n        self.assertIn("000001", codes)\r\n        self.assertIn("600000", codes)\r\n\r\n    def test_summary_str_format(self):\r\n        from src.data.collector.run_report import RunReport\r\n        report = RunReport(self.tmpdir)\r\n        report.record_success("000001", 0, "tdx")\r\n        report.record_failed ("000002", 0, "fail")\r\n        s = report.summary_str()\r\n        self.assertIn("\xe2\x9c\x93", s)\r\n        self.assertIn("\xe2\x9c\x97", s)\r\n\r\n    def test_thread_safe_recording(self):\r\n        """\xe5\xa4\x9a\xe7\xba\xbf\xe7\xa8\x8b\xe5\xb9\xb6\xe5\x8f\x91\xe8\xae\xb0\xe5\xbd\x95\xe4\xb8\x8d\xe5\xb4\xa9\xe6\xba\x83\xe3\x80\x81\xe8\xae\xa1\xe6\x95\xb0\xe5\x87\x86\xe7\xa1\xae\xe3\x80\x82"""\r\n        from src.data.collector.run_report import RunReport\r\n        report = RunReport(self.tmpdir)\r\n\r\n        def _worker(i):\r\n            if i % 3 == 0:\r\n                report.record_success(f"{i:06d}", 0, "tdx")\r\n            elif i % 3 == 1:\r\n                report.record_failed(f"{i:06d}", 0, "fail")\r\n            else:\r\n                report.record_skipped(f"{i:06d}", 0)\r\n\r\n        threads = [threading.Thread(target=_worker, args=(i,)) for i in range(60)]\r\n        for t in threads: t.start()\r\n        for t in threads: t.join()\r\n\r\n        self.assertEqual(report.total_success + report.total_failed + report.total_skipped, 60)\r\n\r\n\r\n# ============================================================================\r\n# T6: \xe5\x8f\x8c\xe8\xbd\xa8\xe5\x90\x88\xe5\xb9\xb6\xe9\x80\xbb\xe8\xbe\x91\r\n# ============================================================================\r\nclass TestDualTrackMerge(unittest.TestCase):\r\n\r\n    def test_both_none_returns_none(self):\r\n        from src.data.collector.pipeline import _merge_dual_track\r\n        self.assertIsNone(_merge_dual_track(None, None))\r\n\r\n    def test_only_tdx_returns_tdx(self):\r\n        from src.data.collector.pipeline import _merge_dual_track\r\n        tdx = _make_ohlcv(20)\r\n        result = _merge_dual_track(tdx, None)\r\n        self.assertEqual(len(result), 20)\r\n        self.assertEqual(result["source"].iloc[0], "tdx")\r\n\r\n    def test_only_akshare_returns_akshare(self):\r\n        from src.data.collector.pipeline import _merge_dual_track\r\n        ak = _make_akshare_df(20)\r\n        result = _merge_dual_track(None, ak)\r\n        self.assertEqual(result["source"].iloc[0], "akshare")\r\n\r\n    def test_merge_adds_turnover_column(self):\r\n        """\xe5\x8f\x8c\xe8\xbd\xa8\xe5\x90\x88\xe5\xb9\xb6\xe5\x90\x8e\xef\xbc\x8cresult \xe5\xba\x94\xe5\x8c\x85\xe5\x90\xab\xe6\x9d\xa5\xe8\x87\xaa AKShare \xe7\x9a\x84 turnover \xe5\xad\x97\xe6\xae\xb5\xe3\x80\x82"""\r\n        from src.data.collector.pipeline import _merge_dual_track\r\n        tdx = _make_ohlcv(30)\r\n        ak  = _make_akshare_df(30)\r\n        merged = _merge_dual_track(tdx, ak)\r\n        self.assertIn("turnover", merged.columns)\r\n        self.assertIn("pct_change", merged.columns)\r\n\r\n    def test_merge_date_alignment(self):\r\n        """\xe5\x8f\xaa\xe6\x9c\x89\xe9\x87\x8d\xe5\x8f\xa0\xe6\x97\xa5\xe6\x9c\x9f\xe7\x9a\x84\xe8\xa1\x8c\xe6\x89\x8d\xe5\xba\x94\xe6\x9c\x89\xe9\x9d\x9e NaN \xe7\x9a\x84 turnover\xe3\x80\x82"""\r\n        from src.data.collector.pipeline import _merge_dual_track\r\n        tdx = _make_ohlcv(30)\r\n        # AKShare \xe5\x8f\xaa\xe8\xa6\x86\xe7\x9b\x96\xe5\x90\x8e 15 \xe5\xa4\xa9\r\n        ak  = _make_akshare_df(15)\r\n        # \xe5\xaf\xb9\xe9\xbd\x90\xe6\x97\xa5\xe6\x9c\x9f\r\n        ak_dates = tdx["date"].tail(15).tolist()\r\n        ak["date"] = ak_dates\r\n        merged  = _merge_dual_track(tdx, ak)\r\n        # \xe5\x89\x8d 15 \xe8\xa1\x8c turnover \xe5\xba\x94\xe4\xb8\xba NaN\xef\xbc\x8c\xe5\x90\x8e 15 \xe8\xa1\x8c\xe5\xba\x94\xe6\x9c\x89\xe5\x80\xbc\r\n        self.assertTrue(merged["turnover"].iloc[:15].isna().all())\r\n        self.assertTrue(merged["turnover"].iloc[15:].notna().all())\r\n\r\n    def test_merge_adjust_flag(self):\r\n        """\xe5\x90\x88\xe5\xb9\xb6\xe5\x90\x8e adjust \xe5\x88\x97\xe5\xba\x94\xe4\xb8\xba hfq\xef\xbc\x88TDX \xe5\xb7\xb2 adjustflag=2 \xe5\x90\x8e\xe5\xa4\x8d\xe6\x9d\x83\xef\xbc\x8c\xe4\xb8\x8e AKShare \xe4\xbd\x93\xe7\xb3\xbb\xe7\xbb\x9f\xe4\xb8\x80\xef\xbc\x89\xe3\x80\x82"""\r\n        from src.data.collector.pipeline import _merge_dual_track\r\n        tdx    = _make_ohlcv(20)\r\n        ak     = _make_akshare_df(20)\r\n        # \xe7\xbb\x9f\xe4\xb8\x80 date\r\n        ak["date"] = tdx["date"].tolist()\r\n        merged = _merge_dual_track(tdx, ak)\r\n        self.assertTrue((merged["adjust"] == "hfq").all())\r\n\r\n\r\n# ============================================================================\r\n# T7: \xe4\xb8\x89\xe7\xba\xa7\xe9\x99\x8d\xe7\xba\xa7\xe7\xae\xa1\xe9\x81\x93\xef\xbc\x88\xe5\x85\xa8 Mock\xef\xbc\x89\r\n# ============================================================================\r\nclass TestFailoverPipeline(unittest.TestCase):\r\n\r\n    def _run_update(self, tdx_df, ak_df, bs_df):\r\n        """\xe4\xbe\xbf\xe6\x8d\xb7\xe8\xbe\x85\xe5\x8a\xa9\xef\xbc\x9a\xe6\xa8\xa1\xe6\x8b\x9f update_single_stock \xe7\x9a\x84\xe4\xb8\x89\xe7\xba\xa7\xe9\x99\x8d\xe7\xba\xa7\xe3\x80\x82"""\r\n        import tempfile\r\n        from src.data.collector.pipeline import update_single_stock\r\n        from src.data.collector.run_report import RunReport\r\n\r\n        tmpdir  = tempfile.mkdtemp()\r\n        report  = RunReport(tmpdir)\r\n        pool    = MagicMock()\r\n        ak_results = {"000001": ak_df}\r\n\r\n        with patch("src.data.collector.pipeline._tdx_fetch_chunked", return_value=tdx_df),              patch("src.data.collector.pipeline._fetch_baostock_fallback", return_value=bs_df):\r\n            return update_single_stock(\r\n                code="000001", market=0,\r\n                parquet_dir=Path(tmpdir),\r\n                tdx_pool=pool,\r\n                ak_results=ak_results,\r\n                report=report,\r\n                force_full=True,\r\n            )\r\n\r\n    def test_both_tracks_succeed(self):\r\n        tdx = _make_ohlcv(30)\r\n        ak  = _make_akshare_df(30)\r\n        ak["date"] = tdx["date"].tolist()\r\n        code, ok, src = self._run_update(tdx, ak, None)\r\n        self.assertTrue(ok)\r\n        self.assertIn(src, ("merged", "tdx", "akshare"))\r\n\r\n    def test_tdx_fail_akshare_succeed(self):\r\n        ak = _make_akshare_df(30)\r\n        code, ok, src = self._run_update(None, ak, None)\r\n        self.assertTrue(ok)\r\n        self.assertEqual(src, "akshare")\r\n\r\n    def test_both_fail_baostock_fallback(self):\r\n        bs = _make_ohlcv(30)\r\n        bs["source"] = "baostock"\r\n        code, ok, src = self._run_update(None, None, bs)\r\n        self.assertTrue(ok)\r\n        self.assertEqual(src, "baostock")\r\n\r\n    def test_all_three_fail(self):\r\n        code, ok, src = self._run_update(None, None, None)\r\n        self.assertFalse(ok)\r\n\r\n\r\n# ============================================================================\r\n# T8: AKShare \xe8\xbf\x9b\xe7\xa8\x8b\xe5\x87\xbd\xe6\x95\xb0\xe9\x99\x90\xe6\xb5\x81\xe6\x84\x9f\xe7\x9f\xa5\r\n# ============================================================================\r\nclass TestAKShareRateLimitBackoff(unittest.TestCase):\r\n\r\n    def test_ratelimit_keyword_detection(self):\r\n        """\xe6\xa8\xa1\xe6\x8b\x9f AKShare \xe6\x8a\x9b\xe5\x87\xba\xe9\x99\x90\xe6\xb5\x81\xe9\x94\x99\xe8\xaf\xaf\xef\xbc\x8c\xe9\xaa\x8c\xe8\xaf\x81\xe7\xad\x89\xe5\xbe\x85\xe6\x97\xb6\xe9\x97\xb4\xe5\xa4\xa7\xe4\xba\x8e\xe6\x99\xae\xe9\x80\x9a\xe9\x94\x99\xe8\xaf\xaf\xe3\x80\x82"""\r\n        from src.data.collector.akshare_client import _RATELIMIT_KEYWORDS\r\n        ratelimit_errs = ["429 Too Many Requests", "\xe8\xa7\xa6\xe5\x8f\x91\xe9\x99\x90\xe6\xb5\x81", "\xe8\xaf\xb7\xe6\xb1\x82\xe9\xa2\x91\xe7\xb9\x81", "too many requests"]\r\n        for err in ratelimit_errs:\r\n            is_rl = any(kw in err for kw in _RATELIMIT_KEYWORDS)\r\n            self.assertTrue(is_rl, f"\xe9\x99\x90\xe6\xb5\x81\xe5\x85\xb3\xe9\x94\xae\xe8\xaf\x8d\xe6\x9c\xaa\xe5\x8c\xb9\xe9\x85\x8d: {err}")\r\n\r\n    def test_normal_error_not_ratelimit(self):\r\n        from src.data.collector.akshare_client import _RATELIMIT_KEYWORDS\r\n        normal_errs = ["ConnectionError", "TimeoutError", "JSONDecodeError", "KeyError"]\r\n        for err in normal_errs:\r\n            is_rl = any(kw in err for kw in _RATELIMIT_KEYWORDS)\r\n            self.assertFalse(is_rl, f"\xe6\x99\xae\xe9\x80\x9a\xe9\x94\x99\xe8\xaf\xaf\xe8\xa2\xab\xe8\xaf\xaf\xe5\x88\xa4\xe4\xb8\xba\xe9\x99\x90\xe6\xb5\x81: {err}")\r\n\r\n    def test_process_worker_handles_import_error(self):\r\n        """akshare \xe6\x9c\xaa\xe5\xae\x89\xe8\xa3\x85\xe6\x97\xb6\xef\xbc\x8cworker \xe5\xba\x94\xe8\xbf\x94\xe5\x9b\x9e\xe6\x98\x8e\xe7\xa1\xae\xe9\x94\x99\xe8\xaf\xaf\xe8\x80\x8c\xe9\x9d\x9e\xe5\xb4\xa9\xe6\xba\x83\xe3\x80\x82"""\r\n        from src.data.collector.akshare_client import _akshare_process_worker\r\n        task = ("000001", "2023-01-01", "2023-12-31", 1, 0.0, 0.0)\r\n        with patch.dict("sys.modules", {"akshare": None}):\r\n            code, data, error = _akshare_process_worker(task)\r\n        self.assertEqual(code, "000001")\r\n        self.assertIsNone(data)\r\n        self.assertIsNotNone(error)\r\n\r\n    def test_extended_fields_constant(self):\r\n        """AK_EXTENDED_FIELDS \xe5\xbf\x85\xe9\xa1\xbb\xe5\x8c\x85\xe5\x90\xab turnover\xe3\x80\x82"""\r\n        from src.data.collector.akshare_client import AK_EXTENDED_FIELDS\r\n        self.assertIn("turnover", AK_EXTENDED_FIELDS)\r\n        self.assertIn("pct_change", AK_EXTENDED_FIELDS)\r\n\r\n\r\nif __name__ == "__main__":\r\n    unittest.main(verbosity=2)\r\n'

FILE_tests_test_v5_core_py = b'#!/usr/bin/env python3\r\n"""\r\nQ-UNITY-V6 \xe6\xa0\xb8\xe5\xbf\x83\xe5\x9b\x9e\xe5\xbd\x92\xe6\xb5\x8b\xe8\xaf\x95 v2.1\r\nT1: RSRS \xe7\xa8\xb3\xe5\xae\x9a\xe6\x80\xa7\xef\xbc\x886\xe7\x94\xa8\xe4\xbe\x8b, resid_std >= 0\xef\xbc\x89\r\nT2: \xe9\xa3\x8e\xe6\x8e\xa7\xe7\x86\x94\xe6\x96\xad\xef\xbc\x88\xe8\xa7\xa6\xe5\x8f\x91+cooldown\xef\xbc\x89\r\nT3: \xe5\x89\x8d\xe8\xa7\x86\xe5\x81\x8f\xe5\xb7\xae\xe9\xaa\x8c\xe8\xaf\x81\xef\xbc\x88NB-01\xef\xbc\x89\r\nT4: \xe7\xad\x96\xe7\x95\xa5\xe9\x9b\x86\xe6\x88\x90\xef\xbc\x88\xe5\x81\x9c\xe7\x89\x8c/\xe7\xbc\xba\xe5\xa4\xb1\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x89\r\nT5: NB-21 \xe9\x97\xad\xe7\x8e\xaf\xef\xbc\x885\xe5\xa4\xa9\xe6\x96\xb0\xe8\x82\xa1/\xe6\x9c\x89\xe6\x95\x88\xe6\x8e\xa9\xe7\xa0\x81\xe5\xbd\xa2\xe7\x8a\xb6/\xe6\xb7\xb7\xe5\x90\x88\xe6\x97\xb6\xe5\xba\x8f\xef\xbc\x89\r\n"""\r\nfrom __future__ import annotations\r\nimport math\r\nfrom datetime import datetime, timedelta, date\r\nfrom typing import Dict, List, Optional\r\nimport numpy as np\r\nimport pandas as pd\r\nimport pytest\r\n\r\n# \xe2\x94\x80\xe2\x94\x80 \xe8\xbe\x85\xe5\x8a\xa9\xe7\x94\x9f\xe6\x88\x90\xe5\x99\xa8 \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\r\n\r\ndef _make_ohlcv(n: int, seed: int = 42, start_price: float = 10.0) -> pd.DataFrame:\r\n    rng = np.random.RandomState(seed)\r\n    close = start_price * np.cumprod(1 + rng.randn(n) * 0.01)\r\n    high  = close * (1 + rng.uniform(0, 0.03, n))\r\n    low   = close * (1 - rng.uniform(0, 0.03, n))\r\n    open_ = close * (1 + rng.randn(n) * 0.005)\r\n    vol   = rng.randint(100_000, 1_000_000, n).astype(float)\r\n    dates = pd.date_range("2022-01-01", periods=n, freq="B")\r\n    return pd.DataFrame({\r\n        "open": open_, "high": high, "low": low, "close": close, "volume": vol,\r\n    }, index=dates)\r\n\r\n\r\ndef _make_price_data(codes: List[str], n_days: int = 252) -> Dict[str, Dict[str, float]]:\r\n    """\xe7\x94\x9f\xe6\x88\x90\xe5\xbd\x93\xe6\x97\xa5\xe4\xbb\xb7\xe6\xa0\xbc\xe5\xbf\xab\xe7\x85\xa7\xe5\xad\x97\xe5\x85\xb8"""\r\n    rng = np.random.RandomState(0)\r\n    return {\r\n        code: {\r\n            "open": 10.0 + rng.rand(),\r\n            "high": 10.5 + rng.rand(),\r\n            "low":  9.5  + rng.rand(),\r\n            "close": 10.0 + rng.rand(),\r\n            "volume": 500_000.0,\r\n        }\r\n        for code in codes\r\n    }\r\n\r\n\r\n# ============================================================================\r\n# T1: RSRS \xe7\xa8\xb3\xe5\xae\x9a\xe6\x80\xa7\xe6\xb5\x8b\xe8\xaf\x95\r\n# ============================================================================\r\n\r\nclass TestRSRSStability:\r\n    """T1: RSRS \xe5\x9b\xa0\xe5\xad\x90\xe5\x9c\xa8\xe5\x90\x84\xe7\xa7\x8d\xe6\x95\xb0\xe6\x8d\xae\xe6\x9d\xa1\xe4\xbb\xb6\xe4\xb8\x8b\xe7\x9a\x84\xe7\xa8\xb3\xe5\xae\x9a\xe6\x80\xa7"""\r\n\r\n    def _compute(self, df, window=18, zwindow=600):\r\n        from src.factors.technical.rsrs import compute_rsrs\r\n        return compute_rsrs(df, regression_window=window, zscore_window=zwindow)\r\n\r\n    def test_normal_data_basic(self):\r\n        """\xe6\xad\xa3\xe5\xb8\xb8\xe6\x95\xb0\xe6\x8d\xae: rsrs_raw \xe6\x9c\xab\xe5\xb0\xbe\xe5\xba\x94\xe4\xb8\xba\xe6\x9c\x89\xe9\x99\x90\xe6\xb5\xae\xe7\x82\xb9\xe6\x95\xb0"""\r\n        df = _make_ohlcv(300)\r\n        result = self._compute(df)\r\n        assert "rsrs_raw" in result.columns\r\n        tail = result["rsrs_raw"].dropna()\r\n        assert len(tail) > 0\r\n        assert math.isfinite(float(tail.iloc[-1]))\r\n\r\n    def test_resid_std_nonnegative(self):\r\n        """resid_std \xe4\xb8\x8d\xe5\x8f\xaf\xe4\xb8\xba\xe8\xb4\x9f\xef\xbc\x88NB \xe5\x9f\xba\xe7\xa1\x80\xe8\xa6\x81\xe6\xb1\x82\xef\xbc\x89"""\r\n        df = _make_ohlcv(300)\r\n        result = self._compute(df)\r\n        rstd = result["resid_std"].dropna()\r\n        assert (rstd >= 0).all(), "resid_std \xe5\x87\xba\xe7\x8e\xb0\xe8\xb4\x9f\xe5\x80\xbc!"\r\n\r\n    def test_short_series_no_crash(self):\r\n        """\xe7\x9f\xad\xe5\xba\x8f\xe5\x88\x97\xef\xbc\x8815\xe8\xa1\x8c\xef\xbc\x89: \xe4\xb8\x8d\xe5\xb4\xa9\xe6\xba\x83\xef\xbc\x8c\xe8\xbf\x94\xe5\x9b\x9e\xe5\x85\xa8NaN"""\r\n        df = _make_ohlcv(15)\r\n        result = self._compute(df)\r\n        # window=18 > 15\xef\xbc\x8c\xe5\x85\xa8\xe9\x83\xa8\xe5\xba\x94\xe4\xb8\xba NaN\r\n        assert result["rsrs_raw"].isna().all()\r\n\r\n    def test_constant_price_no_crash(self):\r\n        """\xe5\xb8\xb8\xe6\x95\xb0\xe4\xbb\xb7\xe6\xa0\xbc: \xe4\xb8\x8d\xe5\xb4\xa9\xe6\xba\x83\xef\xbc\x88OLS \xe6\x96\xb9\xe5\xb7\xae\xe4\xb8\xba0\xef\xbc\x89\xef\xbc\x8cresid_std >= 0"""\r\n        df = _make_ohlcv(300)\r\n        df["high"] = 11.0\r\n        df["low"]  = 9.0\r\n        result = self._compute(df)\r\n        rstd = result["resid_std"].dropna()\r\n        assert (rstd >= 0).all()\r\n\r\n    def test_zscore_finite_enough(self):\r\n        """\xe5\x85\x85\xe8\xb6\xb3\xe6\x95\xb0\xe6\x8d\xae\xe5\x90\x8e zscore \xe7\xaa\x97\xe5\x8f\xa3\xe5\x86\x85\xe5\xba\x94\xe4\xba\xa7\xe7\x94\x9f\xe6\x9c\x89\xe9\x99\x90\xe5\x80\xbc"""\r\n        df = _make_ohlcv(700)\r\n        result = self._compute(df, zwindow=200)\r\n        tail = result["rsrs_zscore"].dropna()\r\n        assert len(tail) > 100\r\n        assert all(math.isfinite(v) for v in tail.tail(10))\r\n\r\n    def test_r2_bounded(self):\r\n        """R\xc2\xb2 \xe5\xba\x94\xe5\x9c\xa8 [0, 1] \xe5\x86\x85"""\r\n        df = _make_ohlcv(400)\r\n        result = self._compute(df)\r\n        r2 = result["rsrs_r2"].dropna()\r\n        assert (r2 >= 0).all() and (r2 <= 1.0 + 1e-9).all()\r\n\r\n\r\n# ============================================================================\r\n# T2: \xe9\xa3\x8e\xe6\x8e\xa7\xe7\x86\x94\xe6\x96\xad\xe6\xb5\x8b\xe8\xaf\x95\r\n# ============================================================================\r\n\r\nclass TestRiskCircuitBreaker:\r\n    """T2: \xe7\x86\x94\xe6\x96\xad\xe8\xa7\xa6\xe5\x8f\x91 + NB-12 cooldown \xe8\xa7\xa3\xe9\x99\xa4"""\r\n\r\n    def _make_engine(self, max_dd=0.20, cooldown=3):\r\n        from src.engine.execution import BacktestEngine\r\n        return BacktestEngine(\r\n            initial_cash=1_000_000.0,\r\n            circuit_breaker_max_dd=max_dd,\r\n            circuit_breaker_cooldown_days=cooldown,\r\n        )\r\n\r\n    def test_circuit_breaker_triggers(self):\r\n        """\xe5\x9b\x9e\xe6\x92\xa4\xe8\xb6\x85\xe8\xbf\x87\xe9\x98\x88\xe5\x80\xbc\xe6\x97\xb6\xe7\x86\x94\xe6\x96\xad\xe5\xba\x94\xe8\xa7\xa6\xe5\x8f\x91"""\r\n        eng = self._make_engine(max_dd=0.20, cooldown=999)\r\n        codes = ["000001"]\r\n        # \xe6\xa8\xa1\xe6\x8b\x9f\xe5\xa4\xa7\xe5\xb9\x85\xe4\xba\x8f\xe6\x8d\x9f\r\n        for i in range(30):\r\n            price = max(1.0, 10.0 - i * 0.5)\r\n            price_data = {"000001": {"open": price, "high": price, "low": price*0.99,\r\n                                     "close": price, "volume": 1e6}}\r\n            result = eng.step(date(2023, 1, 1) + timedelta(days=i), price_data, [])\r\n        # \xe6\xa3\x80\xe6\x9f\xa5\xe6\x98\xaf\xe5\x90\xa6\xe8\xa7\xa6\xe5\x8f\x91\xef\xbc\x88\xe8\xa7\x86\xe5\x88\x9d\xe5\xa7\x8b\xe8\xb5\x84\xe4\xba\xa7\xe6\x97\xa0\xe6\x8c\x81\xe4\xbb\x93\xef\xbc\x8c\xe5\x9b\x9e\xe6\x92\xa4=0\xef\xbc\x8c\xe6\x95\x85\xe7\x9b\xb4\xe6\x8e\xa5\xe6\xb5\x8b API\xef\xbc\x89\r\n        eng._circuit_broken = True\r\n        eng._circuit_break_date = date(2023, 1, 10)\r\n        result = eng.step(date(2023, 2, 10), {"000001": {"open": 5.0, "high": 5.1,\r\n                                                          "low": 4.9, "close": 5.0,\r\n                                                          "volume": 1e6}}, [])\r\n        assert result["circuit_broken"] is False, "cooldown \xe5\x90\x8e\xe5\xba\x94\xe5\xb7\xb2\xe8\xa7\xa3\xe9\x99\xa4"\r\n\r\n    def test_circuit_breaker_cooldown(self):\r\n        """NB-12: cooldown_days \xe5\x86\x85\xe4\xb8\x8d\xe4\xb9\xb0\xe5\x85\xa5\xef\xbc\x8c\xe8\xbf\x87\xe5\x90\x8e\xe8\x87\xaa\xe5\x8a\xa8\xe8\xa7\xa3\xe9\x99\xa4"""\r\n        eng = self._make_engine(max_dd=0.10, cooldown=5)\r\n        eng._circuit_broken     = True\r\n        eng._circuit_break_date = date(2023, 3, 1)\r\n        # \xe7\xac\xac3\xe5\xa4\xa9: \xe4\xbb\x8d\xe5\x9c\xa8 cooldown\r\n        r1 = eng.step(date(2023, 3, 4), {"A": {"open": 10.0, "high": 10.1,\r\n                                                "low": 9.9, "close": 10.0, "volume": 1e6}}, [])\r\n        assert r1["circuit_broken"] is True\r\n        # \xe7\xac\xac6\xe5\xa4\xa9: cooldown \xe7\xbb\x93\xe6\x9d\x9f\r\n        r2 = eng.step(date(2023, 3, 7), {"A": {"open": 10.0, "high": 10.1,\r\n                                                "low": 9.9, "close": 10.0, "volume": 1e6}}, [])\r\n        assert r2["circuit_broken"] is False\r\n\r\n\r\n# ============================================================================\r\n# T3: \xe5\x89\x8d\xe8\xa7\x86\xe5\x81\x8f\xe5\xb7\xae\xe9\xaa\x8c\xe8\xaf\x81\r\n# ============================================================================\r\n\r\nclass TestLookaheadBias:\r\n    """T3: NB-01 \xe4\xbf\xa1\xe5\x8f\xb7T-1\xe7\x94\x9f\xe6\x88\x90\xef\xbc\x8cT\xe6\x89\xa7\xe8\xa1\x8c\xef\xbc\x8c\xe6\x97\xa0\xe5\x89\x8d\xe8\xa7\x86\xe5\x81\x8f\xe5\xb7\xae"""\r\n\r\n    def test_signal_uses_yesterday_data(self):\r\n        """\xe4\xbf\xa1\xe5\x8f\xb7\xe5\xba\x94\xe5\x9f\xba\xe4\xba\x8e\xe6\x88\xaa\xe6\xad\xa2 T-1 \xe7\x9a\x84\xe5\x9b\xa0\xe5\xad\x90\xe6\x95\xb0\xe6\x8d\xae"""\r\n        from src.factors.alpha_engine import AlphaEngine\r\n        df = _make_ohlcv(200)\r\n        result = AlphaEngine.compute_from_history(df)\r\n        # T\xe6\x97\xa5\xe7\x9a\x84 rsrs_adaptive \xe4\xbb\x85\xe4\xbe\x9d\xe8\xb5\x96 T-1 \xe5\x8f\x8a\xe4\xb9\x8b\xe5\x89\x8d\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x88OLS\xe8\xae\xa1\xe7\xae\x97\xe4\xb8\x8d\xe5\x90\xabT\xe6\x97\xa5\xef\xbc\x89\r\n        # \xe9\xaa\x8c\xe8\xaf\x81: \xe8\x8b\xa5\xe6\x88\xaa\xe6\x96\xad\xe6\x9c\x80\xe5\x90\x8e1\xe8\xa1\x8c\xef\xbc\x8c\xe5\x89\x8dN\xe8\xa1\x8c\xe7\xbb\x93\xe6\x9e\x9c\xe4\xb8\x8d\xe5\x8f\x98\r\n        result_full = AlphaEngine.compute_from_history(df)\r\n        result_cut  = AlphaEngine.compute_from_history(df.iloc[:-1])\r\n        # \xe5\x80\x92\xe6\x95\xb0\xe7\xac\xac2\xe8\xa1\x8c\xe7\x9a\x84\xe5\x80\xbc\xe5\xba\x94\xe7\x9b\xb8\xe5\x90\x8c\xef\xbc\x88\xe6\x97\xa0\xe5\x89\x8d\xe8\xa7\x86\xef\xbc\x89\r\n        if not result_cut["rsrs_adaptive"].isna().all():\r\n            val_full = result_full["rsrs_adaptive"].dropna().iloc[-2]\r\n            val_cut  = result_cut["rsrs_adaptive"].dropna().iloc[-1]\r\n            assert abs(val_full - val_cut) < 1e-9, "\xe6\xa3\x80\xe6\xb5\x8b\xe5\x88\xb0\xe5\x89\x8d\xe8\xa7\x86\xe5\x81\x8f\xe5\xb7\xae!"\r\n\r\n    def test_engine_uses_open_price_for_execution(self):\r\n        """\xe5\xbc\x95\xe6\x93\x8e\xe5\x9c\xa8 T \xe6\x97\xa5\xe5\xbc\x80\xe7\x9b\x98\xe4\xbb\xb7\xe6\x89\xa7\xe8\xa1\x8c\xe4\xbf\xa1\xe5\x8f\xb7\xef\xbc\x88NB-01\xef\xbc\x89"""\r\n        from src.engine.execution import BacktestEngine\r\n        from src.types import OrderSide, Signal\r\n        eng = BacktestEngine(initial_cash=1_000_000.0)\r\n\r\n        # T-1 \xe6\x97\xa5\xe7\x94\x9f\xe6\x88\x90\xe4\xbf\xa1\xe5\x8f\xb7\r\n        sig = Signal(\r\n            timestamp=datetime(2023, 1, 2),\r\n            code="000001",\r\n            side=OrderSide.BUY,\r\n            score=1.0,\r\n            weight=0.1,\r\n            reason="\xe6\xb5\x8b\xe8\xaf\x95",\r\n        )\r\n        # T-1 \xe6\x97\xa5 step\xef\xbc\x88\xe4\xbf\xa1\xe5\x8f\xb7\xe5\x8a\xa0\xe5\x85\xa5 pending\xef\xbc\x89\r\n        pd_t1 = {"000001": {"open": 10.0, "high": 10.5, "low": 9.5,\r\n                              "close": 10.0, "volume": 1e6}}\r\n        eng.step(date(2023, 1, 2), pd_t1, [sig])\r\n\r\n        # T \xe6\x97\xa5 step\xef\xbc\x88\xe4\xbd\xbf\xe7\x94\xa8 T \xe6\x97\xa5 open=11.0 \xe6\x89\xa7\xe8\xa1\x8c\xef\xbc\x89\r\n        pd_t2 = {"000001": {"open": 11.0, "high": 11.5, "low": 10.5,\r\n                              "close": 11.0, "volume": 1e6}}\r\n        result = eng.step(date(2023, 1, 3), pd_t2, [])\r\n        # \xe6\xa3\x80\xe6\x9f\xa5\xe6\x88\x90\xe4\xba\xa4\xe5\x8f\x91\xe7\x94\x9f\xe5\x9c\xa8 T \xe6\x97\xa5\xe5\xbc\x80\xe7\x9b\x98\xe4\xbb\xb7\xe9\x99\x84\xe8\xbf\x91\xef\xbc\x88\xe5\x90\xab\xe6\xbb\x91\xe7\x82\xb9\xef\xbc\x89\r\n        fills = result.get("executions", [])\r\n        if fills:\r\n            exec_price = fills[0]["price"]\r\n            assert abs(exec_price - 11.0 * 1.001) < 0.01, f"\xe6\x89\xa7\xe8\xa1\x8c\xe4\xbb\xb7\xe5\xba\x94\xe4\xb8\xbaT\xe6\x97\xa5\xe5\xbc\x80\xe7\x9b\x98\xe4\xbb\xb7\xe5\x90\xab\xe6\xbb\x91\xe7\x82\xb9, \xe5\xae\x9e\xe9\x99\x85={exec_price}"\r\n\r\n\r\n# ============================================================================\r\n# T4: \xe7\xad\x96\xe7\x95\xa5\xe9\x9b\x86\xe6\x88\x90\xe6\xb5\x8b\xe8\xaf\x95\r\n# ============================================================================\r\n\r\nclass TestStrategyIntegration:\r\n    """T4: \xe5\x81\x9c\xe7\x89\x8c/\xe7\xbc\xba\xe5\xa4\xb1\xe6\x95\xb0\xe6\x8d\xae\xe5\x9c\xba\xe6\x99\xaf\xe4\xb8\x8b\xe7\xad\x96\xe7\x95\xa5\xe7\xa8\xb3\xe5\xae\x9a\xe6\x80\xa7"""\r\n\r\n    def _make_factor_data(self, codes: List[str], n: int = 200) -> Dict:\r\n        result = {}\r\n        for code in codes:\r\n            df = _make_ohlcv(n, seed=hash(code) % 1000)\r\n            from src.factors.alpha_engine import AlphaEngine\r\n            result[code] = AlphaEngine.compute_from_history(df)\r\n        return result\r\n\r\n    def test_rsrs_strategy_with_missing_factor(self):\r\n        """RSRSMomentum: \xe9\x83\xa8\xe5\x88\x86\xe8\x82\xa1\xe7\xa5\xa8\xe6\x97\xa0\xe5\x9b\xa0\xe5\xad\x90\xe6\x95\xb0\xe6\x8d\xae\xe6\x97\xb6\xe4\xb8\x8d\xe5\xb4\xa9\xe6\xba\x83"""\r\n        from src.strategy.strategies import RSRSMomentumStrategy\r\n        strat = RSRSMomentumStrategy({"top_n": 3, "rsrs_threshold": 0.3})\r\n        universe = ["000001", "000002", "000003"]\r\n        market_data = {code: _make_ohlcv(200) for code in universe}\r\n        factor_data = self._make_factor_data(["000001"])  # \xe5\x8f\xaa\xe6\x9c\x89\xe4\xb8\x80\xe4\xb8\xaa\xe6\x9c\x89\xe5\x9b\xa0\xe5\xad\x90\r\n        factor_data["000002"] = pd.DataFrame()            # \xe7\xa9\xba DataFrame\r\n        # 000003 \xe7\xbc\xba\xe5\xa4\xb1\r\n\r\n        signals = strat.generate_signals(\r\n            universe, market_data, factor_data,\r\n            datetime(2023, 6, 1), {}\r\n        )\r\n        assert isinstance(signals, list)\r\n\r\n    def test_kunpeng_v10_suspended_stock(self):\r\n        """KunpengV10: \xe5\x81\x9c\xe7\x89\x8c\xe8\x82\xa1\xef\xbc\x88\xe6\x97\xa0\xe4\xbb\xb7\xe6\xa0\xbc\xe6\x95\xb0\xe6\x8d\xae\xef\xbc\x89\xe4\xb8\x8d\xe4\xba\xa7\xe7\x94\x9f\xe4\xbf\xa1\xe5\x8f\xb7"""\r\n        from src.strategy.strategies import KunpengV10Strategy\r\n        strat = KunpengV10Strategy({"top_n": 3})\r\n        universe = ["000001", "000002"]\r\n        # 000002 \xe5\x81\x9c\xe7\x89\x8c\xef\xbc\x9a\xe6\x97\xa0\xe5\xb8\x82\xe5\x9c\xba\xe6\x95\xb0\xe6\x8d\xae\r\n        market_data = {"000001": _make_ohlcv(60)}\r\n        factor_data = {}\r\n        signals = strat.generate_signals(\r\n            universe, market_data, factor_data,\r\n            datetime(2023, 6, 1), {}\r\n        )\r\n        # \xe5\x81\x9c\xe7\x89\x8c\xe8\x82\xa1\xe4\xb8\x8d\xe5\xba\x94\xe6\x9c\x89\xe4\xb9\xb0\xe5\x85\xa5\xe4\xbf\xa1\xe5\x8f\xb7\r\n        buy_codes = [s.code for s in signals if s.side.value == "BUY"]\r\n        assert "000002" not in buy_codes\r\n\r\n    def test_alpha_max_v5_no_fundamental(self):\r\n        """AlphaMaxV5: \xe6\x97\xa0\xe5\x9f\xba\xe6\x9c\xac\xe9\x9d\xa2\xe6\x95\xb0\xe6\x8d\xae\xe6\x97\xb6\xe4\xb8\x8d\xe5\xb4\xa9\xe6\xba\x83\xef\xbc\x8c\xe4\xbb\x8d\xe8\x83\xbd\xe8\xaf\x84\xe5\x88\x86"""\r\n        from src.strategy.strategies import AlphaMaxV5FixedStrategy\r\n        strat = AlphaMaxV5FixedStrategy({"top_n": 5})\r\n        codes = [f"00000{i}" for i in range(1, 6)]\r\n        market_data = {c: _make_ohlcv(60, seed=i) for i, c in enumerate(codes)}\r\n        factor_data = {}\r\n        signals = strat.generate_signals(\r\n            codes, market_data, factor_data,\r\n            datetime(2023, 6, 1), {},\r\n            fundamental_data=None,\r\n        )\r\n        assert isinstance(signals, list)\r\n\r\n\r\n# ============================================================================\r\n# T5: NB-21 \xe9\x97\xad\xe7\x8e\xaf\xe6\x96\xb0\xe8\x82\xa1\xe9\x98\xb2\xe5\xbe\xa1\xe6\xb5\x8b\xe8\xaf\x95\r\n# ============================================================================\r\n\r\nclass TestNB21NewStockDefense:\r\n    """T5: NB-21 \xe9\x97\xad\xe7\x8e\xaf Monkey-Patch \xe9\xaa\x8c\xe8\xaf\x81"""\r\n\r\n    def _make_short_df(self, n: int) -> pd.DataFrame:\r\n        """\xe7\x94\x9f\xe6\x88\x90 n \xe5\xa4\xa9\xe8\xa1\x8c\xe6\x83\x85\xef\xbc\x88\xe6\xa8\xa1\xe6\x8b\x9f\xe6\x96\xb0\xe8\x82\xa1\xe4\xb8\x8a\xe5\xb8\x82\xe5\x88\x9d\xe6\x9c\x9f\xef\xbc\x89"""\r\n        rng = np.random.RandomState(123)\r\n        base = 10.0 + rng.randn(n).cumsum() * 0.1\r\n        return pd.DataFrame({\r\n            "open":   base,\r\n            "high":   base * 1.03,\r\n            "low":    base * 0.97,\r\n            "close":  base,\r\n            "volume": np.full(n, 1e6),\r\n        })\r\n\r\n    def test_5_day_stock_rsrs_all_nan(self):\r\n        """5\xe5\xa4\xa9\xe6\x96\xb0\xe8\x82\xa1: rsrs_adaptive \xe5\xbf\x85\xe9\xa1\xbb\xe5\x85\xa8\xe4\xb8\xba NaN\xef\xbc\x88NB-21 \xe9\x98\xb2\xe5\xbe\xa1\xef\xbc\x89"""\r\n        from src.factors.alpha_engine import AlphaEngine\r\n        df = self._make_short_df(5)\r\n        result = AlphaEngine.compute_from_history(df)\r\n        assert "rsrs_adaptive" in result.columns\r\n        assert result["rsrs_adaptive"].isna().all(),             "5\xe5\xa4\xa9\xe6\x96\xb0\xe8\x82\xa1 rsrs_adaptive \xe5\xba\x94\xe5\x85\xa8NaN\xef\xbc\x8cNB-21 \xe6\x9c\xaa\xe6\xad\xa3\xe7\xa1\xae\xe5\xba\x94\xe7\x94\xa8!"\r\n\r\n    def test_valid_mask_shape_matches_df(self):\r\n        """_nb21_valid_mask \xe8\xbe\x93\xe5\x87\xba\xe5\xbd\xa2\xe7\x8a\xb6\xe4\xb8\x8e\xe8\xbe\x93\xe5\x85\xa5 DataFrame \xe4\xb8\x80\xe8\x87\xb4"""\r\n        from src.factors.alpha_engine import _nb21_valid_mask\r\n        df = self._make_short_df(100)\r\n        mask = _nb21_valid_mask(df, rsrs_window=18)\r\n        assert mask.shape == (100,), f"mask \xe5\xbd\xa2\xe7\x8a\xb6\xe9\x94\x99\xe8\xaf\xaf: {mask.shape}"\r\n        assert mask.dtype == bool\r\n\r\n    def test_valid_mask_threshold(self):\r\n        """\xe5\x89\x8d rsrs_window*2-1 \xe8\xa1\x8c mask=False\xef\xbc\x8c\xe4\xb9\x8b\xe5\x90\x8e mask=True\xef\xbc\x88\xe6\x97\xa0\xe7\xbc\xba\xe5\xa4\xb1\xe6\x97\xb6\xef\xbc\x89"""\r\n        from src.factors.alpha_engine import _nb21_valid_mask\r\n        rsrs_window = 18\r\n        n = 100\r\n        df = self._make_short_df(n)\r\n        mask = _nb21_valid_mask(df, rsrs_window=rsrs_window)\r\n        threshold = rsrs_window * 2  # \xe7\xac\xac threshold \xe8\xa1\x8c\xe8\xb5\xb7\xe4\xb8\xba True\xef\xbc\x880-indexed\xef\xbc\x89\r\n        assert not mask[threshold - 2], f"\xe7\xac\xac{threshold-2}\xe8\xa1\x8c\xe5\xba\x94\xe4\xb8\xbaFalse"\r\n        assert mask[threshold - 1], f"\xe7\xac\xac{threshold-1}\xe8\xa1\x8c\xe5\xba\x94\xe4\xb8\xbaTrue"\r\n\r\n    def test_mixed_vintage_old_stock_has_rsrs(self):\r\n        """\xe5\x85\x85\xe8\xb6\xb3\xe5\x8e\x86\xe5\x8f\xb2(200\xe5\xa4\xa9)\xe7\x9a\x84\xe8\x80\x81\xe8\x82\xa1\xe7\xa5\xa8: rsrs_adaptive \xe6\x9c\xab\xe5\xb0\xbe\xe5\xba\x94\xe6\x9c\x89\xe6\x9c\x89\xe6\x95\x88\xe5\x80\xbc"""\r\n        from src.factors.alpha_engine import AlphaEngine\r\n        df = self._make_short_df(200)\r\n        result = AlphaEngine.compute_from_history(df)\r\n        tail = result["rsrs_adaptive"].dropna()\r\n        assert len(tail) > 0, "200\xe5\xa4\xa9\xe8\x80\x81\xe8\x82\xa1\xe7\xa5\xa8 rsrs_adaptive \xe5\x85\xa8\xe4\xb8\xbaNaN\xef\xbc\x8cNB-21 \xe8\xbf\x87\xe5\xba\xa6\xe5\xb1\x8f\xe8\x94\xbd!"\r\n        assert math.isfinite(float(tail.iloc[-1]))\r\n\r\n    def test_apply_mask_forces_nan(self):\r\n        """_apply_nb21_mask_to_rsrs: mask=False \xe5\xa4\x84\xe5\xbc\xba\xe5\x88\xb6 NaN"""\r\n        from src.factors.alpha_engine import _apply_nb21_mask_to_rsrs\r\n        n = 50\r\n        df = pd.DataFrame({\r\n            "rsrs_raw":      np.random.randn(n),\r\n            "rsrs_zscore":   np.random.randn(n),\r\n            "rsrs_r2":       np.random.rand(n),\r\n            "rsrs_adaptive": np.random.randn(n),\r\n            "resid_std":     np.random.rand(n),\r\n        })\r\n        mask = np.zeros(n, dtype=bool)\r\n        mask[30:] = True   # \xe5\x90\x8e20\xe8\xa1\x8c\xe6\x9c\x89\xe6\x95\x88\r\n        result = _apply_nb21_mask_to_rsrs(df.copy(), mask)\r\n        assert result["rsrs_adaptive"].iloc[:30].isna().all(), "mask=False \xe5\xa4\x84\xe6\x9c\xaa\xe7\xbd\xaeNaN"\r\n        assert result["rsrs_adaptive"].iloc[30:].notna().all(), "mask=True \xe5\xa4\x84\xe4\xb8\x8d\xe5\xba\x94\xe4\xb8\xbaNaN"\r\n'


def build() -> None:
    """Write all 39 project files and create empty data directories."""
    all_files = [
        ('config.json', FILE_config_json),
        ('requirements.txt', FILE_requirements_txt),
        ('README_OP.md', FILE_README_OP_md),
        ('main.py', FILE_main_py),
        ('main_op.py', FILE_main_op_py),
        ('menu_main.py', FILE_menu_main_py),
        ('src/__init__.py', FILE_src_init_py),
        ('src/types.py', FILE_src_types_py),
        ('src/constants.py', FILE_src_constants_py),
        ('src/config.py', FILE_src_config_py),
        ('src/data/__init__.py', FILE_src_data_init_py),
        ('src/data/storage.py', FILE_src_data_storage_py),
        ('src/data/fundamental.py', FILE_src_data_fundamental_py),
        ('src/data/industry_provider.py', FILE_src_data_industry_provider_py),
        ('src/data/collector/__init__.py', FILE_src_data_collector_init_py),
        ('src/data/collector/node_scanner.py', FILE_src_data_collector_node_scanner_py),
        ('src/data/collector/tdx_pool.py', FILE_src_data_collector_tdx_pool_py),
        ('src/data/collector/akshare_client.py', FILE_src_data_collector_akshare_client_py),
        ('src/data/collector/baostock_client.py', FILE_src_data_collector_baostock_client_py),
        ('src/data/collector/incremental.py', FILE_src_data_collector_incremental_py),
        ('src/data/collector/validator.py', FILE_src_data_collector_validator_py),
        ('src/data/collector/run_report.py', FILE_src_data_collector_run_report_py),
        ('src/data/collector/cache_manager.py', FILE_src_data_collector_cache_manager_py),
        ('src/data/collector/pipeline.py', FILE_src_data_collector_pipeline_py),
        ('src/engine/__init__.py', FILE_src_engine_init_py),
        ('src/engine/execution.py', FILE_src_engine_execution_py),
        ('src/factors/__init__.py', FILE_src_factors_init_py),
        ('src/factors/alpha_engine.py', FILE_src_factors_alpha_engine_py),
        ('src/factors/technical/__init__.py', FILE_src_factors_technical_init_py),
        ('src/factors/technical/rsrs.py', FILE_src_factors_technical_rsrs_py),
        ('src/factors/technical/alpha.py', FILE_src_factors_technical_alpha_py),
        ('src/risk/__init__.py', FILE_src_risk_init_py),
        ('src/risk/risk_control.py', FILE_src_risk_risk_control_py),
        ('src/strategy/__init__.py', FILE_src_strategy_init_py),
        ('src/strategy/strategies.py', FILE_src_strategy_strategies_py),
        ('tests/__init__.py', FILE_tests_init_py),
        ('tests/conftest.py', FILE_tests_conftest_py),
        ('tests/test_collector.py', FILE_tests_test_collector_py),
        ('tests/test_v5_core.py', FILE_tests_test_v5_core_py),
    ]
    for path, content in all_files:
        write_file(path, content)
    data_dirs = [
        "data/stock",
        "data/reports",
        "data/logs",
    ]
    for d in data_dirs:
        (BASE / d).mkdir(parents=True, exist_ok=True)
    print(f"Q-UNITY-V7.1 project built successfully in {BASE.resolve()}")
    print(f"  Files written : {len(all_files)}")


if __name__ == "__main__":
    build()
